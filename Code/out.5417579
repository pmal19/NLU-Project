Loading /scratch/pm2758/nlu/snli_1.0/snli_1.0_train.jsonl
('Time taken - ', 197.76311016082764)
('Epoch start - ', 0)
(0, 1.4672132730484009)
Train Epoch: 0 [0/549367 (0%)]	Loss: 1.467213
(1, 6.31339693069458)
(2, 2.200686454772949)
(3, 1.7820459604263306)
(4, 1.762035846710205)
(5, 1.6136298179626465)
(6, 1.2664074897766113)
(7, 1.186644196510315)
(8, 1.3188892602920532)
(9, 1.408180832862854)
(10, 1.352681040763855)
(11, 1.3478997945785522)
(12, 1.09774649143219)
(13, 1.1366994380950928)
(14, 1.256691813468933)
(15, 1.1903830766677856)
(16, 1.2755357027053833)
(17, 1.1763854026794434)
(18, 1.1886826753616333)
(19, 1.1679147481918335)
(20, 1.2043309211730957)
(21, 1.222550630569458)
(22, 1.194824457168579)
(23, 1.2533406019210815)
(24, 1.2020680904388428)
(25, 1.151152491569519)
(26, 1.155439853668213)
(27, 1.2230311632156372)
(28, 1.1774699687957764)
(29, 1.1198666095733643)
(30, 1.1433615684509277)
(31, 1.0959148406982422)
(32, 1.113441824913025)
(33, 1.1674753427505493)
(34, 1.2262243032455444)
(35, 1.1578383445739746)
(36, 1.1655070781707764)
(37, 1.1187968254089355)
(38, 1.1390174627304077)
(39, 1.1494437456130981)
(40, 1.0752555131912231)
(41, 1.181562900543213)
(42, 1.1443983316421509)
(43, 1.1404943466186523)
(44, 1.1120884418487549)
(45, 1.135779619216919)
(46, 1.141819715499878)
(47, 1.0934514999389648)
(48, 1.139107346534729)
(49, 1.1585596799850464)
(50, 1.1033095121383667)
(51, 1.1819292306900024)
(52, 1.1398465633392334)
(53, 1.1092922687530518)
(54, 1.1223845481872559)
(55, 1.2077066898345947)
(56, 1.155683994293213)
(57, 1.1475344896316528)
(58, 1.1426936388015747)
(59, 1.1296212673187256)
(60, 1.2241079807281494)
(61, 1.111266016960144)
(62, 1.128361463546753)
(63, 1.1981065273284912)
(64, 1.1399784088134766)
(65, 1.1735633611679077)
(66, 1.1273695230484009)
(67, 1.1293538808822632)
(68, 1.1760047674179077)
(69, 1.264100432395935)
(70, 1.1169551610946655)
(71, 1.1102778911590576)
(72, 1.1464214324951172)
(73, 1.1773744821548462)
(74, 1.0998679399490356)
(75, 1.151430368423462)
(76, 1.1332374811172485)
(77, 1.137780785560608)
(78, 1.0974055528640747)
(79, 1.1210289001464844)
(80, 1.1519229412078857)
(81, 1.2022759914398193)
(82, 1.1580793857574463)
(83, 1.1043390035629272)
(84, 1.166110634803772)
(85, 1.1603742837905884)
(86, 1.1094805002212524)
(87, 1.1416584253311157)
(88, 1.1722331047058105)
(89, 1.1399390697479248)
(90, 1.0579218864440918)
(91, 1.108284831047058)
(92, 1.1257283687591553)
(93, 1.1255768537521362)
(94, 1.1552530527114868)
(95, 1.1431418657302856)
(96, 1.0870822668075562)
(97, 1.1296569108963013)
(98, 1.0727568864822388)
(99, 1.1371854543685913)
(100, 1.175201654434204)
Train Epoch: 0 [200/549367 (1%)]	Loss: 1.175202
(101, 1.1609899997711182)
(102, 1.1146255731582642)
(103, 1.1878845691680908)
(104, 1.1141691207885742)
(105, 1.143843412399292)
(106, 1.1718394756317139)
(107, 1.1526215076446533)
(108, 1.089974284172058)
(109, 1.153876543045044)
(110, 1.0666382312774658)
(111, 1.0789036750793457)
(112, 1.119325041770935)
(113, 1.1399955749511719)
(114, 1.1272311210632324)
(115, 1.103209376335144)
(116, 1.1069657802581787)
(117, 1.1572041511535645)
(118, 1.1414307355880737)
(119, 1.1116256713867188)
(120, 1.1678684949874878)
(121, 1.1163190603256226)
(122, 1.1190537214279175)
(123, 1.136156678199768)
(124, 1.1496787071228027)
(125, 1.1549662351608276)
(126, 1.1513586044311523)
(127, 1.1910583972930908)
(128, 1.115510106086731)
(129, 1.1377089023590088)
(130, 1.1326152086257935)
(131, 1.1086102724075317)
(132, 1.1158535480499268)
(133, 1.0768035650253296)
(134, 1.1403508186340332)
(135, 1.0969305038452148)
(136, 1.156733751296997)
(137, 1.0893659591674805)
(138, 1.1436841487884521)
(139, 1.1626696586608887)
(140, 1.1064987182617188)
(141, 1.1544510126113892)
(142, 1.0827661752700806)
(143, 1.1193599700927734)
(144, 1.104362964630127)
(145, 1.1033387184143066)
(146, 1.1261839866638184)
(147, 1.160056233406067)
(148, 1.1023300886154175)
(149, 1.151065707206726)
(150, 1.1293730735778809)
(151, 1.149167537689209)
(152, 1.1242395639419556)
(153, 1.1265056133270264)
(154, 1.1270846128463745)
(155, 1.0847442150115967)
(156, 1.1262892484664917)
(157, 1.1088488101959229)
(158, 1.116310954093933)
(159, 1.0627657175064087)
(160, 1.169997215270996)
(161, 1.1653574705123901)
(162, 1.115580439567566)
(163, 1.0603358745574951)
(164, 1.08688485622406)
(165, 1.1265838146209717)
(166, 1.1190075874328613)
(167, 1.0801963806152344)
(168, 1.1422067880630493)
(169, 1.1481585502624512)
(170, 1.1633321046829224)
(171, 1.137347936630249)
(172, 1.1136951446533203)
(173, 1.1576831340789795)
(174, 1.1060459613800049)
(175, 1.1195671558380127)
(176, 1.1471433639526367)
(177, 1.110429048538208)
(178, 1.1517419815063477)
(179, 1.1016615629196167)
(180, 1.1547831296920776)
(181, 1.0986113548278809)
(182, 1.1698583364486694)
(183, 1.128895878791809)
(184, 1.1211796998977661)
(185, 1.0765795707702637)
(186, 1.1589384078979492)
(187, 1.1077872514724731)
(188, 1.102308988571167)
(189, 1.1227715015411377)
(190, 1.1640597581863403)
(191, 1.0803645849227905)
(192, 1.1570831537246704)
(193, 1.1623625755310059)
(194, 1.1022148132324219)
(195, 1.1315019130706787)
(196, 1.0893503427505493)
(197, 1.0782957077026367)
(198, 1.108410358428955)
(199, 1.1314176321029663)
(200, 1.104581356048584)
Train Epoch: 0 [400/549367 (2%)]	Loss: 1.104581
(201, 1.1011744737625122)
(202, 1.1349409818649292)
(203, 1.1170271635055542)
(204, 1.126208782196045)
(205, 1.1045385599136353)
(206, 1.1377654075622559)
(207, 1.1379047632217407)
(208, 1.1449742317199707)
(209, 1.110460638999939)
(210, 1.1429815292358398)
(211, 1.105866551399231)
(212, 1.1146336793899536)
(213, 1.0864949226379395)
(214, 1.084113359451294)
(215, 1.1493011713027954)
(216, 1.1296594142913818)
(217, 1.0842013359069824)
(218, 1.1267439126968384)
(219, 1.1318258047103882)
(220, 1.1012589931488037)
(221, 1.1424528360366821)
(222, 1.1048452854156494)
(223, 1.1099295616149902)
(224, 1.1053721904754639)
(225, 1.1368558406829834)
(226, 1.118920922279358)
(227, 1.1034514904022217)
(228, 1.1080365180969238)
(229, 1.1266400814056396)
(230, 1.097327709197998)
(231, 1.133864164352417)
(232, 1.1091339588165283)
(233, 1.15372896194458)
(234, 1.1076246500015259)
(235, 1.129575252532959)
(236, 1.0888094902038574)
(237, 1.1333051919937134)
(238, 1.0922356843948364)
(239, 1.124250054359436)
(240, 1.119351863861084)
(241, 1.125104546546936)
(242, 1.1136047840118408)
(243, 1.08602774143219)
(244, 1.1136038303375244)
(245, 1.1149790287017822)
(246, 1.1213605403900146)
(247, 1.0863977670669556)
(248, 1.0984553098678589)
(249, 1.1060006618499756)
(250, 1.1026759147644043)
(251, 1.1030081510543823)
(252, 1.1012303829193115)
(253, 1.1152938604354858)
(254, 1.0907196998596191)
(255, 1.143121361732483)
(256, 1.1212873458862305)
(257, 1.111693024635315)
(258, 1.1059120893478394)
(259, 1.1215988397598267)
(260, 1.1032823324203491)
(261, 1.103042483329773)
(262, 1.120313048362732)
(263, 1.1473225355148315)
(264, 1.1193904876708984)
(265, 1.1217950582504272)
(266, 1.1149271726608276)
(267, 1.1246147155761719)
(268, 1.1142029762268066)
(269, 1.0985417366027832)
(270, 1.1217920780181885)
(271, 1.1093051433563232)
(272, 1.1002496480941772)
(273, 1.097077488899231)
(274, 1.1326727867126465)
(275, 1.1396033763885498)
(276, 1.1114771366119385)
(277, 1.0740824937820435)
(278, 1.1520333290100098)
(279, 1.131989598274231)
(280, 1.1065621376037598)
(281, 1.1037142276763916)
(282, 1.1152684688568115)
(283, 1.0981262922286987)
(284, 1.1338971853256226)
(285, 1.1134449243545532)
(286, 1.136093258857727)
(287, 1.1084197759628296)
(288, 1.0844320058822632)
(289, 1.103132724761963)
(290, 1.1201874017715454)
(291, 1.0894393920898438)
(292, 1.135046362876892)
(293, 1.0835868120193481)
(294, 1.0991870164871216)
(295, 1.1470069885253906)
(296, 1.115251898765564)
(297, 1.1201989650726318)
(298, 1.113740086555481)
(299, 1.0838284492492676)
(300, 1.1449358463287354)
Train Epoch: 0 [600/549367 (3%)]	Loss: 1.144936
(301, 1.104313850402832)
(302, 1.0961767435073853)
(303, 1.1500427722930908)
(304, 1.0938341617584229)
(305, 1.1249537467956543)
(306, 1.1053982973098755)
(307, 1.1266038417816162)
(308, 1.083477258682251)
(309, 1.0976603031158447)
(310, 1.1040592193603516)
(311, 1.094490647315979)
(312, 1.1174544095993042)
(313, 1.1026841402053833)
(314, 1.088139295578003)
(315, 1.060030221939087)
(316, 1.0845057964324951)
(317, 1.1424976587295532)
(318, 1.0922858715057373)
(319, 1.0952672958374023)
(320, 1.111704707145691)
(321, 1.1235382556915283)
(322, 1.116689920425415)
(323, 1.1027394533157349)
(324, 1.1052664518356323)
(325, 1.090316891670227)
(326, 1.1064690351486206)
(327, 1.1324325799942017)
(328, 1.0972341299057007)
(329, 1.0895202159881592)
(330, 1.097524642944336)
(331, 1.131706953048706)
(332, 1.062154769897461)
(333, 1.1246458292007446)
(334, 1.122564435005188)
(335, 1.127710223197937)
(336, 1.1102944612503052)
(337, 1.1335049867630005)
(338, 1.1249421834945679)
(339, 1.1133880615234375)
(340, 1.1321736574172974)
(341, 1.1123642921447754)
(342, 1.1135810613632202)
(343, 1.1289377212524414)
(344, 1.1090642213821411)
(345, 1.1207530498504639)
(346, 1.1378589868545532)
(347, 1.1232107877731323)
(348, 1.1220054626464844)
(349, 1.1234745979309082)
(350, 1.11249840259552)
(351, 1.114850401878357)
(352, 1.147027611732483)
(353, 1.110658884048462)
(354, 1.1268194913864136)
(355, 1.1039113998413086)
(356, 1.095951795578003)
(357, 1.1235147714614868)
(358, 1.0892980098724365)
(359, 1.1212533712387085)
(360, 1.0977550745010376)
(361, 1.0999038219451904)
(362, 1.1210933923721313)
(363, 1.1057881116867065)
(364, 1.1060668230056763)
(365, 1.0941420793533325)
(366, 1.0973575115203857)
(367, 1.1176618337631226)
(368, 1.1187046766281128)
(369, 1.102928638458252)
(370, 1.083823561668396)
(371, 1.1143178939819336)
(372, 1.0839738845825195)
(373, 1.0909477472305298)
(374, 1.1155927181243896)
(375, 1.0926226377487183)
(376, 1.1104079484939575)
(377, 1.1077721118927002)
(378, 1.0903209447860718)
(379, 1.1122901439666748)
(380, 1.1100670099258423)
(381, 1.115220069885254)
(382, 1.13106369972229)
(383, 1.0739567279815674)
(384, 1.0941905975341797)
(385, 1.1003525257110596)
(386, 1.1101306676864624)
(387, 1.0929831266403198)
(388, 1.0861544609069824)
(389, 1.1122899055480957)
(390, 1.111646294593811)
(391, 1.0971052646636963)
(392, 1.1046240329742432)
(393, 1.1275205612182617)
(394, 1.1184321641921997)
(395, 1.102248191833496)
(396, 1.1222084760665894)
(397, 1.1242852210998535)
(398, 1.1024467945098877)
(399, 1.1154993772506714)
(400, 1.1359583139419556)
Train Epoch: 0 [800/549367 (5%)]	Loss: 1.135958
(401, 1.066765308380127)
(402, 1.114025354385376)
(403, 1.0973149538040161)
(404, 1.0861213207244873)
(405, 1.1249792575836182)
(406, 1.0957465171813965)
(407, 1.092528223991394)
(408, 1.105546474456787)
(409, 1.0949815511703491)
(410, 1.0863678455352783)
(411, 1.118017554283142)
(412, 1.0924248695373535)
(413, 1.0892413854599)
(414, 1.0965839624404907)
(415, 1.1250920295715332)
(416, 1.0872938632965088)
(417, 1.127597451210022)
(418, 1.1139918565750122)
(419, 1.1038504838943481)
(420, 1.1231950521469116)
(421, 1.1232646703720093)
(422, 1.1142796277999878)
(423, 1.0991929769515991)
(424, 1.1094837188720703)
(425, 1.1048883199691772)
(426, 1.1250889301300049)
(427, 1.1031885147094727)
(428, 1.112641453742981)
(429, 1.115896463394165)
(430, 1.10038423538208)
(431, 1.1250598430633545)
(432, 1.1171655654907227)
(433, 1.107346534729004)
(434, 1.1017661094665527)
(435, 1.1291882991790771)
(436, 1.0973687171936035)
(437, 1.0970901250839233)
(438, 1.0954227447509766)
(439, 1.1103671789169312)
(440, 1.114451289176941)
(441, 1.1204560995101929)
(442, 1.0773683786392212)
(443, 1.1204938888549805)
(444, 1.1045211553573608)
(445, 1.1000901460647583)
(446, 1.1073763370513916)
(447, 1.1182000637054443)
(448, 1.1228914260864258)
(449, 1.0973618030548096)
(450, 1.1114740371704102)
(451, 1.1166582107543945)
(452, 1.133600115776062)
(453, 1.1072384119033813)
(454, 1.1295801401138306)
(455, 1.146427035331726)
(456, 1.1346409320831299)
(457, 1.1226428747177124)
(458, 1.0890709161758423)
(459, 1.105658769607544)
(460, 1.1024187803268433)
(461, 1.0861451625823975)
(462, 1.119587779045105)
(463, 1.1089625358581543)
(464, 1.1293275356292725)
(465, 1.1013081073760986)
(466, 1.1034773588180542)
(467, 1.1186432838439941)
(468, 1.0971124172210693)
(469, 1.1126638650894165)
(470, 1.130739688873291)
(471, 1.0914831161499023)
(472, 1.0940563678741455)
(473, 1.1037944555282593)
(474, 1.107994794845581)
(475, 1.0852516889572144)
(476, 1.1217855215072632)
(477, 1.1292144060134888)
(478, 1.1007741689682007)
(479, 1.0963339805603027)
(480, 1.10516357421875)
(481, 1.1157617568969727)
(482, 1.11527681350708)
(483, 1.1071776151657104)
(484, 1.0744365453720093)
(485, 1.1155139207839966)
(486, 1.0814697742462158)
(487, 1.1121093034744263)
(488, 1.1188002824783325)
(489, 1.1098390817642212)
(490, 1.118167757987976)
(491, 1.092047929763794)
(492, 1.0862840414047241)
(493, 1.0942660570144653)
(494, 1.1167124509811401)
(495, 1.1103225946426392)
(496, 1.0686848163604736)
(497, 1.1406347751617432)
(498, 1.1256399154663086)
(499, 1.0939174890518188)
(500, 1.0901342630386353)
Train Epoch: 0 [1000/549367 (6%)]	Loss: 1.090134
(501, 1.0781548023223877)
(502, 1.0991036891937256)
(503, 1.10138738155365)
(504, 1.0961755514144897)
(505, 1.0844123363494873)
(506, 1.0958493947982788)
(507, 1.1036146879196167)
(508, 1.1002377271652222)
(509, 1.1123387813568115)
(510, 1.1159814596176147)
(511, 1.1021591424942017)
(512, 1.106701135635376)
(513, 1.1159265041351318)
(514, 1.1041508913040161)
(515, 1.1191425323486328)
(516, 1.0938845872879028)
(517, 1.098196268081665)
(518, 1.0763896703720093)
(519, 1.0949180126190186)
(520, 1.0818073749542236)
(521, 1.0993784666061401)
(522, 1.1211494207382202)
(523, 1.0998231172561646)
(524, 1.0963188409805298)
(525, 1.10933518409729)
(526, 1.1163963079452515)
(527, 1.1306198835372925)
(528, 1.1374478340148926)
(529, 1.1075034141540527)
(530, 1.1278815269470215)
(531, 1.1230905055999756)
(532, 1.0949674844741821)
(533, 1.097090244293213)
(534, 1.1146163940429688)
(535, 1.107934832572937)
(536, 1.0938650369644165)
(537, 1.097504734992981)
(538, 1.088078498840332)
(539, 1.0934938192367554)
(540, 1.1253825426101685)
(541, 1.1092725992202759)
(542, 1.0852961540222168)
(543, 1.1072229146957397)
(544, 1.099230408668518)
(545, 1.1218397617340088)
(546, 1.1034533977508545)
(547, 1.1116710901260376)
(548, 1.0986272096633911)
(549, 1.083980679512024)
(550, 1.1119012832641602)
(551, 1.0928378105163574)
(552, 1.1233525276184082)
(553, 1.1261709928512573)
(554, 1.1382384300231934)
(555, 1.1083520650863647)
(556, 1.0846142768859863)
(557, 1.1036250591278076)
(558, 1.1165955066680908)
(559, 1.108618140220642)
(560, 1.078302264213562)
(561, 1.1350407600402832)
(562, 1.1028684377670288)
(563, 1.1186214685440063)
(564, 1.0816353559494019)
(565, 1.1063975095748901)
(566, 1.0846718549728394)
(567, 1.108069658279419)
(568, 1.1149346828460693)
(569, 1.1005685329437256)
(570, 1.0960173606872559)
(571, 1.0893315076828003)
(572, 1.0930589437484741)
(573, 1.1033073663711548)
(574, 1.0967237949371338)
(575, 1.1051123142242432)
(576, 1.1224242448806763)
(577, 1.1079202890396118)
(578, 1.1108468770980835)
(579, 1.0969431400299072)
(580, 1.087207317352295)
(581, 1.090522289276123)
(582, 1.097744107246399)
(583, 1.1167941093444824)
(584, 1.1170756816864014)
(585, 1.0901482105255127)
(586, 1.1034106016159058)
(587, 1.1134929656982422)
(588, 1.0891766548156738)
(589, 1.1019355058670044)
(590, 1.1274713277816772)
(591, 1.0976841449737549)
(592, 1.104012370109558)
(593, 1.0942336320877075)
(594, 1.1009645462036133)
(595, 1.1087102890014648)
(596, 1.095075249671936)
(597, 1.1027430295944214)
(598, 1.1114850044250488)
(599, 1.109114408493042)
(600, 1.1167882680892944)
Train Epoch: 0 [1200/549367 (7%)]	Loss: 1.116788
(601, 1.0954607725143433)
(602, 1.1010538339614868)
(603, 1.0895227193832397)
(604, 1.0915017127990723)
(605, 1.0973562002182007)
(606, 1.1159653663635254)
(607, 1.082558274269104)
(608, 1.106581687927246)
(609, 1.1154998540878296)
(610, 1.090361475944519)
(611, 1.1015321016311646)
(612, 1.088860034942627)
(613, 1.1076494455337524)
(614, 1.0954198837280273)
(615, 1.1002914905548096)
(616, 1.1010487079620361)
(617, 1.095871090888977)
(618, 1.1068075895309448)
(619, 1.0924956798553467)
(620, 1.1216686964035034)
(621, 1.1056627035140991)
(622, 1.1044609546661377)
(623, 1.0807197093963623)
(624, 1.0971897840499878)
(625, 1.0987943410873413)
(626, 1.1028656959533691)
(627, 1.1209369897842407)
(628, 1.0966920852661133)
(629, 1.1074203252792358)
(630, 1.1029804944992065)
(631, 1.1032581329345703)
(632, 1.0989603996276855)
(633, 1.112924575805664)
(634, 1.1061933040618896)
(635, 1.1336584091186523)
(636, 1.1111485958099365)
(637, 1.1048632860183716)
(638, 1.1022474765777588)
(639, 1.1213356256484985)
(640, 1.0937232971191406)
(641, 1.0920426845550537)
(642, 1.1080716848373413)
(643, 1.0981123447418213)
(644, 1.1068733930587769)
(645, 1.0925580263137817)
(646, 1.1076321601867676)
(647, 1.1008999347686768)
(648, 1.095353126525879)
(649, 1.092427372932434)
(650, 1.1070283651351929)
(651, 1.1069467067718506)
(652, 1.1121091842651367)
(653, 1.1074917316436768)
(654, 1.0867950916290283)
(655, 1.1057904958724976)
(656, 1.0964736938476562)
(657, 1.1260874271392822)
(658, 1.1084438562393188)
(659, 1.1068841218948364)
(660, 1.1211106777191162)
(661, 1.0915019512176514)
(662, 1.0845072269439697)
(663, 1.1010633707046509)
(664, 1.082765817642212)
(665, 1.1023441553115845)
(666, 1.1156318187713623)
(667, 1.1062750816345215)
(668, 1.1001465320587158)
(669, 1.1120281219482422)
(670, 1.1006543636322021)
(671, 1.1193081140518188)
(672, 1.1038267612457275)
(673, 1.0922361612319946)
(674, 1.1159698963165283)
(675, 1.0982279777526855)
(676, 1.1098976135253906)
(677, 1.1167371273040771)
(678, 1.1106511354446411)
(679, 1.1014347076416016)
(680, 1.0903376340866089)
(681, 1.0898165702819824)
(682, 1.115897536277771)
(683, 1.1047662496566772)
(684, 1.1066433191299438)
(685, 1.100649118423462)
(686, 1.1242496967315674)
(687, 1.1089937686920166)
(688, 1.100123643875122)
(689, 1.0963141918182373)
(690, 1.1126792430877686)
(691, 1.0873832702636719)
(692, 1.1016496419906616)
(693, 1.1098241806030273)
(694, 1.079656720161438)
(695, 1.1145845651626587)
(696, 1.1129456758499146)
(697, 1.1135683059692383)
(698, 1.0936670303344727)
(699, 1.1181707382202148)
(700, 1.0993223190307617)
Train Epoch: 0 [1400/549367 (8%)]	Loss: 1.099322
(701, 1.1040630340576172)
(702, 1.1021981239318848)
(703, 1.1264630556106567)
(704, 1.1152615547180176)
(705, 1.117467999458313)
(706, 1.0995843410491943)
(707, 1.1120100021362305)
(708, 1.1100306510925293)
(709, 1.1130404472351074)
(710, 1.0947622060775757)
(711, 1.1331040859222412)
(712, 1.1017839908599854)
(713, 1.1161463260650635)
(714, 1.109540581703186)
(715, 1.1014106273651123)
(716, 1.0773576498031616)
(717, 1.085522174835205)
(718, 1.101372241973877)
(719, 1.0948740243911743)
(720, 1.106053113937378)
(721, 1.0983905792236328)
(722, 1.0995099544525146)
(723, 1.0835336446762085)
(724, 1.106476902961731)
(725, 1.0876529216766357)
(726, 1.0946599245071411)
(727, 1.1051197052001953)
(728, 1.097109079360962)
(729, 1.0989254713058472)
(730, 1.0932508707046509)
(731, 1.1116337776184082)
(732, 1.1271765232086182)
(733, 1.106345534324646)
(734, 1.109714150428772)
(735, 1.1056487560272217)
(736, 1.1026909351348877)
(737, 1.0946717262268066)
(738, 1.0939024686813354)
(739, 1.1070722341537476)
(740, 1.1125801801681519)
(741, 1.1024725437164307)
(742, 1.1073411703109741)
(743, 1.1201483011245728)
(744, 1.0968397855758667)
(745, 1.099656581878662)
(746, 1.100862979888916)
(747, 1.115063190460205)
(748, 1.097228765487671)
(749, 1.097756266593933)
(750, 1.1003690958023071)
(751, 1.107900619506836)
(752, 1.1077603101730347)
(753, 1.091242790222168)
(754, 1.1035315990447998)
(755, 1.0923385620117188)
(756, 1.09883451461792)
(757, 1.0903780460357666)
(758, 1.0853972434997559)
(759, 1.1069908142089844)
(760, 1.076340675354004)
(761, 1.1084345579147339)
(762, 1.0991766452789307)
(763, 1.1050294637680054)
(764, 1.1075284481048584)
(765, 1.0944844484329224)
(766, 1.097976803779602)
(767, 1.095578908920288)
(768, 1.1054058074951172)
(769, 1.0995920896530151)
(770, 1.1046984195709229)
(771, 1.111811637878418)
(772, 1.088027834892273)
(773, 1.1038414239883423)
(774, 1.1048884391784668)
(775, 1.0921064615249634)
(776, 1.1171003580093384)
(777, 1.1101552248001099)
(778, 1.1041314601898193)
(779, 1.118054986000061)
(780, 1.1214244365692139)
(781, 1.1080667972564697)
(782, 1.0985311269760132)
(783, 1.1169730424880981)
(784, 1.112123966217041)
(785, 1.098132610321045)
(786, 1.1123265027999878)
(787, 1.0972530841827393)
(788, 1.1044224500656128)
(789, 1.0927579402923584)
(790, 1.10588800907135)
(791, 1.1126952171325684)
(792, 1.1000628471374512)
(793, 1.0980373620986938)
(794, 1.0951848030090332)
(795, 1.0726627111434937)
(796, 1.0939286947250366)
(797, 1.100961446762085)
(798, 1.0920747518539429)
(799, 1.1066210269927979)
(800, 1.112828016281128)
Train Epoch: 0 [1600/549367 (9%)]	Loss: 1.112828
(801, 1.1094473600387573)
(802, 1.0969914197921753)
(803, 1.114410400390625)
(804, 1.098389744758606)
(805, 1.0991562604904175)
(806, 1.1228461265563965)
(807, 1.0894718170166016)
(808, 1.1177092790603638)
(809, 1.1033862829208374)
(810, 1.0982608795166016)
(811, 1.1058205366134644)
(812, 1.1103492975234985)
(813, 1.0975258350372314)
(814, 1.1000304222106934)
(815, 1.0975677967071533)
(816, 1.1026922464370728)
(817, 1.1097447872161865)
(818, 1.0957735776901245)
(819, 1.0975583791732788)
(820, 1.095482349395752)
(821, 1.1041910648345947)
(822, 1.0968329906463623)
(823, 1.1079012155532837)
(824, 1.0969773530960083)
(825, 1.0842689275741577)
(826, 1.0958257913589478)
(827, 1.095636010169983)
(828, 1.1038793325424194)
(829, 1.1202155351638794)
(830, 1.0850629806518555)
(831, 1.1190963983535767)
(832, 1.1103317737579346)
(833, 1.1062806844711304)
(834, 1.0985337495803833)
(835, 1.102770447731018)
(836, 1.1044061183929443)
(837, 1.0981491804122925)
(838, 1.1030595302581787)
(839, 1.1029114723205566)
(840, 1.0823551416397095)
(841, 1.0988740921020508)
(842, 1.0844637155532837)
(843, 1.101833462715149)
(844, 1.090761423110962)
(845, 1.0893378257751465)
(846, 1.090496301651001)
(847, 1.1021497249603271)
(848, 1.1130259037017822)
(849, 1.1008373498916626)
(850, 1.0893635749816895)
(851, 1.1157468557357788)
(852, 1.106711745262146)
(853, 1.1255273818969727)
(854, 1.0977171659469604)
(855, 1.095860481262207)
(856, 1.1002299785614014)
(857, 1.0885635614395142)
(858, 1.1058709621429443)
(859, 1.099290132522583)
(860, 1.1032004356384277)
(861, 1.1114590167999268)
(862, 1.1000871658325195)
(863, 1.1024017333984375)
(864, 1.1039503812789917)
(865, 1.0965185165405273)
(866, 1.0920829772949219)
(867, 1.1129379272460938)
(868, 1.0830827951431274)
(869, 1.0823906660079956)
(870, 1.07755446434021)
(871, 1.0960663557052612)
(872, 1.0913032293319702)
(873, 1.111531376838684)
(874, 1.0963420867919922)
(875, 1.1192212104797363)
(876, 1.0969544649124146)
(877, 1.100084900856018)
(878, 1.101211667060852)
(879, 1.1195813417434692)
(880, 1.107069730758667)
(881, 1.0906779766082764)
(882, 1.084315538406372)
(883, 1.0921088457107544)
(884, 1.098971962928772)
(885, 1.0850203037261963)
(886, 1.1049399375915527)
(887, 1.0957064628601074)
(888, 1.1011409759521484)
(889, 1.1129544973373413)
(890, 1.1092665195465088)
(891, 1.0820732116699219)
(892, 1.1000432968139648)
(893, 1.1010987758636475)
(894, 1.1171845197677612)
(895, 1.0854966640472412)
(896, 1.0998237133026123)
(897, 1.10387122631073)
(898, 1.0937365293502808)
(899, 1.0959465503692627)
(900, 1.1013243198394775)
Train Epoch: 0 [1800/549367 (10%)]	Loss: 1.101324
(901, 1.1125926971435547)
(902, 1.0996737480163574)
(903, 1.1088886260986328)
(904, 1.0914212465286255)
(905, 1.1235978603363037)
(906, 1.0977096557617188)
(907, 1.0929896831512451)
(908, 1.1036931276321411)
(909, 1.1074923276901245)
(910, 1.119510531425476)
(911, 1.114942193031311)
(912, 1.1086039543151855)
(913, 1.0872207880020142)
(914, 1.0950862169265747)
(915, 1.0899909734725952)
(916, 1.1044541597366333)
(917, 1.1009336709976196)
(918, 1.1129465103149414)
(919, 1.1146968603134155)
(920, 1.1082032918930054)
(921, 1.1060242652893066)
(922, 1.1032590866088867)
(923, 1.1107585430145264)
(924, 1.0801573991775513)
(925, 1.0964255332946777)
(926, 1.1261972188949585)
(927, 1.0929625034332275)
(928, 1.1114288568496704)
(929, 1.10793936252594)
(930, 1.1117922067642212)
(931, 1.0785454511642456)
(932, 1.1120597124099731)
(933, 1.105022668838501)
(934, 1.1117867231369019)
(935, 1.0999794006347656)
(936, 1.0970046520233154)
(937, 1.1095483303070068)
(938, 1.1148406267166138)
(939, 1.1023565530776978)
(940, 1.1076531410217285)
(941, 1.1084270477294922)
(942, 1.1122864484786987)
(943, 1.0980900526046753)
(944, 1.099122166633606)
(945, 1.1003223657608032)
(946, 1.0931216478347778)
(947, 1.0921505689620972)
(948, 1.0988540649414062)
(949, 1.0976221561431885)
(950, 1.0893224477767944)
(951, 1.0938191413879395)
(952, 1.1084805727005005)
(953, 1.1254184246063232)
(954, 1.1135282516479492)
(955, 1.092018961906433)
(956, 1.093013048171997)
(957, 1.1088078022003174)
(958, 1.1051254272460938)
(959, 1.1060729026794434)
(960, 1.1044361591339111)
(961, 1.1085524559020996)
(962, 1.0960034132003784)
(963, 1.1033791303634644)
(964, 1.1137120723724365)
(965, 1.1125284433364868)
(966, 1.110003113746643)
(967, 1.1022610664367676)
(968, 1.1099352836608887)
(969, 1.0984562635421753)
(970, 1.097302794456482)
(971, 1.0898628234863281)
(972, 1.0918190479278564)
(973, 1.1061499118804932)
(974, 1.1068998575210571)
(975, 1.1020524501800537)
(976, 1.0982401371002197)
(977, 1.1078611612319946)
(978, 1.1003175973892212)
(979, 1.1056896448135376)
(980, 1.1167056560516357)
(981, 1.0940790176391602)
(982, 1.1027995347976685)
(983, 1.1098246574401855)
(984, 1.1069955825805664)
(985, 1.0986088514328003)
(986, 1.1043816804885864)
(987, 1.0815110206604004)
(988, 1.0950942039489746)
(989, 1.1058768033981323)
(990, 1.0971484184265137)
(991, 1.1073225736618042)
(992, 1.1182008981704712)
(993, 1.1020557880401611)
(994, 1.0976276397705078)
(995, 1.1104878187179565)
(996, 1.0951108932495117)
(997, 1.115156650543213)
(998, 1.1078133583068848)
(999, 1.1198136806488037)
(1000, 1.0935642719268799)
Train Epoch: 0 [2000/549367 (12%)]	Loss: 1.093564
(1001, 1.0880650281906128)
(1002, 1.0927118062973022)
(1003, 1.0890157222747803)
(1004, 1.0909956693649292)
(1005, 1.106307864189148)
(1006, 1.0943578481674194)
(1007, 1.0983951091766357)
(1008, 1.0880638360977173)
(1009, 1.1113545894622803)
(1010, 1.1019854545593262)
(1011, 1.100112795829773)
(1012, 1.120210886001587)
(1013, 1.0909152030944824)
(1014, 1.121175765991211)
(1015, 1.1046994924545288)
(1016, 1.1022388935089111)
(1017, 1.0924071073532104)
(1018, 1.0954549312591553)
(1019, 1.0966800451278687)
(1020, 1.1014965772628784)
(1021, 1.1091731786727905)
(1022, 1.111024022102356)
(1023, 1.102697730064392)
(1024, 1.1109035015106201)
(1025, 1.09538733959198)
(1026, 1.1044704914093018)
(1027, 1.101658821105957)
(1028, 1.1037883758544922)
(1029, 1.0950133800506592)
(1030, 1.1015068292617798)
(1031, 1.1071195602416992)
(1032, 1.0927537679672241)
(1033, 1.1108136177062988)
(1034, 1.0999022722244263)
(1035, 1.1025166511535645)
(1036, 1.10697340965271)
(1037, 1.0844626426696777)
(1038, 1.0988478660583496)
(1039, 1.108701467514038)
(1040, 1.1192128658294678)
(1041, 1.105231761932373)
(1042, 1.0880608558654785)
(1043, 1.1036126613616943)
(1044, 1.1078286170959473)
(1045, 1.1045897006988525)
(1046, 1.0988049507141113)
(1047, 1.1141571998596191)
(1048, 1.0960761308670044)
(1049, 1.0994805097579956)
(1050, 1.109782099723816)
(1051, 1.092301368713379)
(1052, 1.0945372581481934)
(1053, 1.0932503938674927)
(1054, 1.1078366041183472)
(1055, 1.0975074768066406)
(1056, 1.0967144966125488)
(1057, 1.103386640548706)
(1058, 1.1019831895828247)
(1059, 1.1006702184677124)
(1060, 1.1015843152999878)
(1061, 1.1039161682128906)
(1062, 1.099829077720642)
(1063, 1.1076651811599731)
(1064, 1.1011415719985962)
(1065, 1.0918257236480713)
(1066, 1.1033176183700562)
(1067, 1.0985932350158691)
(1068, 1.0962132215499878)
(1069, 1.0945847034454346)
(1070, 1.1067806482315063)
(1071, 1.1101268529891968)
(1072, 1.102372407913208)
(1073, 1.1046541929244995)
(1074, 1.1130189895629883)
(1075, 1.1032981872558594)
(1076, 1.1092785596847534)
(1077, 1.1048080921173096)
(1078, 1.0984867811203003)
(1079, 1.1131776571273804)
(1080, 1.0960675477981567)
(1081, 1.1015987396240234)
(1082, 1.1099015474319458)
(1083, 1.1056902408599854)
(1084, 1.10433030128479)
(1085, 1.101768136024475)
(1086, 1.098768711090088)
(1087, 1.0998293161392212)
(1088, 1.099109411239624)
(1089, 1.0956628322601318)
(1090, 1.092435598373413)
(1091, 1.1050472259521484)
(1092, 1.0980807542800903)
(1093, 1.1033316850662231)
(1094, 1.097756266593933)
(1095, 1.1027828454971313)
(1096, 1.1058851480484009)
(1097, 1.087110161781311)
(1098, 1.109977126121521)
(1099, 1.1052480936050415)
(1100, 1.1030356884002686)
Train Epoch: 0 [2200/549367 (13%)]	Loss: 1.103036
(1101, 1.0956965684890747)
(1102, 1.104889154434204)
(1103, 1.1054027080535889)
(1104, 1.1087946891784668)
(1105, 1.1086218357086182)
(1106, 1.115851640701294)
(1107, 1.1008226871490479)
(1108, 1.1068490743637085)
(1109, 1.1006443500518799)
(1110, 1.1035499572753906)
(1111, 1.0961551666259766)
(1112, 1.1043095588684082)
(1113, 1.103590726852417)
(1114, 1.1046104431152344)
(1115, 1.1038246154785156)
(1116, 1.0990469455718994)
(1117, 1.1040345430374146)
(1118, 1.096432089805603)
(1119, 1.0944682359695435)
(1120, 1.1160269975662231)
(1121, 1.1006871461868286)
(1122, 1.0997962951660156)
(1123, 1.103604793548584)
(1124, 1.0961204767227173)
(1125, 1.1019853353500366)
(1126, 1.0855042934417725)
(1127, 1.0984879732131958)
(1128, 1.1078524589538574)
(1129, 1.0973471403121948)
(1130, 1.0862243175506592)
(1131, 1.1048365831375122)
(1132, 1.1038203239440918)
(1133, 1.110918402671814)
(1134, 1.0920484066009521)
(1135, 1.096757411956787)
(1136, 1.0914089679718018)
(1137, 1.1041278839111328)
(1138, 1.1002748012542725)
(1139, 1.095514178276062)
(1140, 1.1027441024780273)
(1141, 1.1042234897613525)
(1142, 1.1096253395080566)
(1143, 1.0989362001419067)
(1144, 1.1084331274032593)
(1145, 1.1128188371658325)
(1146, 1.101784110069275)
(1147, 1.0986895561218262)
(1148, 1.1041669845581055)
(1149, 1.1098999977111816)
(1150, 1.094364881515503)
(1151, 1.0901840925216675)
(1152, 1.116926670074463)
(1153, 1.1146175861358643)
(1154, 1.0969774723052979)
(1155, 1.1063508987426758)
(1156, 1.1104105710983276)
(1157, 1.098462462425232)
(1158, 1.1073788404464722)
(1159, 1.0951091051101685)
(1160, 1.0868241786956787)
(1161, 1.0999727249145508)
(1162, 1.1086463928222656)
(1163, 1.103347659111023)
(1164, 1.0986781120300293)
(1165, 1.0843802690505981)
(1166, 1.1004283428192139)
(1167, 1.0945851802825928)
(1168, 1.0983372926712036)
(1169, 1.1007360219955444)
(1170, 1.0948411226272583)
(1171, 1.0935057401657104)
(1172, 1.0935055017471313)
(1173, 1.100159764289856)
(1174, 1.0991464853286743)
(1175, 1.1066513061523438)
(1176, 1.0999504327774048)
(1177, 1.0933115482330322)
(1178, 1.103600263595581)
(1179, 1.1140350103378296)
(1180, 1.1014968156814575)
(1181, 1.09864342212677)
(1182, 1.08796226978302)
(1183, 1.1052583456039429)
(1184, 1.1004817485809326)
(1185, 1.087425708770752)
(1186, 1.1052576303482056)
(1187, 1.0989842414855957)
(1188, 1.0989642143249512)
(1189, 1.0967704057693481)
(1190, 1.1148306131362915)
(1191, 1.1062240600585938)
(1192, 1.107822060585022)
(1193, 1.1099344491958618)
(1194, 1.094079613685608)
(1195, 1.0978593826293945)
(1196, 1.0995675325393677)
(1197, 1.1056269407272339)
(1198, 1.1075491905212402)
(1199, 1.1024606227874756)
(1200, 1.1122492551803589)
Train Epoch: 0 [2400/549367 (14%)]	Loss: 1.112249
(1201, 1.0921058654785156)
(1202, 1.0998520851135254)
(1203, 1.1068495512008667)
(1204, 1.089985966682434)
(1205, 1.0916876792907715)
(1206, 1.1130013465881348)
(1207, 1.09534752368927)
(1208, 1.1141256093978882)
(1209, 1.090295433998108)
(1210, 1.0990571975708008)
(1211, 1.1012638807296753)
(1212, 1.0921622514724731)
(1213, 1.1119786500930786)
(1214, 1.0985344648361206)
(1215, 1.094573736190796)
(1216, 1.0967464447021484)
(1217, 1.0860230922698975)
(1218, 1.0968618392944336)
(1219, 1.0982862710952759)
(1220, 1.115224003791809)
(1221, 1.1043262481689453)
(1222, 1.1102869510650635)
(1223, 1.0930440425872803)
(1224, 1.0871745347976685)
(1225, 1.088993787765503)
(1226, 1.075650691986084)
(1227, 1.0969693660736084)
(1228, 1.1032295227050781)
(1229, 1.0970221757888794)
(1230, 1.0933321714401245)
(1231, 1.1014008522033691)
(1232, 1.102249264717102)
(1233, 1.094913125038147)
(1234, 1.0918463468551636)
(1235, 1.086485505104065)
(1236, 1.0954186916351318)
(1237, 1.1012457609176636)
(1238, 1.1117162704467773)
(1239, 1.0855764150619507)
(1240, 1.116186261177063)
(1241, 1.1046178340911865)
(1242, 1.1125314235687256)
(1243, 1.0967506170272827)
(1244, 1.1103445291519165)
(1245, 1.1110562086105347)
(1246, 1.0973116159439087)
(1247, 1.0998830795288086)
(1248, 1.1154041290283203)
(1249, 1.0951110124588013)
(1250, 1.1004879474639893)
(1251, 1.1133450269699097)
(1252, 1.0981507301330566)
(1253, 1.095622181892395)
(1254, 1.100529670715332)
(1255, 1.1006470918655396)
(1256, 1.0955580472946167)
(1257, 1.0812510251998901)
(1258, 1.096040964126587)
(1259, 1.107501745223999)
(1260, 1.1074179410934448)
(1261, 1.0885804891586304)
(1262, 1.0938388109207153)
(1263, 1.0921961069107056)
(1264, 1.0932179689407349)
(1265, 1.1124744415283203)
(1266, 1.1010175943374634)
(1267, 1.1066768169403076)
(1268, 1.0991666316986084)
(1269, 1.1045407056808472)
(1270, 1.1215404272079468)
(1271, 1.1099789142608643)
(1272, 1.1010617017745972)
(1273, 1.1085458993911743)
(1274, 1.1015808582305908)
(1275, 1.0890177488327026)
(1276, 1.1012399196624756)
(1277, 1.105393409729004)
(1278, 1.1011098623275757)
(1279, 1.0957032442092896)
(1280, 1.1019624471664429)
(1281, 1.0967212915420532)
(1282, 1.1010245084762573)
(1283, 1.1050732135772705)
(1284, 1.1033939123153687)
(1285, 1.1038398742675781)
(1286, 1.0978814363479614)
(1287, 1.106724739074707)
(1288, 1.1010875701904297)
(1289, 1.0834664106369019)
(1290, 1.1017675399780273)
(1291, 1.0801290273666382)
(1292, 1.114457130432129)
(1293, 1.103323221206665)
(1294, 1.1102683544158936)
(1295, 1.0970804691314697)
(1296, 1.0994415283203125)
(1297, 1.1028045415878296)
(1298, 1.1037639379501343)
(1299, 1.1149888038635254)
(1300, 1.090512752532959)
Train Epoch: 0 [2600/549367 (15%)]	Loss: 1.090513
(1301, 1.1064609289169312)
(1302, 1.100226640701294)
(1303, 1.093772292137146)
(1304, 1.088942050933838)
(1305, 1.1093724966049194)
(1306, 1.1076560020446777)
(1307, 1.0951509475708008)
(1308, 1.0946002006530762)
(1309, 1.1082332134246826)
(1310, 1.0990397930145264)
(1311, 1.1070176362991333)
(1312, 1.1005396842956543)
(1313, 1.0907833576202393)
(1314, 1.104962706565857)
(1315, 1.0948151350021362)
(1316, 1.0989514589309692)
(1317, 1.1083492040634155)
(1318, 1.0923632383346558)
(1319, 1.0959173440933228)
(1320, 1.0900311470031738)
(1321, 1.120666742324829)
(1322, 1.0904103517532349)
(1323, 1.1005487442016602)
(1324, 1.085440993309021)
(1325, 1.0889934301376343)
(1326, 1.1076074838638306)
(1327, 1.108744740486145)
(1328, 1.1026250123977661)
(1329, 1.090315341949463)
(1330, 1.109639286994934)
(1331, 1.10419499874115)
(1332, 1.0894821882247925)
(1333, 1.1044514179229736)
(1334, 1.10050630569458)
(1335, 1.1063131093978882)
(1336, 1.0804888010025024)
(1337, 1.1043697595596313)
(1338, 1.0913585424423218)
(1339, 1.1041191816329956)
(1340, 1.1041871309280396)
(1341, 1.0880416631698608)
(1342, 1.0991090536117554)
(1343, 1.0976645946502686)
(1344, 1.0979052782058716)
(1345, 1.106621503829956)
(1346, 1.1017149686813354)
(1347, 1.100141167640686)
(1348, 1.09185791015625)
(1349, 1.1044514179229736)
(1350, 1.1047691106796265)
(1351, 1.1013574600219727)
(1352, 1.1019561290740967)
(1353, 1.1044367551803589)
(1354, 1.119615912437439)
(1355, 1.113851547241211)
(1356, 1.0923515558242798)
(1357, 1.1021385192871094)
(1358, 1.0956389904022217)
(1359, 1.0980359315872192)
(1360, 1.1072204113006592)
(1361, 1.0993703603744507)
(1362, 1.1032369136810303)
(1363, 1.1014697551727295)
(1364, 1.1084215641021729)
(1365, 1.0981675386428833)
(1366, 1.1091023683547974)
(1367, 1.0958930253982544)
(1368, 1.0958510637283325)
(1369, 1.1039797067642212)
(1370, 1.0777195692062378)
(1371, 1.0978752374649048)
(1372, 1.1062698364257812)
(1373, 1.1120885610580444)
(1374, 1.0928499698638916)
(1375, 1.1043988466262817)
(1376, 1.1018211841583252)
(1377, 1.0751501321792603)
(1378, 1.0956064462661743)
(1379, 1.0907390117645264)
(1380, 1.0964895486831665)
(1381, 1.1083415746688843)
(1382, 1.099123239517212)
(1383, 1.1206245422363281)
(1384, 1.105544924736023)
(1385, 1.1095211505889893)
(1386, 1.0937480926513672)
(1387, 1.0966740846633911)
(1388, 1.1045020818710327)
(1389, 1.0976296663284302)
(1390, 1.1149916648864746)
(1391, 1.0936459302902222)
(1392, 1.0927878618240356)
(1393, 1.109640121459961)
(1394, 1.086829662322998)
(1395, 1.0991957187652588)
(1396, 1.1005710363388062)
(1397, 1.0995808839797974)
(1398, 1.0973021984100342)
(1399, 1.0996203422546387)
(1400, 1.1104463338851929)
Train Epoch: 0 [2800/549367 (16%)]	Loss: 1.110446
(1401, 1.1220561265945435)
(1402, 1.0894192457199097)
(1403, 1.1055136919021606)
(1404, 1.0823034048080444)
(1405, 1.0796650648117065)
(1406, 1.1232562065124512)
(1407, 1.0946545600891113)
(1408, 1.1064541339874268)
(1409, 1.0959258079528809)
(1410, 1.0985007286071777)
(1411, 1.100435495376587)
(1412, 1.1017943620681763)
(1413, 1.110089898109436)
(1414, 1.103869915008545)
(1415, 1.1017669439315796)
(1416, 1.0937899351119995)
(1417, 1.0827412605285645)
(1418, 1.0992505550384521)
(1419, 1.1056874990463257)
(1420, 1.0890183448791504)
(1421, 1.0871477127075195)
(1422, 1.0749223232269287)
(1423, 1.0930317640304565)
(1424, 1.0993119478225708)
(1425, 1.096636176109314)
(1426, 1.0904300212860107)
(1427, 1.0985616445541382)
(1428, 1.1112000942230225)
(1429, 1.0970523357391357)
(1430, 1.098064661026001)
(1431, 1.0742096900939941)
(1432, 1.107534646987915)
(1433, 1.1098475456237793)
(1434, 1.0961830615997314)
(1435, 1.1007757186889648)
(1436, 1.0998167991638184)
(1437, 1.0926555395126343)
(1438, 1.1043919324874878)
(1439, 1.0879600048065186)
(1440, 1.1072174310684204)
(1441, 1.118652582168579)
(1442, 1.0968635082244873)
(1443, 1.114557147026062)
(1444, 1.1015410423278809)
(1445, 1.1166185140609741)
(1446, 1.0897225141525269)
(1447, 1.1098252534866333)
(1448, 1.1074244976043701)
(1449, 1.0936979055404663)
(1450, 1.0921436548233032)
(1451, 1.1001561880111694)
(1452, 1.1015523672103882)
(1453, 1.0946084260940552)
(1454, 1.1103582382202148)
(1455, 1.1031745672225952)
(1456, 1.1107202768325806)
(1457, 1.1042485237121582)
(1458, 1.0963484048843384)
(1459, 1.1024460792541504)
(1460, 1.0941741466522217)
(1461, 1.0992064476013184)
(1462, 1.0953506231307983)
(1463, 1.1120471954345703)
(1464, 1.108020305633545)
(1465, 1.1117278337478638)
(1466, 1.089455008506775)
(1467, 1.0939451456069946)
(1468, 1.1177747249603271)
(1469, 1.093292474746704)
(1470, 1.1077086925506592)
(1471, 1.0869812965393066)
(1472, 1.0869548320770264)
(1473, 1.117893099784851)
(1474, 1.1081080436706543)
(1475, 1.088389277458191)
(1476, 1.0781986713409424)
(1477, 1.1061960458755493)
(1478, 1.0996028184890747)
(1479, 1.093444585800171)
(1480, 1.0842286348342896)
(1481, 1.1045640707015991)
(1482, 1.1085506677627563)
(1483, 1.098827838897705)
(1484, 1.1129393577575684)
(1485, 1.0987515449523926)
(1486, 1.1026475429534912)
(1487, 1.0890315771102905)
(1488, 1.1031290292739868)
(1489, 1.099655270576477)
(1490, 1.093719720840454)
(1491, 1.1053853034973145)
(1492, 1.1048928499221802)
(1493, 1.100905179977417)
(1494, 1.097649097442627)
(1495, 1.0989211797714233)
(1496, 1.0933568477630615)
(1497, 1.1065804958343506)
(1498, 1.0956882238388062)
(1499, 1.1052868366241455)
(1500, 1.1034374237060547)
Train Epoch: 0 [3000/549367 (17%)]	Loss: 1.103437
(1501, 1.1128509044647217)
(1502, 1.0953489542007446)
(1503, 1.0863738059997559)
(1504, 1.1100996732711792)
(1505, 1.093479871749878)
(1506, 1.0941027402877808)
(1507, 1.1038190126419067)
(1508, 1.1089155673980713)
(1509, 1.1044875383377075)
(1510, 1.0942925214767456)
(1511, 1.1129648685455322)
(1512, 1.1114829778671265)
(1513, 1.1032534837722778)
(1514, 1.1058882474899292)
(1515, 1.1164922714233398)
(1516, 1.1015957593917847)
(1517, 1.1014821529388428)
(1518, 1.102685809135437)
(1519, 1.1008377075195312)
(1520, 1.0904767513275146)
(1521, 1.1025245189666748)
(1522, 1.0989044904708862)
(1523, 1.108649730682373)
(1524, 1.0950125455856323)
(1525, 1.095840334892273)
(1526, 1.0980356931686401)
(1527, 1.1014643907546997)
(1528, 1.0900293588638306)
(1529, 1.0883010625839233)
(1530, 1.1053237915039062)
(1531, 1.0981924533843994)
(1532, 1.1030023097991943)
(1533, 1.090708613395691)
(1534, 1.0963605642318726)
(1535, 1.0867595672607422)
(1536, 1.0985209941864014)
(1537, 1.1011830568313599)
(1538, 1.0819947719573975)
(1539, 1.092515230178833)
(1540, 1.1151968240737915)
(1541, 1.091140627861023)
(1542, 1.1009749174118042)
(1543, 1.1039209365844727)
(1544, 1.1096287965774536)
(1545, 1.1055805683135986)
(1546, 1.1167033910751343)
(1547, 1.1031646728515625)
(1548, 1.0987191200256348)
(1549, 1.092239260673523)
(1550, 1.0913512706756592)
(1551, 1.1112070083618164)
(1552, 1.0944232940673828)
(1553, 1.1003124713897705)
(1554, 1.0989216566085815)
(1555, 1.1115857362747192)
(1556, 1.092366099357605)
(1557, 1.0998446941375732)
(1558, 1.0935156345367432)
(1559, 1.109276294708252)
(1560, 1.1068968772888184)
(1561, 1.1030139923095703)
(1562, 1.1057931184768677)
(1563, 1.0980418920516968)
(1564, 1.120119571685791)
(1565, 1.107560396194458)
(1566, 1.1012049913406372)
(1567, 1.0893654823303223)
(1568, 1.1058681011199951)
(1569, 1.1134381294250488)
(1570, 1.105837345123291)
(1571, 1.1150619983673096)
(1572, 1.1050381660461426)
(1573, 1.1097651720046997)
(1574, 1.1060497760772705)
(1575, 1.1006361246109009)
(1576, 1.0981742143630981)
(1577, 1.0946927070617676)
(1578, 1.0985431671142578)
(1579, 1.1095885038375854)
(1580, 1.0991538763046265)
(1581, 1.1061967611312866)
(1582, 1.1049954891204834)
(1583, 1.0922460556030273)
(1584, 1.0898747444152832)
(1585, 1.1112059354782104)
(1586, 1.0982595682144165)
(1587, 1.1003618240356445)
(1588, 1.1010808944702148)
(1589, 1.0963383913040161)
(1590, 1.1014139652252197)
(1591, 1.0947701930999756)
(1592, 1.1105271577835083)
(1593, 1.1049476861953735)
(1594, 1.0914769172668457)
(1595, 1.0942391157150269)
(1596, 1.109689712524414)
(1597, 1.1054476499557495)
(1598, 1.106335163116455)
(1599, 1.0976934432983398)
(1600, 1.1031678915023804)
Train Epoch: 0 [3200/549367 (19%)]	Loss: 1.103168
(1601, 1.1099119186401367)
(1602, 1.0962274074554443)
(1603, 1.1048901081085205)
(1604, 1.1016223430633545)
(1605, 1.102665901184082)
(1606, 1.104682445526123)
(1607, 1.0912691354751587)
(1608, 1.093186616897583)
(1609, 1.1071988344192505)
(1610, 1.1042672395706177)
(1611, 1.0982319116592407)
(1612, 1.1005737781524658)
(1613, 1.1109808683395386)
(1614, 1.101054310798645)
(1615, 1.091214895248413)
(1616, 1.0931923389434814)
(1617, 1.0917062759399414)
(1618, 1.0979208946228027)
(1619, 1.099494457244873)
(1620, 1.0940953493118286)
(1621, 1.105394721031189)
(1622, 1.09878671169281)
(1623, 1.1069161891937256)
(1624, 1.0927388668060303)
(1625, 1.0969481468200684)
(1626, 1.0950411558151245)
(1627, 1.0967999696731567)
(1628, 1.1043508052825928)
(1629, 1.1006083488464355)
(1630, 1.1050623655319214)
(1631, 1.1007282733917236)
(1632, 1.102264642715454)
(1633, 1.103467345237732)
(1634, 1.0987054109573364)
(1635, 1.1023274660110474)
(1636, 1.0954831838607788)
(1637, 1.1015522480010986)
(1638, 1.0952250957489014)
(1639, 1.1057301759719849)
(1640, 1.1086413860321045)
(1641, 1.098835825920105)
(1642, 1.104931116104126)
(1643, 1.109442949295044)
(1644, 1.1074579954147339)
(1645, 1.105818748474121)
(1646, 1.106234073638916)
(1647, 1.1055009365081787)
(1648, 1.0981624126434326)
(1649, 1.1038193702697754)
(1650, 1.1012903451919556)
(1651, 1.0993143320083618)
(1652, 1.108878493309021)
(1653, 1.099412202835083)
(1654, 1.1123201847076416)
(1655, 1.1012059450149536)
(1656, 1.09861159324646)
(1657, 1.0867507457733154)
(1658, 1.0962855815887451)
(1659, 1.0985404253005981)
(1660, 1.1025792360305786)
(1661, 1.1033207178115845)
(1662, 1.0892632007598877)
(1663, 1.099332332611084)
(1664, 1.0985373258590698)
(1665, 1.1064852476119995)
(1666, 1.0899208784103394)
(1667, 1.1062288284301758)
(1668, 1.1111654043197632)
(1669, 1.0930078029632568)
(1670, 1.1011091470718384)
(1671, 1.1070239543914795)
(1672, 1.1039355993270874)
(1673, 1.094022512435913)
(1674, 1.1075758934020996)
(1675, 1.0922504663467407)
(1676, 1.1033015251159668)
(1677, 1.0988446474075317)
(1678, 1.1119940280914307)
(1679, 1.1010475158691406)
(1680, 1.1102166175842285)
(1681, 1.1052013635635376)
(1682, 1.0993008613586426)
(1683, 1.096877098083496)
(1684, 1.0904176235198975)
(1685, 1.095179557800293)
(1686, 1.0933187007904053)
(1687, 1.1008771657943726)
(1688, 1.1064035892486572)
(1689, 1.0970979928970337)
(1690, 1.0973585844039917)
(1691, 1.095118522644043)
(1692, 1.1021344661712646)
(1693, 1.0983830690383911)
(1694, 1.100144386291504)
(1695, 1.1014459133148193)
(1696, 1.1038216352462769)
(1697, 1.101430892944336)
(1698, 1.0997508764266968)
(1699, 1.0988448858261108)
(1700, 1.095886468887329)
Train Epoch: 0 [3400/549367 (20%)]	Loss: 1.095886
(1701, 1.098198652267456)
(1702, 1.0888832807540894)
(1703, 1.0990593433380127)
(1704, 1.0955952405929565)
(1705, 1.1019712686538696)
(1706, 1.1011866331100464)
(1707, 1.091439127922058)
(1708, 1.0954490900039673)
(1709, 1.1067754030227661)
(1710, 1.0999723672866821)
(1711, 1.0985331535339355)
(1712, 1.1138163805007935)
(1713, 1.0923203229904175)
(1714, 1.106113076210022)
(1715, 1.1005381345748901)
(1716, 1.1045093536376953)
(1717, 1.111144781112671)
(1718, 1.101599097251892)
(1719, 1.0920175313949585)
(1720, 1.0913305282592773)
(1721, 1.1062860488891602)
(1722, 1.1046003103256226)
(1723, 1.1051414012908936)
(1724, 1.1213232278823853)
(1725, 1.1033552885055542)
(1726, 1.1179677248001099)
(1727, 1.0922602415084839)
(1728, 1.1031064987182617)
(1729, 1.0984147787094116)
(1730, 1.1025997400283813)
(1731, 1.1013681888580322)
(1732, 1.0934356451034546)
(1733, 1.1039364337921143)
(1734, 1.1113883256912231)
(1735, 1.1059170961380005)
(1736, 1.1004685163497925)
(1737, 1.097602367401123)
(1738, 1.0975134372711182)
(1739, 1.095853328704834)
(1740, 1.0944136381149292)
(1741, 1.1064479351043701)
(1742, 1.107686996459961)
(1743, 1.111533761024475)
(1744, 1.0971571207046509)
(1745, 1.0980033874511719)
(1746, 1.0947259664535522)
(1747, 1.0922728776931763)
(1748, 1.1050639152526855)
(1749, 1.0962114334106445)
(1750, 1.097909927368164)
(1751, 1.0928715467453003)
(1752, 1.113917589187622)
(1753, 1.0949493646621704)
(1754, 1.0905346870422363)
(1755, 1.1037894487380981)
(1756, 1.10157310962677)
(1757, 1.0925461053848267)
(1758, 1.1020729541778564)
(1759, 1.094463586807251)
(1760, 1.0869680643081665)
(1761, 1.0982714891433716)
(1762, 1.1109731197357178)
(1763, 1.0976684093475342)
(1764, 1.1086180210113525)
(1765, 1.0945757627487183)
(1766, 1.0983457565307617)
(1767, 1.0981667041778564)
(1768, 1.1069236993789673)
(1769, 1.1087043285369873)
(1770, 1.0951703786849976)
(1771, 1.1101772785186768)
(1772, 1.100167155265808)
(1773, 1.1071767807006836)
(1774, 1.0984631776809692)
(1775, 1.1086690425872803)
(1776, 1.1127424240112305)
(1777, 1.1019511222839355)
(1778, 1.0961261987686157)
(1779, 1.111180067062378)
(1780, 1.1027153730392456)
(1781, 1.1041702032089233)
(1782, 1.0899474620819092)
(1783, 1.0943361520767212)
(1784, 1.0939961671829224)
(1785, 1.1001349687576294)
(1786, 1.1034904718399048)
(1787, 1.1047353744506836)
(1788, 1.1057761907577515)
(1789, 1.0842783451080322)
(1790, 1.1013686656951904)
(1791, 1.0993380546569824)
(1792, 1.093533992767334)
(1793, 1.106748104095459)
(1794, 1.0907913446426392)
(1795, 1.1020793914794922)
(1796, 1.106360912322998)
(1797, 1.0917737483978271)
(1798, 1.096719741821289)
(1799, 1.0964592695236206)
(1800, 1.1067842245101929)
Train Epoch: 0 [3600/549367 (21%)]	Loss: 1.106784
(1801, 1.1014569997787476)
(1802, 1.0867602825164795)
(1803, 1.1090059280395508)
(1804, 1.1009023189544678)
(1805, 1.1016865968704224)
(1806, 1.0998561382293701)
(1807, 1.0989090204238892)
(1808, 1.09977126121521)
(1809, 1.104562520980835)
(1810, 1.1047184467315674)
(1811, 1.103705644607544)
(1812, 1.0974173545837402)
(1813, 1.099075198173523)
(1814, 1.0917519330978394)
(1815, 1.0947527885437012)
(1816, 1.1010940074920654)
(1817, 1.1081092357635498)
(1818, 1.0946937799453735)
(1819, 1.1036802530288696)
(1820, 1.0939180850982666)
(1821, 1.0941314697265625)
(1822, 1.1099281311035156)
(1823, 1.093643307685852)
(1824, 1.1082346439361572)
(1825, 1.1006909608840942)
(1826, 1.0963269472122192)
(1827, 1.0994168519973755)
(1828, 1.0810493230819702)
(1829, 1.109026551246643)
(1830, 1.1031215190887451)
(1831, 1.1040295362472534)
(1832, 1.0915881395339966)
(1833, 1.1150856018066406)
(1834, 1.1026791334152222)
(1835, 1.0968960523605347)
(1836, 1.0937954187393188)
(1837, 1.1017051935195923)
(1838, 1.1052567958831787)
(1839, 1.1090443134307861)
(1840, 1.0917028188705444)
(1841, 1.0923773050308228)
(1842, 1.110980749130249)
(1843, 1.1083157062530518)
(1844, 1.1065082550048828)
(1845, 1.1048836708068848)
(1846, 1.0869511365890503)
(1847, 1.0853878259658813)
(1848, 1.1005886793136597)
(1849, 1.0960801839828491)
(1850, 1.1022840738296509)
(1851, 1.1008168458938599)
(1852, 1.0929096937179565)
(1853, 1.1102731227874756)
(1854, 1.0942814350128174)
(1855, 1.0982712507247925)
(1856, 1.1085827350616455)
(1857, 1.103448510169983)
(1858, 1.103070855140686)
(1859, 1.1046788692474365)
(1860, 1.0950678586959839)
(1861, 1.09312105178833)
(1862, 1.0982121229171753)
(1863, 1.108340859413147)
(1864, 1.0931979417800903)
(1865, 1.10762357711792)
(1866, 1.1047292947769165)
(1867, 1.0949103832244873)
(1868, 1.0798227787017822)
(1869, 1.1017075777053833)
(1870, 1.0914973020553589)
(1871, 1.0912758111953735)
(1872, 1.1121296882629395)
(1873, 1.0973625183105469)
(1874, 1.1177157163619995)
(1875, 1.099615216255188)
(1876, 1.0918326377868652)
(1877, 1.0872788429260254)
(1878, 1.0972511768341064)
(1879, 1.0999048948287964)
(1880, 1.1051336526870728)
(1881, 1.0977163314819336)
(1882, 1.092651128768921)
(1883, 1.1051586866378784)
(1884, 1.0950069427490234)
(1885, 1.0866875648498535)
(1886, 1.0941849946975708)
(1887, 1.0962885618209839)
(1888, 1.093536376953125)
(1889, 1.1064732074737549)
(1890, 1.0952579975128174)
(1891, 1.0952411890029907)
(1892, 1.1042622327804565)
(1893, 1.097901463508606)
(1894, 1.0946805477142334)
(1895, 1.1110605001449585)
(1896, 1.0949417352676392)
(1897, 1.1082935333251953)
(1898, 1.0972988605499268)
(1899, 1.0934795141220093)
(1900, 1.103979229927063)
Train Epoch: 0 [3800/549367 (22%)]	Loss: 1.103979
(1901, 1.0948774814605713)
(1902, 1.1149219274520874)
(1903, 1.104508399963379)
(1904, 1.0935262441635132)
(1905, 1.104007601737976)
(1906, 1.1085261106491089)
(1907, 1.0981707572937012)
(1908, 1.0993211269378662)
(1909, 1.0899561643600464)
(1910, 1.0994693040847778)
(1911, 1.1035557985305786)
(1912, 1.0965811014175415)
(1913, 1.1120235919952393)
(1914, 1.1064738035202026)
(1915, 1.0978636741638184)
(1916, 1.107122540473938)
(1917, 1.0906916856765747)
(1918, 1.1075546741485596)
(1919, 1.099648118019104)
(1920, 1.1098099946975708)
(1921, 1.0942295789718628)
(1922, 1.1016275882720947)
(1923, 1.1007726192474365)
(1924, 1.0928053855895996)
(1925, 1.115525245666504)
(1926, 1.095147967338562)
(1927, 1.1066501140594482)
(1928, 1.0890995264053345)
(1929, 1.0974595546722412)
(1930, 1.0889226198196411)
(1931, 1.0975676774978638)
(1932, 1.0926660299301147)
(1933, 1.1011523008346558)
(1934, 1.107358455657959)
(1935, 1.091118574142456)
(1936, 1.0964070558547974)
(1937, 1.1099965572357178)
(1938, 1.1021455526351929)
(1939, 1.107205867767334)
(1940, 1.095841884613037)
(1941, 1.0961233377456665)
(1942, 1.1066871881484985)
(1943, 1.107003092765808)
(1944, 1.081458330154419)
(1945, 1.0995826721191406)
(1946, 1.0894041061401367)
(1947, 1.0953904390335083)
(1948, 1.1083922386169434)
(1949, 1.1045823097229004)
(1950, 1.101049780845642)
(1951, 1.1125099658966064)
(1952, 1.1003576517105103)
(1953, 1.0985939502716064)
(1954, 1.09138822555542)
(1955, 1.097701907157898)
(1956, 1.103301763534546)
(1957, 1.091755747795105)
(1958, 1.097345232963562)
(1959, 1.112502932548523)
(1960, 1.09633469581604)
(1961, 1.1088236570358276)
(1962, 1.0960935354232788)
(1963, 1.0956060886383057)
(1964, 1.1048274040222168)
(1965, 1.1146230697631836)
(1966, 1.0895963907241821)
(1967, 1.0875940322875977)
(1968, 1.1003462076187134)
(1969, 1.0982283353805542)
(1970, 1.1121373176574707)
(1971, 1.1048842668533325)
(1972, 1.1014163494110107)
(1973, 1.1007990837097168)
(1974, 1.100192904472351)
(1975, 1.0897661447525024)
(1976, 1.1032264232635498)
(1977, 1.1096667051315308)
(1978, 1.0992711782455444)
(1979, 1.123175859451294)
(1980, 1.1120102405548096)
(1981, 1.0864641666412354)
(1982, 1.0931346416473389)
(1983, 1.088620901107788)
(1984, 1.091948390007019)
(1985, 1.1073471307754517)
(1986, 1.1064711809158325)
(1987, 1.0932846069335938)
(1988, 1.1053389310836792)
(1989, 1.1067975759506226)
(1990, 1.096407413482666)
(1991, 1.0957013368606567)
(1992, 1.1047409772872925)
(1993, 1.0902284383773804)
(1994, 1.1055271625518799)
(1995, 1.092371940612793)
(1996, 1.1018083095550537)
(1997, 1.091476559638977)
(1998, 1.1023930311203003)
(1999, 1.092721939086914)
(2000, 1.092576503753662)
Train Epoch: 0 [4000/549367 (23%)]	Loss: 1.092577
(2001, 1.094511866569519)
(2002, 1.1021467447280884)
(2003, 1.0900115966796875)
(2004, 1.0999457836151123)
(2005, 1.1077345609664917)
(2006, 1.1033796072006226)
(2007, 1.0941979885101318)
(2008, 1.12189519405365)
(2009, 1.110422968864441)
(2010, 1.0941658020019531)
(2011, 1.093741774559021)
(2012, 1.1131688356399536)
(2013, 1.1041860580444336)
(2014, 1.1000909805297852)
(2015, 1.0946670770645142)
(2016, 1.110287070274353)
(2017, 1.0977271795272827)
(2018, 1.0952714681625366)
(2019, 1.1004010438919067)
(2020, 1.1006356477737427)
(2021, 1.1003496646881104)
(2022, 1.097432017326355)
(2023, 1.1082589626312256)
(2024, 1.097885251045227)
(2025, 1.1091995239257812)
(2026, 1.1091808080673218)
(2027, 1.093573808670044)
(2028, 1.1098456382751465)
(2029, 1.096453070640564)
(2030, 1.0925300121307373)
(2031, 1.0879071950912476)
(2032, 1.0991382598876953)
(2033, 1.1073458194732666)
(2034, 1.0989457368850708)
(2035, 1.0941598415374756)
(2036, 1.0896059274673462)
(2037, 1.0979539155960083)
(2038, 1.1014891862869263)
(2039, 1.1038103103637695)
(2040, 1.0875000953674316)
(2041, 1.0996161699295044)
(2042, 1.0981873273849487)
(2043, 1.0953552722930908)
(2044, 1.102400541305542)
(2045, 1.1064540147781372)
(2046, 1.100612998008728)
(2047, 1.0994691848754883)
(2048, 1.0982106924057007)
(2049, 1.1121402978897095)
(2050, 1.102311372756958)
(2051, 1.0930392742156982)
(2052, 1.0981107950210571)
(2053, 1.107353925704956)
(2054, 1.1023855209350586)
(2055, 1.0996558666229248)
(2056, 1.1007391214370728)
(2057, 1.1104851961135864)
(2058, 1.0959796905517578)
(2059, 1.1068027019500732)
(2060, 1.1039767265319824)
(2061, 1.0994638204574585)
(2062, 1.1079267263412476)
(2063, 1.0979392528533936)
(2064, 1.1021431684494019)
(2065, 1.0959144830703735)
(2066, 1.099178671836853)
(2067, 1.0941977500915527)
(2068, 1.093862533569336)
(2069, 1.0982990264892578)
(2070, 1.1089314222335815)
(2071, 1.1052523851394653)
(2072, 1.0898419618606567)
(2073, 1.1012697219848633)
(2074, 1.099674105644226)
(2075, 1.1048616170883179)
(2076, 1.095046877861023)
(2077, 1.0946518182754517)
(2078, 1.0932706594467163)
(2079, 1.103934645652771)
(2080, 1.0949163436889648)
(2081, 1.1026986837387085)
(2082, 1.1059614419937134)
(2083, 1.0905530452728271)
(2084, 1.1051934957504272)
(2085, 1.1057027578353882)
(2086, 1.0890402793884277)
(2087, 1.0959795713424683)
(2088, 1.099492073059082)
(2089, 1.09140944480896)
(2090, 1.1040101051330566)
(2091, 1.1017242670059204)
(2092, 1.098167896270752)
(2093, 1.1023093461990356)
(2094, 1.1032789945602417)
(2095, 1.1000981330871582)
(2096, 1.1028990745544434)
(2097, 1.0984971523284912)
(2098, 1.1046561002731323)
(2099, 1.1023035049438477)
(2100, 1.100395679473877)
Train Epoch: 0 [4200/549367 (24%)]	Loss: 1.100396
(2101, 1.0873818397521973)
(2102, 1.0880690813064575)
(2103, 1.1055500507354736)
(2104, 1.1031748056411743)
(2105, 1.1061441898345947)
(2106, 1.1057261228561401)
(2107, 1.1014790534973145)
(2108, 1.105531930923462)
(2109, 1.0920844078063965)
(2110, 1.0946004390716553)
(2111, 1.0981712341308594)
(2112, 1.0985190868377686)
(2113, 1.1090989112854004)
(2114, 1.094956874847412)
(2115, 1.0974558591842651)
(2116, 1.0990147590637207)
(2117, 1.1001596450805664)
(2118, 1.1048184633255005)
(2119, 1.1040854454040527)
(2120, 1.0948028564453125)
(2121, 1.1030597686767578)
(2122, 1.0993200540542603)
(2123, 1.0903736352920532)
(2124, 1.0875862836837769)
(2125, 1.1043622493743896)
(2126, 1.1065279245376587)
(2127, 1.0944207906723022)
(2128, 1.1048219203948975)
(2129, 1.0979173183441162)
(2130, 1.095759630203247)
(2131, 1.0910600423812866)
(2132, 1.0999184846878052)
(2133, 1.0962530374526978)
(2134, 1.1055190563201904)
(2135, 1.090668797492981)
(2136, 1.102537989616394)
(2137, 1.1032154560089111)
(2138, 1.0988924503326416)
(2139, 1.0979253053665161)
(2140, 1.0983984470367432)
(2141, 1.1137945652008057)
(2142, 1.10249662399292)
(2143, 1.1091114282608032)
(2144, 1.0926941633224487)
(2145, 1.092624306678772)
(2146, 1.1007241010665894)
(2147, 1.1041419506072998)
(2148, 1.0917625427246094)
(2149, 1.0889592170715332)
(2150, 1.0990725755691528)
(2151, 1.095112681388855)
(2152, 1.095920443534851)
(2153, 1.1098238229751587)
(2154, 1.096863031387329)
(2155, 1.1071226596832275)
(2156, 1.094712734222412)
(2157, 1.0856242179870605)
(2158, 1.109127163887024)
(2159, 1.115859866142273)
(2160, 1.0925012826919556)
(2161, 1.1119321584701538)
(2162, 1.0967366695404053)
(2163, 1.1030983924865723)
(2164, 1.094139575958252)
(2165, 1.0987013578414917)
(2166, 1.0923588275909424)
(2167, 1.104520559310913)
(2168, 1.0917741060256958)
(2169, 1.102597713470459)
(2170, 1.10283625125885)
(2171, 1.1045982837677002)
(2172, 1.1050084829330444)
(2173, 1.0965558290481567)
(2174, 1.10574471950531)
(2175, 1.0995746850967407)
(2176, 1.1036100387573242)
(2177, 1.0994573831558228)
(2178, 1.0996460914611816)
(2179, 1.1017248630523682)
(2180, 1.0929886102676392)
(2181, 1.1092604398727417)
(2182, 1.1015812158584595)
(2183, 1.1063448190689087)
(2184, 1.1115972995758057)
(2185, 1.1077858209609985)
(2186, 1.1039668321609497)
(2187, 1.1072125434875488)
(2188, 1.0932525396347046)
(2189, 1.108802080154419)
(2190, 1.0900267362594604)
(2191, 1.0922541618347168)
(2192, 1.1033060550689697)
(2193, 1.1020491123199463)
(2194, 1.098972201347351)
(2195, 1.0956976413726807)
(2196, 1.1096521615982056)
(2197, 1.1037399768829346)
(2198, 1.0965064764022827)
(2199, 1.1036720275878906)
(2200, 1.1237486600875854)
Train Epoch: 0 [4400/549367 (26%)]	Loss: 1.123749
(2201, 1.094321370124817)
(2202, 1.0944567918777466)
(2203, 1.0991820096969604)
(2204, 1.0924967527389526)
(2205, 1.0920401811599731)
(2206, 1.092968463897705)
(2207, 1.1040654182434082)
(2208, 1.0950663089752197)
(2209, 1.093787431716919)
(2210, 1.0975133180618286)
(2211, 1.093542456626892)
(2212, 1.100677728652954)
(2213, 1.0982495546340942)
(2214, 1.1043611764907837)
(2215, 1.10271418094635)
(2216, 1.104440689086914)
(2217, 1.09880530834198)
(2218, 1.0956783294677734)
(2219, 1.1118018627166748)
(2220, 1.0968265533447266)
(2221, 1.1054167747497559)
(2222, 1.1052237749099731)
(2223, 1.1065775156021118)
(2224, 1.0920618772506714)
(2225, 1.1093833446502686)
(2226, 1.09990394115448)
(2227, 1.1128082275390625)
(2228, 1.106582760810852)
(2229, 1.1009076833724976)
(2230, 1.0847433805465698)
(2231, 1.1017543077468872)
(2232, 1.0987327098846436)
(2233, 1.1028565168380737)
(2234, 1.1031758785247803)
(2235, 1.0942165851593018)
(2236, 1.1008456945419312)
(2237, 1.099196434020996)
(2238, 1.0950767993927002)
(2239, 1.1102107763290405)
(2240, 1.1056740283966064)
(2241, 1.0941588878631592)
(2242, 1.1093847751617432)
(2243, 1.1051263809204102)
(2244, 1.0987920761108398)
(2245, 1.0959093570709229)
(2246, 1.1087868213653564)
(2247, 1.0992624759674072)
(2248, 1.0908972024917603)
(2249, 1.0927175283432007)
(2250, 1.1055841445922852)
(2251, 1.0988731384277344)
(2252, 1.1042494773864746)
(2253, 1.098564624786377)
(2254, 1.1094281673431396)
(2255, 1.100649356842041)
(2256, 1.107582926750183)
(2257, 1.099045753479004)
(2258, 1.0959103107452393)
(2259, 1.0934906005859375)
(2260, 1.1077173948287964)
(2261, 1.107684850692749)
(2262, 1.0954196453094482)
(2263, 1.1057876348495483)
(2264, 1.1022096872329712)
(2265, 1.1095646619796753)
(2266, 1.1003066301345825)
(2267, 1.0998855829238892)
(2268, 1.0961054563522339)
(2269, 1.1030691862106323)
(2270, 1.0998588800430298)
(2271, 1.1071122884750366)
(2272, 1.098378300666809)
(2273, 1.0929415225982666)
(2274, 1.1008632183074951)
(2275, 1.0972256660461426)
(2276, 1.0992299318313599)
(2277, 1.0976817607879639)
(2278, 1.1054221391677856)
(2279, 1.1068377494812012)
(2280, 1.1022834777832031)
(2281, 1.097697138786316)
(2282, 1.0960075855255127)
(2283, 1.0993964672088623)
(2284, 1.0918054580688477)
(2285, 1.1003236770629883)
(2286, 1.0972979068756104)
(2287, 1.0883336067199707)
(2288, 1.094982624053955)
(2289, 1.0954195261001587)
(2290, 1.100932002067566)
(2291, 1.1040544509887695)
(2292, 1.098467469215393)
(2293, 1.102210521697998)
(2294, 1.0961112976074219)
(2295, 1.1059248447418213)
(2296, 1.1054439544677734)
(2297, 1.0974578857421875)
(2298, 1.0965012311935425)
(2299, 1.0931861400604248)
(2300, 1.1099817752838135)
Train Epoch: 0 [4600/549367 (27%)]	Loss: 1.109982
(2301, 1.091303825378418)
(2302, 1.1072981357574463)
(2303, 1.1013036966323853)
(2304, 1.094488501548767)
(2305, 1.1003834009170532)
(2306, 1.0935968160629272)
(2307, 1.0895925760269165)
(2308, 1.0927425622940063)
(2309, 1.0933120250701904)
(2310, 1.0942203998565674)
(2311, 1.1054039001464844)
(2312, 1.1130800247192383)
(2313, 1.0943151712417603)
(2314, 1.1016439199447632)
(2315, 1.0957002639770508)
(2316, 1.1051346063613892)
(2317, 1.0980581045150757)
(2318, 1.0918833017349243)
(2319, 1.1055220365524292)
(2320, 1.0941071510314941)
(2321, 1.0978132486343384)
(2322, 1.095296859741211)
(2323, 1.1034650802612305)
(2324, 1.09709894657135)
(2325, 1.106574535369873)
(2326, 1.0944591760635376)
(2327, 1.101279377937317)
(2328, 1.0949087142944336)
(2329, 1.098687767982483)
(2330, 1.1028428077697754)
(2331, 1.101809024810791)
(2332, 1.0962928533554077)
(2333, 1.0980743169784546)
(2334, 1.0975922346115112)
(2335, 1.0982518196105957)
(2336, 1.1017794609069824)
(2337, 1.1012376546859741)
(2338, 1.0969094038009644)
(2339, 1.0986864566802979)
(2340, 1.0964175462722778)
(2341, 1.1111924648284912)
(2342, 1.0998828411102295)
(2343, 1.1015723943710327)
(2344, 1.0906941890716553)
(2345, 1.0844961404800415)
(2346, 1.096937894821167)
(2347, 1.1040977239608765)
(2348, 1.0996363162994385)
(2349, 1.114946722984314)
(2350, 1.1074551343917847)
(2351, 1.1038914918899536)
(2352, 1.0971583127975464)
(2353, 1.1066681146621704)
(2354, 1.0890446901321411)
(2355, 1.1004449129104614)
(2356, 1.0975935459136963)
(2357, 1.1031092405319214)
(2358, 1.0935554504394531)
(2359, 1.1021562814712524)
(2360, 1.1069080829620361)
(2361, 1.0926283597946167)
(2362, 1.094563364982605)
(2363, 1.0907038450241089)
(2364, 1.1048446893692017)
(2365, 1.0955406427383423)
(2366, 1.1026091575622559)
(2367, 1.0892390012741089)
(2368, 1.0999608039855957)
(2369, 1.1004747152328491)
(2370, 1.099651575088501)
(2371, 1.0950655937194824)
(2372, 1.1019259691238403)
(2373, 1.1070160865783691)
(2374, 1.096286416053772)
(2375, 1.1074986457824707)
(2376, 1.0999464988708496)
(2377, 1.0882140398025513)
(2378, 1.1048624515533447)
(2379, 1.1026806831359863)
(2380, 1.0946424007415771)
(2381, 1.1061677932739258)
(2382, 1.0996708869934082)
(2383, 1.1042063236236572)
(2384, 1.1003566980361938)
(2385, 1.0938093662261963)
(2386, 1.101755976676941)
(2387, 1.1050814390182495)
(2388, 1.099354863166809)
(2389, 1.0898981094360352)
(2390, 1.098981499671936)
(2391, 1.1060799360275269)
(2392, 1.0973554849624634)
(2393, 1.1054831743240356)
(2394, 1.1005951166152954)
(2395, 1.0977531671524048)
(2396, 1.096706509590149)
(2397, 1.1094865798950195)
(2398, 1.0946532487869263)
(2399, 1.108284831047058)
(2400, 1.0971812009811401)
Train Epoch: 0 [4800/549367 (28%)]	Loss: 1.097181
(2401, 1.100032925605774)
(2402, 1.1016144752502441)
(2403, 1.092354416847229)
(2404, 1.110834002494812)
(2405, 1.1051547527313232)
(2406, 1.107201337814331)
(2407, 1.0869693756103516)
(2408, 1.1027332544326782)
(2409, 1.0982190370559692)
(2410, 1.1002585887908936)
(2411, 1.1069623231887817)
(2412, 1.0996325016021729)
(2413, 1.0924042463302612)
(2414, 1.1107912063598633)
(2415, 1.0996713638305664)
(2416, 1.0888562202453613)
(2417, 1.0987449884414673)
(2418, 1.0979852676391602)
(2419, 1.0952194929122925)
(2420, 1.0970704555511475)
(2421, 1.092254400253296)
(2422, 1.095587134361267)
(2423, 1.1110188961029053)
(2424, 1.1011890172958374)
(2425, 1.1028410196304321)
(2426, 1.0955759286880493)
(2427, 1.106524109840393)
(2428, 1.0940001010894775)
(2429, 1.1101136207580566)
(2430, 1.0999189615249634)
(2431, 1.0976312160491943)
(2432, 1.0998092889785767)
(2433, 1.0937227010726929)
(2434, 1.1049453020095825)
(2435, 1.0991604328155518)
(2436, 1.1123532056808472)
(2437, 1.0968554019927979)
(2438, 1.1026028394699097)
(2439, 1.0916763544082642)
(2440, 1.0954020023345947)
(2441, 1.1021206378936768)
(2442, 1.097809910774231)
(2443, 1.0990746021270752)
(2444, 1.1065316200256348)
(2445, 1.1024930477142334)
(2446, 1.0978246927261353)
(2447, 1.1047850847244263)
(2448, 1.095564603805542)
(2449, 1.0897232294082642)
(2450, 1.0960419178009033)
(2451, 1.1072919368743896)
(2452, 1.102805256843567)
(2453, 1.103075385093689)
(2454, 1.0997002124786377)
(2455, 1.101014256477356)
(2456, 1.090066909790039)
(2457, 1.1079533100128174)
(2458, 1.0980360507965088)
(2459, 1.099729061126709)
(2460, 1.09897780418396)
(2461, 1.0967717170715332)
(2462, 1.1038485765457153)
(2463, 1.1071374416351318)
(2464, 1.1002001762390137)
(2465, 1.0826833248138428)
(2466, 1.098909616470337)
(2467, 1.1000603437423706)
(2468, 1.0897940397262573)
(2469, 1.1019095182418823)
(2470, 1.0939929485321045)
(2471, 1.0887293815612793)
(2472, 1.0967713594436646)
(2473, 1.0962247848510742)
(2474, 1.0938338041305542)
(2475, 1.0992746353149414)
(2476, 1.0972644090652466)
(2477, 1.0879933834075928)
(2478, 1.1084362268447876)
(2479, 1.1034808158874512)
(2480, 1.0873265266418457)
(2481, 1.0948474407196045)
(2482, 1.0994179248809814)
(2483, 1.0993728637695312)
(2484, 1.1055899858474731)
(2485, 1.0919605493545532)
(2486, 1.1046392917633057)
(2487, 1.1077802181243896)
(2488, 1.098134160041809)
(2489, 1.0965255498886108)
(2490, 1.104689359664917)
(2491, 1.1037412881851196)
(2492, 1.0837244987487793)
(2493, 1.0975159406661987)
(2494, 1.1002434492111206)
(2495, 1.0962622165679932)
(2496, 1.1027963161468506)
(2497, 1.0925718545913696)
(2498, 1.0888417959213257)
(2499, 1.1041245460510254)
(2500, 1.090857982635498)
Train Epoch: 0 [5000/549367 (29%)]	Loss: 1.090858
(2501, 1.0964792966842651)
(2502, 1.1064541339874268)
(2503, 1.1109669208526611)
(2504, 1.0996257066726685)
(2505, 1.101121425628662)
(2506, 1.0916976928710938)
(2507, 1.1078360080718994)
(2508, 1.0931016206741333)
(2509, 1.098902702331543)
(2510, 1.0941355228424072)
(2511, 1.1124722957611084)
(2512, 1.1118338108062744)
(2513, 1.0938454866409302)
(2514, 1.101367473602295)
(2515, 1.112680196762085)
(2516, 1.095513939857483)
(2517, 1.1009012460708618)
(2518, 1.1027284860610962)
(2519, 1.0986255407333374)
(2520, 1.0925350189208984)
(2521, 1.1011929512023926)
(2522, 1.1009637117385864)
(2523, 1.0988925695419312)
(2524, 1.103320837020874)
(2525, 1.1104037761688232)
(2526, 1.1018438339233398)
(2527, 1.0994863510131836)
(2528, 1.1037994623184204)
(2529, 1.098264455795288)
(2530, 1.1013903617858887)
(2531, 1.095046043395996)
(2532, 1.1046578884124756)
(2533, 1.1104295253753662)
(2534, 1.0990521907806396)
(2535, 1.1089401245117188)
(2536, 1.0930073261260986)
(2537, 1.1039869785308838)
(2538, 1.102084755897522)
(2539, 1.1032963991165161)
(2540, 1.1007717847824097)
(2541, 1.0964266061782837)
(2542, 1.0972943305969238)
(2543, 1.0932180881500244)
(2544, 1.0953408479690552)
(2545, 1.086033821105957)
(2546, 1.1129448413848877)
(2547, 1.0918588638305664)
(2548, 1.1031100749969482)
(2549, 1.09846830368042)
(2550, 1.1006536483764648)
(2551, 1.0958106517791748)
(2552, 1.097044587135315)
(2553, 1.095126986503601)
(2554, 1.098494291305542)
(2555, 1.096963882446289)
(2556, 1.0981718301773071)
(2557, 1.096888542175293)
(2558, 1.0967862606048584)
(2559, 1.0974721908569336)
(2560, 1.0892977714538574)
(2561, 1.1072622537612915)
(2562, 1.1015479564666748)
(2563, 1.0916385650634766)
(2564, 1.0998135805130005)
(2565, 1.1019302606582642)
(2566, 1.1126272678375244)
(2567, 1.094348430633545)
(2568, 1.0995937585830688)
(2569, 1.095288872718811)
(2570, 1.0982495546340942)
(2571, 1.1094164848327637)
(2572, 1.1050522327423096)
(2573, 1.1032614707946777)
(2574, 1.1001739501953125)
(2575, 1.0990430116653442)
(2576, 1.097899317741394)
(2577, 1.0871484279632568)
(2578, 1.1015746593475342)
(2579, 1.0981858968734741)
(2580, 1.1103787422180176)
(2581, 1.1034741401672363)
(2582, 1.0960538387298584)
(2583, 1.1088647842407227)
(2584, 1.0992629528045654)
(2585, 1.1014797687530518)
(2586, 1.0893499851226807)
(2587, 1.1027237176895142)
(2588, 1.0957802534103394)
(2589, 1.0957350730895996)
(2590, 1.0995439291000366)
(2591, 1.0977778434753418)
(2592, 1.0970765352249146)
(2593, 1.098580002784729)
(2594, 1.1067383289337158)
(2595, 1.0950191020965576)
(2596, 1.1033653020858765)
(2597, 1.0936590433120728)
(2598, 1.1023682355880737)
(2599, 1.0882792472839355)
(2600, 1.0937657356262207)
Train Epoch: 0 [5200/549367 (30%)]	Loss: 1.093766
(2601, 1.0976428985595703)
(2602, 1.1024128198623657)
(2603, 1.1081576347351074)
(2604, 1.1015597581863403)
(2605, 1.105225682258606)
(2606, 1.1028274297714233)
(2607, 1.104075312614441)
(2608, 1.1052621603012085)
(2609, 1.1089063882827759)
(2610, 1.11595618724823)
(2611, 1.0971182584762573)
(2612, 1.0949029922485352)
(2613, 1.1030582189559937)
(2614, 1.0940132141113281)
(2615, 1.1082477569580078)
(2616, 1.1090322732925415)
(2617, 1.095528483390808)
(2618, 1.1035023927688599)
(2619, 1.1029644012451172)
(2620, 1.0994905233383179)
(2621, 1.1055030822753906)
(2622, 1.1019294261932373)
(2623, 1.0981353521347046)
(2624, 1.117153525352478)
(2625, 1.1106406450271606)
(2626, 1.086356520652771)
(2627, 1.1061742305755615)
(2628, 1.1049573421478271)
(2629, 1.0912067890167236)
(2630, 1.0941100120544434)
(2631, 1.1055876016616821)
(2632, 1.0994646549224854)
(2633, 1.1066595315933228)
(2634, 1.1081523895263672)
(2635, 1.0928559303283691)
(2636, 1.0970629453659058)
(2637, 1.1010428667068481)
(2638, 1.1037623882293701)
(2639, 1.102477788925171)
(2640, 1.1089969873428345)
(2641, 1.1084569692611694)
(2642, 1.0925847291946411)
(2643, 1.100929617881775)
(2644, 1.1048048734664917)
(2645, 1.0922648906707764)
(2646, 1.0978032350540161)
(2647, 1.1070576906204224)
(2648, 1.103084683418274)
(2649, 1.0944942235946655)
(2650, 1.094162106513977)
(2651, 1.0912599563598633)
(2652, 1.0972260236740112)
(2653, 1.098212718963623)
(2654, 1.1079992055892944)
(2655, 1.1041375398635864)
(2656, 1.0984153747558594)
(2657, 1.0986932516098022)
(2658, 1.0876588821411133)
(2659, 1.1071059703826904)
(2660, 1.0994596481323242)
(2661, 1.1018519401550293)
(2662, 1.0966795682907104)
(2663, 1.0951353311538696)
(2664, 1.0955077409744263)
(2665, 1.1017473936080933)
(2666, 1.0999304056167603)
(2667, 1.0936871767044067)
(2668, 1.0918694734573364)
(2669, 1.1094051599502563)
(2670, 1.0879759788513184)
(2671, 1.097291111946106)
(2672, 1.1052117347717285)
(2673, 1.1007908582687378)
(2674, 1.1017496585845947)
(2675, 1.0990046262741089)
(2676, 1.1082842350006104)
(2677, 1.0969494581222534)
(2678, 1.0985013246536255)
(2679, 1.1066783666610718)
(2680, 1.1007572412490845)
(2681, 1.1066166162490845)
(2682, 1.1022075414657593)
(2683, 1.0988558530807495)
(2684, 1.09796142578125)
(2685, 1.1099066734313965)
(2686, 1.0990509986877441)
(2687, 1.1041814088821411)
(2688, 1.0985932350158691)
(2689, 1.1056511402130127)
(2690, 1.0987907648086548)
(2691, 1.0971657037734985)
(2692, 1.0937392711639404)
(2693, 1.0995322465896606)
(2694, 1.0939496755599976)
(2695, 1.092251181602478)
(2696, 1.0916082859039307)
(2697, 1.1016701459884644)
(2698, 1.0949894189834595)
(2699, 1.1016383171081543)
(2700, 1.097059965133667)
Train Epoch: 0 [5400/549367 (31%)]	Loss: 1.097060
(2701, 1.0993632078170776)
(2702, 1.0950933694839478)
(2703, 1.103545069694519)
(2704, 1.1007356643676758)
(2705, 1.1014912128448486)
(2706, 1.103466272354126)
(2707, 1.0983384847640991)
(2708, 1.102665662765503)
(2709, 1.0947297811508179)
(2710, 1.1074689626693726)
(2711, 1.106061577796936)
(2712, 1.0959656238555908)
(2713, 1.1022238731384277)
(2714, 1.098266839981079)
(2715, 1.1033633947372437)
(2716, 1.0955681800842285)
(2717, 1.0978604555130005)
(2718, 1.0935951471328735)
(2719, 1.1003955602645874)
(2720, 1.0899386405944824)
(2721, 1.100940227508545)
(2722, 1.0965068340301514)
(2723, 1.1075626611709595)
(2724, 1.0997323989868164)
(2725, 1.0987032651901245)
(2726, 1.1044118404388428)
(2727, 1.0958302021026611)
(2728, 1.104355812072754)
(2729, 1.0950685739517212)
(2730, 1.1062406301498413)
(2731, 1.0998907089233398)
(2732, 1.0988165140151978)
(2733, 1.0958210229873657)
(2734, 1.0917812585830688)
(2735, 1.1029651165008545)
(2736, 1.095007300376892)
(2737, 1.0938520431518555)
(2738, 1.0968164205551147)
(2739, 1.0946803092956543)
(2740, 1.1001709699630737)
(2741, 1.10130774974823)
(2742, 1.1024764776229858)
(2743, 1.1052472591400146)
(2744, 1.101915955543518)
(2745, 1.0987660884857178)
(2746, 1.1023370027542114)
(2747, 1.1041113138198853)
(2748, 1.0991575717926025)
(2749, 1.1143739223480225)
(2750, 1.0957953929901123)
(2751, 1.1011149883270264)
(2752, 1.1044138669967651)
(2753, 1.0967671871185303)
(2754, 1.1092212200164795)
(2755, 1.1031402349472046)
(2756, 1.0922435522079468)
(2757, 1.0909950733184814)
(2758, 1.102193832397461)
(2759, 1.100907802581787)
(2760, 1.1058586835861206)
(2761, 1.093960165977478)
(2762, 1.099379539489746)
(2763, 1.1042566299438477)
(2764, 1.1052542924880981)
(2765, 1.0960124731063843)
(2766, 1.106478214263916)
(2767, 1.1003081798553467)
(2768, 1.0949853658676147)
(2769, 1.1038192510604858)
(2770, 1.0941952466964722)
(2771, 1.1029633283615112)
(2772, 1.0991601943969727)
(2773, 1.0946742296218872)
(2774, 1.101793885231018)
(2775, 1.09781813621521)
(2776, 1.1027501821517944)
(2777, 1.0981836318969727)
(2778, 1.0981700420379639)
(2779, 1.1008633375167847)
(2780, 1.1103551387786865)
(2781, 1.0977349281311035)
(2782, 1.0914660692214966)
(2783, 1.1009118556976318)
(2784, 1.0950285196304321)
(2785, 1.0968127250671387)
(2786, 1.0992258787155151)
(2787, 1.0977206230163574)
(2788, 1.1051093339920044)
(2789, 1.0906094312667847)
(2790, 1.1023114919662476)
(2791, 1.1057689189910889)
(2792, 1.1071079969406128)
(2793, 1.099015235900879)
(2794, 1.1129881143569946)
(2795, 1.0971596240997314)
(2796, 1.1046714782714844)
(2797, 1.0989960432052612)
(2798, 1.0985581874847412)
(2799, 1.101892352104187)
(2800, 1.0922378301620483)
Train Epoch: 0 [5600/549367 (33%)]	Loss: 1.092238
(2801, 1.0973459482192993)
(2802, 1.1050974130630493)
(2803, 1.0987730026245117)
(2804, 1.0999724864959717)
(2805, 1.1000159978866577)
(2806, 1.1024527549743652)
(2807, 1.095646619796753)
(2808, 1.1114391088485718)
(2809, 1.0958610773086548)
(2810, 1.0990123748779297)
(2811, 1.0998202562332153)
(2812, 1.1111644506454468)
(2813, 1.0952852964401245)
(2814, 1.1040079593658447)
(2815, 1.0936287641525269)
(2816, 1.098783254623413)
(2817, 1.098368525505066)
(2818, 1.094123125076294)
(2819, 1.1091877222061157)
(2820, 1.0970677137374878)
(2821, 1.0951207876205444)
(2822, 1.1018177270889282)
(2823, 1.09315824508667)
(2824, 1.0967921018600464)
(2825, 1.0972496271133423)
(2826, 1.0981049537658691)
(2827, 1.0987013578414917)
(2828, 1.0898940563201904)
(2829, 1.0953611135482788)
(2830, 1.10513436794281)
(2831, 1.0984137058258057)
(2832, 1.1003917455673218)
(2833, 1.1054400205612183)
(2834, 1.096079707145691)
(2835, 1.0947366952896118)
(2836, 1.0970244407653809)
(2837, 1.0961430072784424)
(2838, 1.1034681797027588)
(2839, 1.0849570035934448)
(2840, 1.100494146347046)
(2841, 1.104770541191101)
(2842, 1.0912820100784302)
(2843, 1.1038901805877686)
(2844, 1.0982847213745117)
(2845, 1.0985565185546875)
(2846, 1.105944275856018)
(2847, 1.1009070873260498)
(2848, 1.0963232517242432)
(2849, 1.1072382926940918)
(2850, 1.100023627281189)
(2851, 1.1032241582870483)
(2852, 1.0991668701171875)
(2853, 1.1018927097320557)
(2854, 1.1078927516937256)
(2855, 1.1056983470916748)
(2856, 1.1070442199707031)
(2857, 1.1040911674499512)
(2858, 1.097000241279602)
(2859, 1.105644941329956)
(2860, 1.088296890258789)
(2861, 1.1145851612091064)
(2862, 1.0943793058395386)
(2863, 1.102597713470459)
(2864, 1.0982258319854736)
(2865, 1.1024880409240723)
(2866, 1.110372543334961)
(2867, 1.099528193473816)
(2868, 1.100297451019287)
(2869, 1.0993659496307373)
(2870, 1.0976988077163696)
(2871, 1.1057438850402832)
(2872, 1.0946072340011597)
(2873, 1.0979725122451782)
(2874, 1.090970754623413)
(2875, 1.1075363159179688)
(2876, 1.0972850322723389)
(2877, 1.0928905010223389)
(2878, 1.1033529043197632)
(2879, 1.1007778644561768)
(2880, 1.0973701477050781)
(2881, 1.093853235244751)
(2882, 1.109777569770813)
(2883, 1.0994614362716675)
(2884, 1.0960489511489868)
(2885, 1.100693941116333)
(2886, 1.101431131362915)
(2887, 1.0934830904006958)
(2888, 1.096929669380188)
(2889, 1.1034467220306396)
(2890, 1.0996288061141968)
(2891, 1.1065375804901123)
(2892, 1.1033023595809937)
(2893, 1.0948667526245117)
(2894, 1.100587010383606)
(2895, 1.1038761138916016)
(2896, 1.0908503532409668)
(2897, 1.1035562753677368)
(2898, 1.0987818241119385)
(2899, 1.0996168851852417)
(2900, 1.1039661169052124)
Train Epoch: 0 [5800/549367 (34%)]	Loss: 1.103966
(2901, 1.0961568355560303)
(2902, 1.099650263786316)
(2903, 1.094027042388916)
(2904, 1.113059639930725)
(2905, 1.1071332693099976)
(2906, 1.0991734266281128)
(2907, 1.089486837387085)
(2908, 1.104217290878296)
(2909, 1.0923460721969604)
(2910, 1.0987491607666016)
(2911, 1.0935193300247192)
(2912, 1.1096136569976807)
(2913, 1.0974981784820557)
(2914, 1.1045371294021606)
(2915, 1.0985527038574219)
(2916, 1.098534345626831)
(2917, 1.0954242944717407)
(2918, 1.098448395729065)
(2919, 1.092149019241333)
(2920, 1.0930813550949097)
(2921, 1.0996875762939453)
(2922, 1.1022599935531616)
(2923, 1.091879963874817)
(2924, 1.0989991426467896)
(2925, 1.0933198928833008)
(2926, 1.0981119871139526)
(2927, 1.1073980331420898)
(2928, 1.101028561592102)
(2929, 1.0975275039672852)
(2930, 1.1022512912750244)
(2931, 1.098992109298706)
(2932, 1.0979952812194824)
(2933, 1.0976591110229492)
(2934, 1.1035032272338867)
(2935, 1.087337851524353)
(2936, 1.0971958637237549)
(2937, 1.0889428853988647)
(2938, 1.1061896085739136)
(2939, 1.1107491254806519)
(2940, 1.0948816537857056)
(2941, 1.1001667976379395)
(2942, 1.1010712385177612)
(2943, 1.1081149578094482)
(2944, 1.1065527200698853)
(2945, 1.0891478061676025)
(2946, 1.105154037475586)
(2947, 1.1003464460372925)
(2948, 1.101299524307251)
(2949, 1.1063448190689087)
(2950, 1.1112385988235474)
(2951, 1.1071559190750122)
(2952, 1.0918898582458496)
(2953, 1.0962005853652954)
(2954, 1.0969538688659668)
(2955, 1.1008250713348389)
(2956, 1.104946494102478)
(2957, 1.0990793704986572)
(2958, 1.0974973440170288)
(2959, 1.1026744842529297)
(2960, 1.0971691608428955)
(2961, 1.1071182489395142)
(2962, 1.099074125289917)
(2963, 1.0967066287994385)
(2964, 1.1041899919509888)
(2965, 1.1092960834503174)
(2966, 1.1060853004455566)
(2967, 1.0924936532974243)
(2968, 1.0997685194015503)
(2969, 1.0983476638793945)
(2970, 1.0887590646743774)
(2971, 1.1020630598068237)
(2972, 1.0963702201843262)
(2973, 1.0924558639526367)
(2974, 1.1015585660934448)
(2975, 1.0970813035964966)
(2976, 1.1070988178253174)
(2977, 1.0897020101547241)
(2978, 1.097921371459961)
(2979, 1.0987951755523682)
(2980, 1.1028165817260742)
(2981, 1.099285364151001)
(2982, 1.1066445112228394)
(2983, 1.1010396480560303)
(2984, 1.1039453744888306)
(2985, 1.0971380472183228)
(2986, 1.1012747287750244)
(2987, 1.0890798568725586)
(2988, 1.089792251586914)
(2989, 1.105648159980774)
(2990, 1.1078846454620361)
(2991, 1.0969892740249634)
(2992, 1.1017056703567505)
(2993, 1.0986697673797607)
(2994, 1.0918512344360352)
(2995, 1.1026073694229126)
(2996, 1.0969548225402832)
(2997, 1.0983134508132935)
(2998, 1.1002832651138306)
(2999, 1.0909501314163208)
(3000, 1.0976835489273071)
Train Epoch: 0 [6000/549367 (35%)]	Loss: 1.097684
(3001, 1.0951255559921265)
(3002, 1.1039515733718872)
(3003, 1.1100651025772095)
(3004, 1.096016526222229)
(3005, 1.0876986980438232)
(3006, 1.1048014163970947)
(3007, 1.1053603887557983)
(3008, 1.0970531702041626)
(3009, 1.0920530557632446)
(3010, 1.1024993658065796)
(3011, 1.103966236114502)
(3012, 1.1010304689407349)
(3013, 1.0997376441955566)
(3014, 1.0920944213867188)
(3015, 1.1035668849945068)
(3016, 1.1019797325134277)
(3017, 1.094875454902649)
(3018, 1.098832130432129)
(3019, 1.0900555849075317)
(3020, 1.0994229316711426)
(3021, 1.0995686054229736)
(3022, 1.1038522720336914)
(3023, 1.100568413734436)
(3024, 1.0985764265060425)
(3025, 1.1018375158309937)
(3026, 1.1081641912460327)
(3027, 1.1030035018920898)
(3028, 1.1022295951843262)
(3029, 1.1187512874603271)
(3030, 1.0981453657150269)
(3031, 1.0918396711349487)
(3032, 1.096744179725647)
(3033, 1.1046208143234253)
(3034, 1.1046595573425293)
(3035, 1.094995379447937)
(3036, 1.10380220413208)
(3037, 1.1094837188720703)
(3038, 1.0996417999267578)
(3039, 1.105712890625)
(3040, 1.0957517623901367)
(3041, 1.1043727397918701)
(3042, 1.1107425689697266)
(3043, 1.1016271114349365)
(3044, 1.1029717922210693)
(3045, 1.1052329540252686)
(3046, 1.1008065938949585)
(3047, 1.1022714376449585)
(3048, 1.0997837781906128)
(3049, 1.0922800302505493)
(3050, 1.090863585472107)
(3051, 1.100206732749939)
(3052, 1.0982531309127808)
(3053, 1.0932096242904663)
(3054, 1.1086229085922241)
(3055, 1.0978825092315674)
(3056, 1.1048612594604492)
(3057, 1.0984457731246948)
(3058, 1.0994842052459717)
(3059, 1.0964179039001465)
(3060, 1.0950654745101929)
(3061, 1.1057941913604736)
(3062, 1.1060773134231567)
(3063, 1.0989083051681519)
(3064, 1.1058354377746582)
(3065, 1.1021356582641602)
(3066, 1.0912978649139404)
(3067, 1.1005812883377075)
(3068, 1.1010857820510864)
(3069, 1.0977182388305664)
(3070, 1.0973564386367798)
(3071, 1.1006501913070679)
(3072, 1.0958266258239746)
(3073, 1.102689266204834)
(3074, 1.1026434898376465)
(3075, 1.0996413230895996)
(3076, 1.1033263206481934)
(3077, 1.100576639175415)
(3078, 1.098360538482666)
(3079, 1.0994302034378052)
(3080, 1.0963468551635742)
(3081, 1.0944706201553345)
(3082, 1.096909999847412)
(3083, 1.090850591659546)
(3084, 1.102586030960083)
(3085, 1.10049307346344)
(3086, 1.098219871520996)
(3087, 1.099853515625)
(3088, 1.10336434841156)
(3089, 1.098334789276123)
(3090, 1.1029568910598755)
(3091, 1.0992918014526367)
(3092, 1.1051687002182007)
(3093, 1.0991286039352417)
(3094, 1.1001861095428467)
(3095, 1.098563313484192)
(3096, 1.0948271751403809)
(3097, 1.1007457971572876)
(3098, 1.0946431159973145)
(3099, 1.1049699783325195)
(3100, 1.1044780015945435)
Train Epoch: 0 [6200/549367 (36%)]	Loss: 1.104478
(3101, 1.0945422649383545)
(3102, 1.1012897491455078)
(3103, 1.0933806896209717)
(3104, 1.0863922834396362)
(3105, 1.0990055799484253)
(3106, 1.1004116535186768)
(3107, 1.0984629392623901)
(3108, 1.1054956912994385)
(3109, 1.1021989583969116)
(3110, 1.0975033044815063)
(3111, 1.0968490839004517)
(3112, 1.0925039052963257)
(3113, 1.0948996543884277)
(3114, 1.1046831607818604)
(3115, 1.0962800979614258)
(3116, 1.1008633375167847)
(3117, 1.0990716218948364)
(3118, 1.1003127098083496)
(3119, 1.0910065174102783)
(3120, 1.09591543674469)
(3121, 1.0984113216400146)
(3122, 1.1000149250030518)
(3123, 1.097724437713623)
(3124, 1.0996910333633423)
(3125, 1.0940097570419312)
(3126, 1.0867598056793213)
(3127, 1.0973314046859741)
(3128, 1.0973185300827026)
(3129, 1.094124674797058)
(3130, 1.1003577709197998)
(3131, 1.1000301837921143)
(3132, 1.111271858215332)
(3133, 1.0970020294189453)
(3134, 1.0995454788208008)
(3135, 1.1004157066345215)
(3136, 1.098423957824707)
(3137, 1.1025125980377197)
(3138, 1.1004002094268799)
(3139, 1.096036672592163)
(3140, 1.0974863767623901)
(3141, 1.0963680744171143)
(3142, 1.104490041732788)
(3143, 1.1058117151260376)
(3144, 1.0986772775650024)
(3145, 1.0889968872070312)
(3146, 1.1047894954681396)
(3147, 1.096675157546997)
(3148, 1.0964888334274292)
(3149, 1.1018041372299194)
(3150, 1.1030535697937012)
(3151, 1.1050305366516113)
(3152, 1.1036388874053955)
(3153, 1.0925343036651611)
(3154, 1.0991283655166626)
(3155, 1.0956687927246094)
(3156, 1.1015186309814453)
(3157, 1.102383017539978)
(3158, 1.1004301309585571)
(3159, 1.090922474861145)
(3160, 1.1085280179977417)
(3161, 1.1010991334915161)
(3162, 1.0993130207061768)
(3163, 1.0931740999221802)
(3164, 1.0846492052078247)
(3165, 1.099352240562439)
(3166, 1.1039592027664185)
(3167, 1.094064712524414)
(3168, 1.0983541011810303)
(3169, 1.099472165107727)
(3170, 1.0990469455718994)
(3171, 1.1098626852035522)
(3172, 1.098973274230957)
(3173, 1.0973695516586304)
(3174, 1.1040663719177246)
(3175, 1.112751841545105)
(3176, 1.1052627563476562)
(3177, 1.107121229171753)
(3178, 1.1022660732269287)
(3179, 1.0978235006332397)
(3180, 1.1074018478393555)
(3181, 1.100334644317627)
(3182, 1.106150507926941)
(3183, 1.0957376956939697)
(3184, 1.0894043445587158)
(3185, 1.0999878644943237)
(3186, 1.0921897888183594)
(3187, 1.0950932502746582)
(3188, 1.101754903793335)
(3189, 1.0967084169387817)
(3190, 1.0962443351745605)
(3191, 1.0988798141479492)
(3192, 1.100255012512207)
(3193, 1.093617558479309)
(3194, 1.0975227355957031)
(3195, 1.0996400117874146)
(3196, 1.1054762601852417)
(3197, 1.1088768243789673)
(3198, 1.0985419750213623)
(3199, 1.095867395401001)
(3200, 1.1023005247116089)
Train Epoch: 0 [6400/549367 (37%)]	Loss: 1.102301
(3201, 1.1079018115997314)
(3202, 1.0969836711883545)
(3203, 1.0979984998703003)
(3204, 1.1037477254867554)
(3205, 1.1022560596466064)
(3206, 1.100588083267212)
(3207, 1.0993874073028564)
(3208, 1.097356915473938)
(3209, 1.0999023914337158)
(3210, 1.1017040014266968)
(3211, 1.0948450565338135)
(3212, 1.1046547889709473)
(3213, 1.1007617712020874)
(3214, 1.103533387184143)
(3215, 1.1005784273147583)
(3216, 1.0975180864334106)
(3217, 1.0987783670425415)
(3218, 1.091248631477356)
(3219, 1.095784068107605)
(3220, 1.10441255569458)
(3221, 1.0992259979248047)
(3222, 1.0938410758972168)
(3223, 1.1028083562850952)
(3224, 1.0990290641784668)
(3225, 1.1031315326690674)
(3226, 1.0986806154251099)
(3227, 1.100698709487915)
(3228, 1.1066806316375732)
(3229, 1.1017242670059204)
(3230, 1.1001440286636353)
(3231, 1.0948041677474976)
(3232, 1.093686580657959)
(3233, 1.1024352312088013)
(3234, 1.1025489568710327)
(3235, 1.0969524383544922)
(3236, 1.0987110137939453)
(3237, 1.0868213176727295)
(3238, 1.1004862785339355)
(3239, 1.100111484527588)
(3240, 1.0987077951431274)
(3241, 1.0953521728515625)
(3242, 1.0964702367782593)
(3243, 1.0974169969558716)
(3244, 1.0860861539840698)
(3245, 1.0997854471206665)
(3246, 1.0926754474639893)
(3247, 1.1000713109970093)
(3248, 1.0963308811187744)
(3249, 1.1062184572219849)
(3250, 1.0957447290420532)
(3251, 1.0926320552825928)
(3252, 1.105069637298584)
(3253, 1.1031532287597656)
(3254, 1.1008492708206177)
(3255, 1.1007694005966187)
(3256, 1.1021883487701416)
(3257, 1.08640718460083)
(3258, 1.0939916372299194)
(3259, 1.0886834859848022)
(3260, 1.0944907665252686)
(3261, 1.1040462255477905)
(3262, 1.098778247833252)
(3263, 1.1007343530654907)
(3264, 1.0935486555099487)
(3265, 1.0910578966140747)
(3266, 1.1008565425872803)
(3267, 1.1022495031356812)
(3268, 1.1046653985977173)
(3269, 1.0947624444961548)
(3270, 1.1051321029663086)
(3271, 1.101817011833191)
(3272, 1.0968799591064453)
(3273, 1.0993099212646484)
(3274, 1.0958586931228638)
(3275, 1.1032553911209106)
(3276, 1.1019090414047241)
(3277, 1.1019556522369385)
(3278, 1.0876134634017944)
(3279, 1.103220820426941)
(3280, 1.1097577810287476)
(3281, 1.0952259302139282)
(3282, 1.0940395593643188)
(3283, 1.0929359197616577)
(3284, 1.0890154838562012)
(3285, 1.1131256818771362)
(3286, 1.0984636545181274)
(3287, 1.0972812175750732)
(3288, 1.090379238128662)
(3289, 1.097507119178772)
(3290, 1.0965564250946045)
(3291, 1.1011745929718018)
(3292, 1.1025049686431885)
(3293, 1.101444959640503)
(3294, 1.0967494249343872)
(3295, 1.1057566404342651)
(3296, 1.1032363176345825)
(3297, 1.1064666509628296)
(3298, 1.0925229787826538)
(3299, 1.1023448705673218)
(3300, 1.0997527837753296)
Train Epoch: 0 [6600/549367 (38%)]	Loss: 1.099753
(3301, 1.091763973236084)
(3302, 1.097409963607788)
(3303, 1.089910626411438)
(3304, 1.1044598817825317)
(3305, 1.100890874862671)
(3306, 1.0922930240631104)
(3307, 1.0918201208114624)
(3308, 1.102968692779541)
(3309, 1.105937123298645)
(3310, 1.1021597385406494)
(3311, 1.0999006032943726)
(3312, 1.100870966911316)
(3313, 1.092125415802002)
(3314, 1.0917240381240845)
(3315, 1.0983768701553345)
(3316, 1.102097988128662)
(3317, 1.1090656518936157)
(3318, 1.109845757484436)
(3319, 1.099514365196228)
(3320, 1.1007473468780518)
(3321, 1.0991781949996948)
(3322, 1.1053268909454346)
(3323, 1.0998138189315796)
(3324, 1.10438871383667)
(3325, 1.0995209217071533)
(3326, 1.095211386680603)
(3327, 1.099462628364563)
(3328, 1.091631293296814)
(3329, 1.1011146306991577)
(3330, 1.0997568368911743)
(3331, 1.100085735321045)
(3332, 1.1045962572097778)
(3333, 1.0981727838516235)
(3334, 1.1027990579605103)
(3335, 1.1003443002700806)
(3336, 1.098629355430603)
(3337, 1.103971004486084)
(3338, 1.0987924337387085)
(3339, 1.0970979928970337)
(3340, 1.1101632118225098)
(3341, 1.092003345489502)
(3342, 1.104365587234497)
(3343, 1.0995984077453613)
(3344, 1.0988383293151855)
(3345, 1.0986690521240234)
(3346, 1.0968283414840698)
(3347, 1.0901439189910889)
(3348, 1.0912021398544312)
(3349, 1.0961257219314575)
(3350, 1.0900837182998657)
(3351, 1.101698398590088)
(3352, 1.1072170734405518)
(3353, 1.0965867042541504)
(3354, 1.1049718856811523)
(3355, 1.0988612174987793)
(3356, 1.0993016958236694)
(3357, 1.0967875719070435)
(3358, 1.0964469909667969)
(3359, 1.097795844078064)
(3360, 1.1010510921478271)
(3361, 1.0999552011489868)
(3362, 1.1001490354537964)
(3363, 1.1059759855270386)
(3364, 1.1083931922912598)
(3365, 1.097372055053711)
(3366, 1.0912251472473145)
(3367, 1.1067405939102173)
(3368, 1.0993894338607788)
(3369, 1.0968362092971802)
(3370, 1.103531002998352)
(3371, 1.100468635559082)
(3372, 1.0977888107299805)
(3373, 1.097468614578247)
(3374, 1.105477213859558)
(3375, 1.1047563552856445)
(3376, 1.1044403314590454)
(3377, 1.097980260848999)
(3378, 1.099109411239624)
(3379, 1.0966565608978271)
(3380, 1.101503610610962)
(3381, 1.1112321615219116)
(3382, 1.0958160161972046)
(3383, 1.1141773462295532)
(3384, 1.0951212644577026)
(3385, 1.097132682800293)
(3386, 1.0965925455093384)
(3387, 1.10097336769104)
(3388, 1.0974562168121338)
(3389, 1.089072585105896)
(3390, 1.1068073511123657)
(3391, 1.0944828987121582)
(3392, 1.0950498580932617)
(3393, 1.100036382675171)
(3394, 1.0997940301895142)
(3395, 1.0995649099349976)
(3396, 1.1051537990570068)
(3397, 1.1012554168701172)
(3398, 1.1019474267959595)
(3399, 1.1055269241333008)
(3400, 1.102708339691162)
Train Epoch: 0 [6800/549367 (40%)]	Loss: 1.102708
(3401, 1.0986305475234985)
(3402, 1.1004483699798584)
(3403, 1.1064764261245728)
(3404, 1.1011769771575928)
(3405, 1.103384256362915)
(3406, 1.0984135866165161)
(3407, 1.0913885831832886)
(3408, 1.1023600101470947)
(3409, 1.094531536102295)
(3410, 1.099105715751648)
(3411, 1.0981189012527466)
(3412, 1.0998332500457764)
(3413, 1.1068195104599)
(3414, 1.0958454608917236)
(3415, 1.1028151512145996)
(3416, 1.0966734886169434)
(3417, 1.101670265197754)
(3418, 1.1043156385421753)
(3419, 1.0970993041992188)
(3420, 1.0901321172714233)
(3421, 1.101514458656311)
(3422, 1.102995753288269)
(3423, 1.0933135747909546)
(3424, 1.0925114154815674)
(3425, 1.103535771369934)
(3426, 1.1013844013214111)
(3427, 1.1006468534469604)
(3428, 1.1079529523849487)
(3429, 1.1017169952392578)
(3430, 1.1022995710372925)
(3431, 1.096817135810852)
(3432, 1.102973222732544)
(3433, 1.096428394317627)
(3434, 1.1005741357803345)
(3435, 1.1002122163772583)
(3436, 1.0949453115463257)
(3437, 1.0965720415115356)
(3438, 1.0965527296066284)
(3439, 1.1058703660964966)
(3440, 1.0874412059783936)
(3441, 1.0994234085083008)
(3442, 1.092936635017395)
(3443, 1.0957562923431396)
(3444, 1.0917869806289673)
(3445, 1.1013400554656982)
(3446, 1.1027063131332397)
(3447, 1.0992262363433838)
(3448, 1.1030805110931396)
(3449, 1.0997653007507324)
(3450, 1.0966192483901978)
(3451, 1.0977685451507568)
(3452, 1.0979337692260742)
(3453, 1.0990180969238281)
(3454, 1.0972362756729126)
(3455, 1.0971614122390747)
(3456, 1.0965514183044434)
(3457, 1.1066877841949463)
(3458, 1.094560980796814)
(3459, 1.1038223505020142)
(3460, 1.1007388830184937)
(3461, 1.0997766256332397)
(3462, 1.0953935384750366)
(3463, 1.0967159271240234)
(3464, 1.1002001762390137)
(3465, 1.0963807106018066)
(3466, 1.0990256071090698)
(3467, 1.1016929149627686)
(3468, 1.1037863492965698)
(3469, 1.1021807193756104)
(3470, 1.0937678813934326)
(3471, 1.0905084609985352)
(3472, 1.0982333421707153)
(3473, 1.09613835811615)
(3474, 1.0974292755126953)
(3475, 1.0938245058059692)
(3476, 1.097147822380066)
(3477, 1.1055076122283936)
(3478, 1.0928763151168823)
(3479, 1.104678988456726)
(3480, 1.0954254865646362)
(3481, 1.101485252380371)
(3482, 1.106507420539856)
(3483, 1.106278657913208)
(3484, 1.0992989540100098)
(3485, 1.0929745435714722)
(3486, 1.1051305532455444)
(3487, 1.1049935817718506)
(3488, 1.1037808656692505)
(3489, 1.0922167301177979)
(3490, 1.0896505117416382)
(3491, 1.0992547273635864)
(3492, 1.1005457639694214)
(3493, 1.0974701642990112)
(3494, 1.095422387123108)
(3495, 1.0976945161819458)
(3496, 1.1002169847488403)
(3497, 1.0964137315750122)
(3498, 1.0972042083740234)
(3499, 1.1054949760437012)
(3500, 1.094968318939209)
Train Epoch: 0 [7000/549367 (41%)]	Loss: 1.094968
(3501, 1.098073124885559)
(3502, 1.0999586582183838)
(3503, 1.099178671836853)
(3504, 1.0942442417144775)
(3505, 1.093441367149353)
(3506, 1.0943901538848877)
(3507, 1.0986063480377197)
(3508, 1.1039270162582397)
(3509, 1.10369873046875)
(3510, 1.0948681831359863)
(3511, 1.1072918176651)
(3512, 1.101511836051941)
(3513, 1.0973600149154663)
(3514, 1.1002998352050781)
(3515, 1.1010959148406982)
(3516, 1.1043081283569336)
(3517, 1.0873348712921143)
(3518, 1.1065176725387573)
(3519, 1.1023545265197754)
(3520, 1.1023309230804443)
(3521, 1.0978198051452637)
(3522, 1.101274847984314)
(3523, 1.091941237449646)
(3524, 1.0948978662490845)
(3525, 1.1000785827636719)
(3526, 1.09771728515625)
(3527, 1.0950790643692017)
(3528, 1.1035531759262085)
(3529, 1.0999764204025269)
(3530, 1.0999696254730225)
(3531, 1.103791356086731)
(3532, 1.1021757125854492)
(3533, 1.1011712551116943)
(3534, 1.101060390472412)
(3535, 1.1042425632476807)
(3536, 1.1010397672653198)
(3537, 1.10462486743927)
(3538, 1.0947226285934448)
(3539, 1.0976358652114868)
(3540, 1.103991150856018)
(3541, 1.0999332666397095)
(3542, 1.096222162246704)
(3543, 1.1056026220321655)
(3544, 1.1011087894439697)
(3545, 1.0983798503875732)
(3546, 1.1046983003616333)
(3547, 1.0974063873291016)
(3548, 1.0947552919387817)
(3549, 1.0965328216552734)
(3550, 1.1025505065917969)
(3551, 1.098118782043457)
(3552, 1.0989574193954468)
(3553, 1.0978047847747803)
(3554, 1.1058987379074097)
(3555, 1.1050591468811035)
(3556, 1.098057508468628)
(3557, 1.1000723838806152)
(3558, 1.1011147499084473)
(3559, 1.0967638492584229)
(3560, 1.0988839864730835)
(3561, 1.1008918285369873)
(3562, 1.1006855964660645)
(3563, 1.0995444059371948)
(3564, 1.1019703149795532)
(3565, 1.100968837738037)
(3566, 1.0970027446746826)
(3567, 1.1021349430084229)
(3568, 1.1026222705841064)
(3569, 1.0930352210998535)
(3570, 1.1019517183303833)
(3571, 1.0967004299163818)
(3572, 1.0968114137649536)
(3573, 1.101629614830017)
(3574, 1.0981035232543945)
(3575, 1.096800684928894)
(3576, 1.0976216793060303)
(3577, 1.0987613201141357)
(3578, 1.1034249067306519)
(3579, 1.094327449798584)
(3580, 1.0964571237564087)
(3581, 1.1026427745819092)
(3582, 1.1027467250823975)
(3583, 1.093929648399353)
(3584, 1.0959172248840332)
(3585, 1.09491765499115)
(3586, 1.094189167022705)
(3587, 1.100417971611023)
(3588, 1.1034480333328247)
(3589, 1.1037633419036865)
(3590, 1.0998873710632324)
(3591, 1.103212594985962)
(3592, 1.0998413562774658)
(3593, 1.1026160717010498)
(3594, 1.1010241508483887)
(3595, 1.101257562637329)
(3596, 1.1008728742599487)
(3597, 1.097672939300537)
(3598, 1.1007801294326782)
(3599, 1.0982489585876465)
(3600, 1.0998632907867432)
Train Epoch: 0 [7200/549367 (42%)]	Loss: 1.099863
(3601, 1.0976884365081787)
(3602, 1.099133849143982)
(3603, 1.1043075323104858)
(3604, 1.0996452569961548)
(3605, 1.1021393537521362)
(3606, 1.0996264219284058)
(3607, 1.1055654287338257)
(3608, 1.0988731384277344)
(3609, 1.0971876382827759)
(3610, 1.1002203226089478)
(3611, 1.0969434976577759)
(3612, 1.0980808734893799)
(3613, 1.0988363027572632)
(3614, 1.1011106967926025)
(3615, 1.1023962497711182)
(3616, 1.0967023372650146)
(3617, 1.0987569093704224)
(3618, 1.097674012184143)
(3619, 1.0973399877548218)
(3620, 1.1052579879760742)
(3621, 1.1007473468780518)
(3622, 1.0960084199905396)
(3623, 1.1053929328918457)
(3624, 1.0951358079910278)
(3625, 1.0953689813613892)
(3626, 1.100011944770813)
(3627, 1.0952651500701904)
(3628, 1.1039550304412842)
(3629, 1.0958161354064941)
(3630, 1.093706727027893)
(3631, 1.1036577224731445)
(3632, 1.1038029193878174)
(3633, 1.1003351211547852)
(3634, 1.0967252254486084)
(3635, 1.095219612121582)
(3636, 1.0961462259292603)
(3637, 1.0992116928100586)
(3638, 1.1063251495361328)
(3639, 1.103516697883606)
(3640, 1.1014130115509033)
(3641, 1.099134922027588)
(3642, 1.1032054424285889)
(3643, 1.1037582159042358)
(3644, 1.0957493782043457)
(3645, 1.0955640077590942)
(3646, 1.0965710878372192)
(3647, 1.0973526239395142)
(3648, 1.090205192565918)
(3649, 1.096184492111206)
(3650, 1.1026471853256226)
(3651, 1.0917224884033203)
(3652, 1.1017816066741943)
(3653, 1.1013133525848389)
(3654, 1.0948203802108765)
(3655, 1.0999912023544312)
(3656, 1.1023377180099487)
(3657, 1.0994449853897095)
(3658, 1.097038984298706)
(3659, 1.1046407222747803)
(3660, 1.0980621576309204)
(3661, 1.0962011814117432)
(3662, 1.1083558797836304)
(3663, 1.1047351360321045)
(3664, 1.1030770540237427)
(3665, 1.0925028324127197)
(3666, 1.099562168121338)
(3667, 1.0990232229232788)
(3668, 1.102344036102295)
(3669, 1.1017096042633057)
(3670, 1.098257064819336)
(3671, 1.0958296060562134)
(3672, 1.0930631160736084)
(3673, 1.1017978191375732)
(3674, 1.0911126136779785)
(3675, 1.107419490814209)
(3676, 1.0943471193313599)
(3677, 1.0985472202301025)
(3678, 1.106507420539856)
(3679, 1.1018580198287964)
(3680, 1.1008042097091675)
(3681, 1.1030285358428955)
(3682, 1.1113550662994385)
(3683, 1.0996006727218628)
(3684, 1.0982638597488403)
(3685, 1.1026712656021118)
(3686, 1.1006789207458496)
(3687, 1.0976096391677856)
(3688, 1.0998508930206299)
(3689, 1.0933637619018555)
(3690, 1.1003460884094238)
(3691, 1.1045339107513428)
(3692, 1.0971978902816772)
(3693, 1.1044907569885254)
(3694, 1.1025336980819702)
(3695, 1.0974375009536743)
(3696, 1.0995311737060547)
(3697, 1.1043975353240967)
(3698, 1.0932679176330566)
(3699, 1.0943219661712646)
(3700, 1.094416618347168)
Train Epoch: 0 [7400/549367 (43%)]	Loss: 1.094417
(3701, 1.1007182598114014)
(3702, 1.1010210514068604)
(3703, 1.0980249643325806)
(3704, 1.097516655921936)
(3705, 1.100495457649231)
(3706, 1.0996259450912476)
(3707, 1.0954129695892334)
(3708, 1.1002936363220215)
(3709, 1.1004124879837036)
(3710, 1.1042206287384033)
(3711, 1.1054186820983887)
(3712, 1.0966755151748657)
(3713, 1.0975033044815063)
(3714, 1.1082261800765991)
(3715, 1.0980244874954224)
(3716, 1.105592131614685)
(3717, 1.0976345539093018)
(3718, 1.0985296964645386)
(3719, 1.0974830389022827)
(3720, 1.0995051860809326)
(3721, 1.1036417484283447)
(3722, 1.0980454683303833)
(3723, 1.0944026708602905)
(3724, 1.1040606498718262)
(3725, 1.1053072214126587)
(3726, 1.0972439050674438)
(3727, 1.0959534645080566)
(3728, 1.0948048830032349)
(3729, 1.099959373474121)
(3730, 1.1007933616638184)
(3731, 1.0907708406448364)
(3732, 1.1009230613708496)
(3733, 1.0959187746047974)
(3734, 1.0971161127090454)
(3735, 1.1046226024627686)
(3736, 1.099086880683899)
(3737, 1.1002246141433716)
(3738, 1.0961178541183472)
(3739, 1.1002123355865479)
(3740, 1.101697325706482)
(3741, 1.102446436882019)
(3742, 1.0961333513259888)
(3743, 1.0982531309127808)
(3744, 1.1031213998794556)
(3745, 1.1003129482269287)
(3746, 1.096866488456726)
(3747, 1.1013439893722534)
(3748, 1.0982859134674072)
(3749, 1.0976370573043823)
(3750, 1.098378300666809)
(3751, 1.1002382040023804)
(3752, 1.0981477499008179)
(3753, 1.0983315706253052)
(3754, 1.1009312868118286)
(3755, 1.102647304534912)
(3756, 1.105219841003418)
(3757, 1.1015859842300415)
(3758, 1.098691701889038)
(3759, 1.0969316959381104)
(3760, 1.0980734825134277)
(3761, 1.0965021848678589)
(3762, 1.1002861261367798)
(3763, 1.102838397026062)
(3764, 1.100050687789917)
(3765, 1.0977580547332764)
(3766, 1.0991383790969849)
(3767, 1.1023625135421753)
(3768, 1.0997326374053955)
(3769, 1.0995510816574097)
(3770, 1.1018542051315308)
(3771, 1.0987540483474731)
(3772, 1.1004440784454346)
(3773, 1.0954252481460571)
(3774, 1.0919303894042969)
(3775, 1.1009025573730469)
(3776, 1.0959142446517944)
(3777, 1.100803017616272)
(3778, 1.0990790128707886)
(3779, 1.1075315475463867)
(3780, 1.1035740375518799)
(3781, 1.0973836183547974)
(3782, 1.0997487306594849)
(3783, 1.1011381149291992)
(3784, 1.0974509716033936)
(3785, 1.1003820896148682)
(3786, 1.0965014696121216)
(3787, 1.1007040739059448)
(3788, 1.0971317291259766)
(3789, 1.105307698249817)
(3790, 1.1047478914260864)
(3791, 1.0933963060379028)
(3792, 1.0952435731887817)
(3793, 1.0953457355499268)
(3794, 1.0936611890792847)
(3795, 1.1029622554779053)
(3796, 1.0960049629211426)
(3797, 1.0954349040985107)
(3798, 1.101304054260254)
(3799, 1.0937042236328125)
(3800, 1.101837158203125)
Train Epoch: 0 [7600/549367 (44%)]	Loss: 1.101837
(3801, 1.093592643737793)
(3802, 1.1002832651138306)
(3803, 1.0934525728225708)
(3804, 1.10201895236969)
(3805, 1.0991121530532837)
(3806, 1.099072813987732)
(3807, 1.0978285074234009)
(3808, 1.0961683988571167)
(3809, 1.0984569787979126)
(3810, 1.101380705833435)
(3811, 1.0966664552688599)
(3812, 1.101563572883606)
(3813, 1.0984536409378052)
(3814, 1.0986707210540771)
(3815, 1.1048825979232788)
(3816, 1.1027721166610718)
(3817, 1.1038473844528198)
(3818, 1.0963866710662842)
(3819, 1.1018108129501343)
(3820, 1.09938645362854)
(3821, 1.0929710865020752)
(3822, 1.0996434688568115)
(3823, 1.0951716899871826)
(3824, 1.0931651592254639)
(3825, 1.1018654108047485)
(3826, 1.1021559238433838)
(3827, 1.0994889736175537)
(3828, 1.093457579612732)
(3829, 1.1020119190216064)
(3830, 1.098225712776184)
(3831, 1.1023632287979126)
(3832, 1.099977970123291)
(3833, 1.097171664237976)
(3834, 1.1000076532363892)
(3835, 1.1032720804214478)
(3836, 1.0944021940231323)
(3837, 1.0913454294204712)
(3838, 1.102444052696228)
(3839, 1.0953564643859863)
(3840, 1.1033073663711548)
(3841, 1.1014444828033447)
(3842, 1.0986449718475342)
(3843, 1.0988050699234009)
(3844, 1.095309853553772)
(3845, 1.0924569368362427)
(3846, 1.0989176034927368)
(3847, 1.1053709983825684)
(3848, 1.0999573469161987)
(3849, 1.1030648946762085)
(3850, 1.1018329858779907)
(3851, 1.1035617589950562)
(3852, 1.0970627069473267)
(3853, 1.1002570390701294)
(3854, 1.1020489931106567)
(3855, 1.0961638689041138)
(3856, 1.1015821695327759)
(3857, 1.1039929389953613)
(3858, 1.093076229095459)
(3859, 1.0963455438613892)
(3860, 1.0951696634292603)
(3861, 1.1037969589233398)
(3862, 1.1001583337783813)
(3863, 1.0996959209442139)
(3864, 1.097392201423645)
(3865, 1.0895780324935913)
(3866, 1.100556492805481)
(3867, 1.0979193449020386)
(3868, 1.098813533782959)
(3869, 1.0962800979614258)
(3870, 1.1007392406463623)
(3871, 1.0932731628417969)
(3872, 1.1028000116348267)
(3873, 1.0947802066802979)
(3874, 1.0975632667541504)
(3875, 1.0995380878448486)
(3876, 1.1015944480895996)
(3877, 1.1009281873703003)
(3878, 1.0960290431976318)
(3879, 1.0991230010986328)
(3880, 1.0978752374649048)
(3881, 1.0957003831863403)
(3882, 1.0989247560501099)
(3883, 1.1069141626358032)
(3884, 1.1003377437591553)
(3885, 1.1014903783798218)
(3886, 1.1004654169082642)
(3887, 1.1004199981689453)
(3888, 1.0987060070037842)
(3889, 1.0976333618164062)
(3890, 1.096354603767395)
(3891, 1.0991309881210327)
(3892, 1.0979686975479126)
(3893, 1.0982835292816162)
(3894, 1.0961709022521973)
(3895, 1.099277377128601)
(3896, 1.0970743894577026)
(3897, 1.1030765771865845)
(3898, 1.0967848300933838)
(3899, 1.0957211256027222)
(3900, 1.1029644012451172)
Train Epoch: 0 [7800/549367 (45%)]	Loss: 1.102964
(3901, 1.1018657684326172)
(3902, 1.0974040031433105)
(3903, 1.1006739139556885)
(3904, 1.1014796495437622)
(3905, 1.096225619316101)
(3906, 1.1004194021224976)
(3907, 1.098225474357605)
(3908, 1.09563410282135)
(3909, 1.0976624488830566)
(3910, 1.1003692150115967)
(3911, 1.09646737575531)
(3912, 1.0979819297790527)
(3913, 1.0970370769500732)
(3914, 1.1039035320281982)
(3915, 1.0944854021072388)
(3916, 1.1005223989486694)
(3917, 1.100883960723877)
(3918, 1.098253846168518)
(3919, 1.1013818979263306)
(3920, 1.101730227470398)
(3921, 1.103739619255066)
(3922, 1.093246340751648)
(3923, 1.102703332901001)
(3924, 1.0942082405090332)
(3925, 1.1004960536956787)
(3926, 1.1012928485870361)
(3927, 1.0908604860305786)
(3928, 1.1032986640930176)
(3929, 1.0950086116790771)
(3930, 1.101750373840332)
(3931, 1.0939664840698242)
(3932, 1.1067036390304565)
(3933, 1.1067485809326172)
(3934, 1.1039295196533203)
(3935, 1.097493290901184)
(3936, 1.095574975013733)
(3937, 1.0922517776489258)
(3938, 1.0957545042037964)
(3939, 1.0991486310958862)
(3940, 1.0866154432296753)
(3941, 1.0987448692321777)
(3942, 1.1080436706542969)
(3943, 1.1010169982910156)
(3944, 1.0994607210159302)
(3945, 1.1028954982757568)
(3946, 1.1005526781082153)
(3947, 1.0965112447738647)
(3948, 1.0959683656692505)
(3949, 1.0937800407409668)
(3950, 1.1017444133758545)
(3951, 1.1057933568954468)
(3952, 1.091697335243225)
(3953, 1.1004420518875122)
(3954, 1.103145718574524)
(3955, 1.0963873863220215)
(3956, 1.0963996648788452)
(3957, 1.1007068157196045)
(3958, 1.0933493375778198)
(3959, 1.0901981592178345)
(3960, 1.1001943349838257)
(3961, 1.1054545640945435)
(3962, 1.1006731986999512)
(3963, 1.0991103649139404)
(3964, 1.0965121984481812)
(3965, 1.088962435722351)
(3966, 1.1031140089035034)
(3967, 1.0985865592956543)
(3968, 1.0942970514297485)
(3969, 1.1063004732131958)
(3970, 1.0995299816131592)
(3971, 1.0971381664276123)
(3972, 1.0976483821868896)
(3973, 1.1016548871994019)
(3974, 1.092769980430603)
(3975, 1.0934464931488037)
(3976, 1.0903651714324951)
(3977, 1.0990053415298462)
(3978, 1.1046559810638428)
(3979, 1.0943632125854492)
(3980, 1.0974645614624023)
(3981, 1.101326584815979)
(3982, 1.1012516021728516)
(3983, 1.097119688987732)
(3984, 1.1053088903427124)
(3985, 1.1054660081863403)
(3986, 1.0963568687438965)
(3987, 1.104468584060669)
(3988, 1.0954809188842773)
(3989, 1.098299264907837)
(3990, 1.0973505973815918)
(3991, 1.095363974571228)
(3992, 1.101335048675537)
(3993, 1.1005216836929321)
(3994, 1.098973035812378)
(3995, 1.1017833948135376)
(3996, 1.098838210105896)
(3997, 1.0888901948928833)
(3998, 1.0938752889633179)
(3999, 1.0963619947433472)
(4000, 1.1025251150131226)
Train Epoch: 0 [8000/549367 (47%)]	Loss: 1.102525
(4001, 1.1017956733703613)
(4002, 1.0975273847579956)
(4003, 1.0995891094207764)
(4004, 1.1047486066818237)
(4005, 1.1020011901855469)
(4006, 1.0977420806884766)
(4007, 1.1074211597442627)
(4008, 1.0964243412017822)
(4009, 1.1069949865341187)
(4010, 1.092056393623352)
(4011, 1.0960278511047363)
(4012, 1.0917075872421265)
(4013, 1.1016792058944702)
(4014, 1.0973660945892334)
(4015, 1.1034529209136963)
(4016, 1.098888874053955)
(4017, 1.1050405502319336)
(4018, 1.0973434448242188)
(4019, 1.1009331941604614)
(4020, 1.0958808660507202)
(4021, 1.0931004285812378)
(4022, 1.1028337478637695)
(4023, 1.0958157777786255)
(4024, 1.104098916053772)
(4025, 1.0988513231277466)
(4026, 1.0955959558486938)
(4027, 1.095400094985962)
(4028, 1.0925685167312622)
(4029, 1.1083102226257324)
(4030, 1.1016734838485718)
(4031, 1.1073015928268433)
(4032, 1.1045241355895996)
(4033, 1.0909265279769897)
(4034, 1.095431923866272)
(4035, 1.103575348854065)
(4036, 1.112236499786377)
(4037, 1.1014436483383179)
(4038, 1.094722867012024)
(4039, 1.0983178615570068)
(4040, 1.1065847873687744)
(4041, 1.0996211767196655)
(4042, 1.0930886268615723)
(4043, 1.094386100769043)
(4044, 1.104823350906372)
(4045, 1.1035140752792358)
(4046, 1.1054801940917969)
(4047, 1.0978001356124878)
(4048, 1.0943851470947266)
(4049, 1.0979410409927368)
(4050, 1.105047583580017)
(4051, 1.0983150005340576)
(4052, 1.1021698713302612)
(4053, 1.0949147939682007)
(4054, 1.101892113685608)
(4055, 1.1017472743988037)
(4056, 1.1015392541885376)
(4057, 1.0937203168869019)
(4058, 1.102052927017212)
(4059, 1.096356987953186)
(4060, 1.0970664024353027)
(4061, 1.100332260131836)
(4062, 1.096792221069336)
(4063, 1.1043022871017456)
(4064, 1.090683937072754)
(4065, 1.0958526134490967)
(4066, 1.0972999334335327)
(4067, 1.0941369533538818)
(4068, 1.0931895971298218)
(4069, 1.0965973138809204)
(4070, 1.0972942113876343)
(4071, 1.1090211868286133)
(4072, 1.1003711223602295)
(4073, 1.1030951738357544)
(4074, 1.0969810485839844)
(4075, 1.1038929224014282)
(4076, 1.1041467189788818)
(4077, 1.096926212310791)
(4078, 1.0933752059936523)
(4079, 1.101000428199768)
(4080, 1.1040058135986328)
(4081, 1.0893616676330566)
(4082, 1.1025859117507935)
(4083, 1.1081486940383911)
(4084, 1.100023627281189)
(4085, 1.094082236289978)
(4086, 1.1015428304672241)
(4087, 1.1076685190200806)
(4088, 1.095312476158142)
(4089, 1.0973402261734009)
(4090, 1.1057453155517578)
(4091, 1.0969663858413696)
(4092, 1.111955165863037)
(4093, 1.0978319644927979)
(4094, 1.099859356880188)
(4095, 1.1002578735351562)
(4096, 1.099745273590088)
(4097, 1.105048656463623)
(4098, 1.10032320022583)
(4099, 1.0986278057098389)
(4100, 1.1010160446166992)
Train Epoch: 0 [8200/549367 (48%)]	Loss: 1.101016
(4101, 1.1011401414871216)
(4102, 1.097814917564392)
(4103, 1.0991073846817017)
(4104, 1.098576307296753)
(4105, 1.0974522829055786)
(4106, 1.1016457080841064)
(4107, 1.1005357503890991)
(4108, 1.0979666709899902)
(4109, 1.0997756719589233)
(4110, 1.1032764911651611)
(4111, 1.0996328592300415)
(4112, 1.1026175022125244)
(4113, 1.1014931201934814)
(4114, 1.096863865852356)
(4115, 1.1022913455963135)
(4116, 1.088628888130188)
(4117, 1.1021461486816406)
(4118, 1.1020596027374268)
(4119, 1.096215844154358)
(4120, 1.102508306503296)
(4121, 1.0940357446670532)
(4122, 1.0913461446762085)
(4123, 1.0954371690750122)
(4124, 1.1054493188858032)
(4125, 1.1028835773468018)
(4126, 1.095286250114441)
(4127, 1.0967158079147339)
(4128, 1.0987292528152466)
(4129, 1.101069688796997)
(4130, 1.1017903089523315)
(4131, 1.1018855571746826)
(4132, 1.1031253337860107)
(4133, 1.0966198444366455)
(4134, 1.0980579853057861)
(4135, 1.0995186567306519)
(4136, 1.0991541147232056)
(4137, 1.0945109128952026)
(4138, 1.102613091468811)
(4139, 1.0912277698516846)
(4140, 1.0951595306396484)
(4141, 1.1033234596252441)
(4142, 1.0980340242385864)
(4143, 1.0952550172805786)
(4144, 1.1055147647857666)
(4145, 1.0973889827728271)
(4146, 1.0968124866485596)
(4147, 1.0891774892807007)
(4148, 1.0968900918960571)
(4149, 1.0987040996551514)
(4150, 1.0985339879989624)
(4151, 1.1012791395187378)
(4152, 1.1016690731048584)
(4153, 1.0977063179016113)
(4154, 1.1023294925689697)
(4155, 1.095633864402771)
(4156, 1.0963820219039917)
(4157, 1.0969136953353882)
(4158, 1.0991871356964111)
(4159, 1.098779559135437)
(4160, 1.1082946062088013)
(4161, 1.101843237876892)
(4162, 1.0957672595977783)
(4163, 1.1008129119873047)
(4164, 1.1015244722366333)
(4165, 1.1028856039047241)
(4166, 1.0974608659744263)
(4167, 1.1030888557434082)
(4168, 1.0964348316192627)
(4169, 1.1004832983016968)
(4170, 1.0969842672348022)
(4171, 1.0971673727035522)
(4172, 1.1055970191955566)
(4173, 1.0972716808319092)
(4174, 1.100533127784729)
(4175, 1.1019752025604248)
(4176, 1.0971004962921143)
(4177, 1.0990225076675415)
(4178, 1.0937485694885254)
(4179, 1.08994722366333)
(4180, 1.0988637208938599)
(4181, 1.1088849306106567)
(4182, 1.1086375713348389)
(4183, 1.0979622602462769)
(4184, 1.0948821306228638)
(4185, 1.1000241041183472)
(4186, 1.0950872898101807)
(4187, 1.0990326404571533)
(4188, 1.1072721481323242)
(4189, 1.1046960353851318)
(4190, 1.10000479221344)
(4191, 1.1008919477462769)
(4192, 1.0907753705978394)
(4193, 1.0961695909500122)
(4194, 1.091447353363037)
(4195, 1.0960520505905151)
(4196, 1.098134160041809)
(4197, 1.1013692617416382)
(4198, 1.0979669094085693)
(4199, 1.0922287702560425)
(4200, 1.0945857763290405)
Train Epoch: 0 [8400/549367 (49%)]	Loss: 1.094586
(4201, 1.0984089374542236)
(4202, 1.0997304916381836)
(4203, 1.0970202684402466)
(4204, 1.1034132242202759)
(4205, 1.0962212085723877)
(4206, 1.0952287912368774)
(4207, 1.1001825332641602)
(4208, 1.0937305688858032)
(4209, 1.1075665950775146)
(4210, 1.098958134651184)
(4211, 1.0961979627609253)
(4212, 1.100502848625183)
(4213, 1.0923211574554443)
(4214, 1.0940604209899902)
(4215, 1.092063307762146)
(4216, 1.0974466800689697)
(4217, 1.1044526100158691)
(4218, 1.095345377922058)
(4219, 1.0976004600524902)
(4220, 1.1022593975067139)
(4221, 1.099328637123108)
(4222, 1.0994970798492432)
(4223, 1.1009516716003418)
(4224, 1.099258542060852)
(4225, 1.1034257411956787)
(4226, 1.1019731760025024)
(4227, 1.1007699966430664)
(4228, 1.0921342372894287)
(4229, 1.0936346054077148)
(4230, 1.107965350151062)
(4231, 1.0987094640731812)
(4232, 1.098167896270752)
(4233, 1.0968345403671265)
(4234, 1.1007440090179443)
(4235, 1.0936211347579956)
(4236, 1.0973175764083862)
(4237, 1.0977983474731445)
(4238, 1.1016721725463867)
(4239, 1.1031543016433716)
(4240, 1.1000909805297852)
(4241, 1.102568507194519)
(4242, 1.1023098230361938)
(4243, 1.0970206260681152)
(4244, 1.0971722602844238)
(4245, 1.093207836151123)
(4246, 1.0966284275054932)
(4247, 1.0960028171539307)
(4248, 1.0919109582901)
(4249, 1.0984774827957153)
(4250, 1.1015527248382568)
(4251, 1.0979409217834473)
(4252, 1.0983470678329468)
(4253, 1.1015524864196777)
(4254, 1.0968245267868042)
(4255, 1.1016347408294678)
(4256, 1.0952426195144653)
(4257, 1.1004726886749268)
(4258, 1.0963817834854126)
(4259, 1.102515697479248)
(4260, 1.1009209156036377)
(4261, 1.0984405279159546)
(4262, 1.0969836711883545)
(4263, 1.098628282546997)
(4264, 1.0960966348648071)
(4265, 1.1014859676361084)
(4266, 1.095367193222046)
(4267, 1.1024539470672607)
(4268, 1.093648076057434)
(4269, 1.0953248739242554)
(4270, 1.0980197191238403)
(4271, 1.1052683591842651)
(4272, 1.1118522882461548)
(4273, 1.0983773469924927)
(4274, 1.0990126132965088)
(4275, 1.1077725887298584)
(4276, 1.1002751588821411)
(4277, 1.1003780364990234)
(4278, 1.0951060056686401)
(4279, 1.0993235111236572)
(4280, 1.0991897583007812)
(4281, 1.1026294231414795)
(4282, 1.101507544517517)
(4283, 1.0931388139724731)
(4284, 1.1012742519378662)
(4285, 1.094523310661316)
(4286, 1.0956073999404907)
(4287, 1.0984835624694824)
(4288, 1.0986430644989014)
(4289, 1.0978118181228638)
(4290, 1.094037413597107)
(4291, 1.0978156328201294)
(4292, 1.100750207901001)
(4293, 1.1037167310714722)
(4294, 1.0960099697113037)
(4295, 1.0950486660003662)
(4296, 1.1000946760177612)
(4297, 1.095365047454834)
(4298, 1.0961767435073853)
(4299, 1.1042119264602661)
(4300, 1.1007591485977173)
Train Epoch: 0 [8600/549367 (50%)]	Loss: 1.100759
(4301, 1.0996960401535034)
(4302, 1.095268726348877)
(4303, 1.0992668867111206)
(4304, 1.1028746366500854)
(4305, 1.100654125213623)
(4306, 1.0968594551086426)
(4307, 1.1034953594207764)
(4308, 1.0967527627944946)
(4309, 1.0966740846633911)
(4310, 1.094495415687561)
(4311, 1.0967453718185425)
(4312, 1.104331374168396)
(4313, 1.1021227836608887)
(4314, 1.0975475311279297)
(4315, 1.1040021181106567)
(4316, 1.0970134735107422)
(4317, 1.0958048105239868)
(4318, 1.096739411354065)
(4319, 1.0999698638916016)
(4320, 1.1035676002502441)
(4321, 1.101704716682434)
(4322, 1.1007896661758423)
(4323, 1.0997538566589355)
(4324, 1.1055885553359985)
(4325, 1.0985199213027954)
(4326, 1.1010812520980835)
(4327, 1.095673680305481)
(4328, 1.0957622528076172)
(4329, 1.0959380865097046)
(4330, 1.0954790115356445)
(4331, 1.107215404510498)
(4332, 1.098096489906311)
(4333, 1.0960712432861328)
(4334, 1.0945042371749878)
(4335, 1.1046068668365479)
(4336, 1.0971276760101318)
(4337, 1.098554015159607)
(4338, 1.1053940057754517)
(4339, 1.0979573726654053)
(4340, 1.10211980342865)
(4341, 1.10157310962677)
(4342, 1.0967860221862793)
(4343, 1.1002848148345947)
(4344, 1.0999444723129272)
(4345, 1.0995800495147705)
(4346, 1.0980974435806274)
(4347, 1.1029911041259766)
(4348, 1.0975537300109863)
(4349, 1.1022499799728394)
(4350, 1.0999281406402588)
(4351, 1.0984492301940918)
(4352, 1.1003072261810303)
(4353, 1.103744387626648)
(4354, 1.1000500917434692)
(4355, 1.099972128868103)
(4356, 1.096951961517334)
(4357, 1.0999548435211182)
(4358, 1.1010345220565796)
(4359, 1.0990824699401855)
(4360, 1.0988603830337524)
(4361, 1.102203130722046)
(4362, 1.0985620021820068)
(4363, 1.0976005792617798)
(4364, 1.0987529754638672)
(4365, 1.0959373712539673)
(4366, 1.0982340574264526)
(4367, 1.100534439086914)
(4368, 1.1007425785064697)
(4369, 1.0984272956848145)
(4370, 1.1033016443252563)
(4371, 1.0988497734069824)
(4372, 1.101440191268921)
(4373, 1.0981454849243164)
(4374, 1.0972387790679932)
(4375, 1.0946056842803955)
(4376, 1.0987554788589478)
(4377, 1.0998196601867676)
(4378, 1.0984013080596924)
(4379, 1.1053258180618286)
(4380, 1.0986331701278687)
(4381, 1.0954055786132812)
(4382, 1.098361849784851)
(4383, 1.0959476232528687)
(4384, 1.0978976488113403)
(4385, 1.0994573831558228)
(4386, 1.0960502624511719)
(4387, 1.0967144966125488)
(4388, 1.1013164520263672)
(4389, 1.093911051750183)
(4390, 1.1031620502471924)
(4391, 1.1006522178649902)
(4392, 1.104022741317749)
(4393, 1.096062183380127)
(4394, 1.0947372913360596)
(4395, 1.1017671823501587)
(4396, 1.1034770011901855)
(4397, 1.1016812324523926)
(4398, 1.106188416481018)
(4399, 1.099579095840454)
(4400, 1.0962722301483154)
Train Epoch: 0 [8800/549367 (51%)]	Loss: 1.096272
(4401, 1.0974411964416504)
(4402, 1.101481556892395)
(4403, 1.101130485534668)
(4404, 1.1014961004257202)
(4405, 1.101162314414978)
(4406, 1.0986244678497314)
(4407, 1.0972882509231567)
(4408, 1.1033072471618652)
(4409, 1.0958361625671387)
(4410, 1.0987043380737305)
(4411, 1.0983595848083496)
(4412, 1.0962761640548706)
(4413, 1.105401873588562)
(4414, 1.0997275114059448)
(4415, 1.0941859483718872)
(4416, 1.0997514724731445)
(4417, 1.1001601219177246)
(4418, 1.094307541847229)
(4419, 1.098408818244934)
(4420, 1.0974175930023193)
(4421, 1.0987905263900757)
(4422, 1.0980631113052368)
(4423, 1.0954669713974)
(4424, 1.0979559421539307)
(4425, 1.1013906002044678)
(4426, 1.099085807800293)
(4427, 1.0964306592941284)
(4428, 1.0961235761642456)
(4429, 1.099160075187683)
(4430, 1.09860098361969)
(4431, 1.0987433195114136)
(4432, 1.0994844436645508)
(4433, 1.097519040107727)
(4434, 1.1046854257583618)
(4435, 1.1012606620788574)
(4436, 1.0986422300338745)
(4437, 1.0977983474731445)
(4438, 1.0999598503112793)
(4439, 1.1007944345474243)
(4440, 1.0994060039520264)
(4441, 1.0945817232131958)
(4442, 1.0993096828460693)
(4443, 1.1006691455841064)
(4444, 1.0991853475570679)
(4445, 1.0973820686340332)
(4446, 1.1003661155700684)
(4447, 1.0984270572662354)
(4448, 1.0941541194915771)
(4449, 1.0973217487335205)
(4450, 1.099304437637329)
(4451, 1.098374366760254)
(4452, 1.0979863405227661)
(4453, 1.098091959953308)
(4454, 1.0968247652053833)
(4455, 1.101384162902832)
(4456, 1.1029269695281982)
(4457, 1.0991569757461548)
(4458, 1.0959259271621704)
(4459, 1.0946393013000488)
(4460, 1.1020318269729614)
(4461, 1.0998239517211914)
(4462, 1.0950989723205566)
(4463, 1.1015418767929077)
(4464, 1.0974364280700684)
(4465, 1.0974931716918945)
(4466, 1.1011734008789062)
(4467, 1.1012006998062134)
(4468, 1.1012603044509888)
(4469, 1.0949764251708984)
(4470, 1.0988388061523438)
(4471, 1.0963597297668457)
(4472, 1.0965996980667114)
(4473, 1.1011955738067627)
(4474, 1.0976154804229736)
(4475, 1.099107265472412)
(4476, 1.0957565307617188)
(4477, 1.1055552959442139)
(4478, 1.1037483215332031)
(4479, 1.096196174621582)
(4480, 1.1009573936462402)
(4481, 1.0965901613235474)
(4482, 1.100073218345642)
(4483, 1.1069395542144775)
(4484, 1.100965142250061)
(4485, 1.1043336391448975)
(4486, 1.1026514768600464)
(4487, 1.0946756601333618)
(4488, 1.1049509048461914)
(4489, 1.0993202924728394)
(4490, 1.1010863780975342)
(4491, 1.0948326587677002)
(4492, 1.1005346775054932)
(4493, 1.0953985452651978)
(4494, 1.0977592468261719)
(4495, 1.09994375705719)
(4496, 1.0964999198913574)
(4497, 1.1001765727996826)
(4498, 1.1075385808944702)
(4499, 1.1000242233276367)
(4500, 1.1046563386917114)
Train Epoch: 0 [9000/549367 (52%)]	Loss: 1.104656
(4501, 1.096022367477417)
(4502, 1.1038206815719604)
(4503, 1.09891939163208)
(4504, 1.1014333963394165)
(4505, 1.100878119468689)
(4506, 1.0978455543518066)
(4507, 1.102146863937378)
(4508, 1.0978636741638184)
(4509, 1.0971990823745728)
(4510, 1.10200834274292)
(4511, 1.1022104024887085)
(4512, 1.100656270980835)
(4513, 1.0985357761383057)
(4514, 1.0979222059249878)
(4515, 1.1006642580032349)
(4516, 1.1010278463363647)
(4517, 1.1004711389541626)
(4518, 1.099910855293274)
(4519, 1.1022685766220093)
(4520, 1.0978174209594727)
(4521, 1.0981237888336182)
(4522, 1.0954394340515137)
(4523, 1.106199860572815)
(4524, 1.100764513015747)
(4525, 1.1048177480697632)
(4526, 1.0988537073135376)
(4527, 1.099281907081604)
(4528, 1.0941851139068604)
(4529, 1.105966567993164)
(4530, 1.0988736152648926)
(4531, 1.103975772857666)
(4532, 1.1003786325454712)
(4533, 1.092670202255249)
(4534, 1.0965371131896973)
(4535, 1.0956854820251465)
(4536, 1.0979496240615845)
(4537, 1.0969642400741577)
(4538, 1.0947811603546143)
(4539, 1.099083662033081)
(4540, 1.100126028060913)
(4541, 1.102527141571045)
(4542, 1.0976006984710693)
(4543, 1.097501516342163)
(4544, 1.1021345853805542)
(4545, 1.101629614830017)
(4546, 1.098902702331543)
(4547, 1.0960017442703247)
(4548, 1.0982962846755981)
(4549, 1.095733642578125)
(4550, 1.0995063781738281)
(4551, 1.1030396223068237)
(4552, 1.0991572141647339)
(4553, 1.1026631593704224)
(4554, 1.0962443351745605)
(4555, 1.0931493043899536)
(4556, 1.0987818241119385)
(4557, 1.1015002727508545)
(4558, 1.100304365158081)
(4559, 1.0929311513900757)
(4560, 1.0961183309555054)
(4561, 1.096663236618042)
(4562, 1.0929069519042969)
(4563, 1.0933455228805542)
(4564, 1.0989824533462524)
(4565, 1.0981920957565308)
(4566, 1.1051368713378906)
(4567, 1.0975490808486938)
(4568, 1.0995806455612183)
(4569, 1.0949897766113281)
(4570, 1.1044179201126099)
(4571, 1.1029914617538452)
(4572, 1.101657509803772)
(4573, 1.1005709171295166)
(4574, 1.0944486856460571)
(4575, 1.096206784248352)
(4576, 1.1093940734863281)
(4577, 1.101819634437561)
(4578, 1.1040959358215332)
(4579, 1.1044796705245972)
(4580, 1.098402738571167)
(4581, 1.1003749370574951)
(4582, 1.099215030670166)
(4583, 1.0955753326416016)
(4584, 1.0968873500823975)
(4585, 1.1017578840255737)
(4586, 1.1008697748184204)
(4587, 1.0976743698120117)
(4588, 1.099416971206665)
(4589, 1.0974026918411255)
(4590, 1.1003587245941162)
(4591, 1.0962897539138794)
(4592, 1.0972658395767212)
(4593, 1.0994899272918701)
(4594, 1.0949068069458008)
(4595, 1.0963690280914307)
(4596, 1.0985420942306519)
(4597, 1.0997741222381592)
(4598, 1.097907304763794)
(4599, 1.0961403846740723)
(4600, 1.10428786277771)
Train Epoch: 0 [9200/549367 (54%)]	Loss: 1.104288
(4601, 1.0962191820144653)
(4602, 1.0994044542312622)
(4603, 1.0981518030166626)
(4604, 1.0984796285629272)
(4605, 1.100535273551941)
(4606, 1.1001330614089966)
(4607, 1.0977705717086792)
(4608, 1.0927399396896362)
(4609, 1.1003718376159668)
(4610, 1.0977555513381958)
(4611, 1.1008061170578003)
(4612, 1.10438072681427)
(4613, 1.0992462635040283)
(4614, 1.1036036014556885)
(4615, 1.099339246749878)
(4616, 1.0951788425445557)
(4617, 1.0994561910629272)
(4618, 1.0991019010543823)
(4619, 1.1089098453521729)
(4620, 1.0984975099563599)
(4621, 1.0977059602737427)
(4622, 1.0969226360321045)
(4623, 1.0900027751922607)
(4624, 1.0913814306259155)
(4625, 1.1041587591171265)
(4626, 1.0929710865020752)
(4627, 1.0976712703704834)
(4628, 1.0940269231796265)
(4629, 1.1025410890579224)
(4630, 1.0969291925430298)
(4631, 1.0970773696899414)
(4632, 1.096853494644165)
(4633, 1.096174955368042)
(4634, 1.1007423400878906)
(4635, 1.0982449054718018)
(4636, 1.091313362121582)
(4637, 1.0986984968185425)
(4638, 1.0985286235809326)
(4639, 1.0975309610366821)
(4640, 1.099368691444397)
(4641, 1.09328293800354)
(4642, 1.1016781330108643)
(4643, 1.0961071252822876)
(4644, 1.1010570526123047)
(4645, 1.09463369846344)
(4646, 1.1036490201950073)
(4647, 1.1069674491882324)
(4648, 1.0974388122558594)
(4649, 1.0974317789077759)
(4650, 1.1108829975128174)
(4651, 1.099245309829712)
(4652, 1.1019383668899536)
(4653, 1.1057507991790771)
(4654, 1.0870970487594604)
(4655, 1.097901701927185)
(4656, 1.0992670059204102)
(4657, 1.1029945611953735)
(4658, 1.097629427909851)
(4659, 1.1027039289474487)
(4660, 1.0997076034545898)
(4661, 1.1026920080184937)
(4662, 1.0998103618621826)
(4663, 1.1050525903701782)
(4664, 1.0947260856628418)
(4665, 1.0946701765060425)
(4666, 1.1008226871490479)
(4667, 1.1084181070327759)
(4668, 1.108494520187378)
(4669, 1.1058578491210938)
(4670, 1.1063729524612427)
(4671, 1.098237156867981)
(4672, 1.095679521560669)
(4673, 1.1005100011825562)
(4674, 1.0994772911071777)
(4675, 1.0910675525665283)
(4676, 1.0982377529144287)
(4677, 1.0999832153320312)
(4678, 1.0970134735107422)
(4679, 1.098218321800232)
(4680, 1.1034572124481201)
(4681, 1.0983768701553345)
(4682, 1.0912511348724365)
(4683, 1.0989609956741333)
(4684, 1.102003812789917)
(4685, 1.1104060411453247)
(4686, 1.0997439622879028)
(4687, 1.0999795198440552)
(4688, 1.097002625465393)
(4689, 1.0946022272109985)
(4690, 1.099464774131775)
(4691, 1.100498914718628)
(4692, 1.1021603345870972)
(4693, 1.1009416580200195)
(4694, 1.0949926376342773)
(4695, 1.102000117301941)
(4696, 1.095459222793579)
(4697, 1.096633791923523)
(4698, 1.0981711149215698)
(4699, 1.1008528470993042)
(4700, 1.0994021892547607)
Train Epoch: 0 [9400/549367 (55%)]	Loss: 1.099402
(4701, 1.1019150018692017)
(4702, 1.1079223155975342)
(4703, 1.1024575233459473)
(4704, 1.0976736545562744)
(4705, 1.0987170934677124)
(4706, 1.1013762950897217)
(4707, 1.099517583847046)
(4708, 1.1024905443191528)
(4709, 1.1087628602981567)
(4710, 1.1002639532089233)
(4711, 1.1014639139175415)
(4712, 1.1053298711776733)
(4713, 1.0962070226669312)
(4714, 1.0995256900787354)
(4715, 1.0972617864608765)
(4716, 1.0930041074752808)
(4717, 1.0989199876785278)
(4718, 1.0933558940887451)
(4719, 1.0996921062469482)
(4720, 1.1041890382766724)
(4721, 1.091393232345581)
(4722, 1.0992107391357422)
(4723, 1.0973492860794067)
(4724, 1.0985921621322632)
(4725, 1.104099988937378)
(4726, 1.097306728363037)
(4727, 1.1018257141113281)
(4728, 1.0957581996917725)
(4729, 1.0999665260314941)
(4730, 1.1012972593307495)
(4731, 1.099605917930603)
(4732, 1.0972033739089966)
(4733, 1.1020888090133667)
(4734, 1.098662257194519)
(4735, 1.098918080329895)
(4736, 1.09784734249115)
(4737, 1.0942949056625366)
(4738, 1.096588134765625)
(4739, 1.0994737148284912)
(4740, 1.1037110090255737)
(4741, 1.0990524291992188)
(4742, 1.10068678855896)
(4743, 1.1012015342712402)
(4744, 1.0989052057266235)
(4745, 1.10298752784729)
(4746, 1.0997577905654907)
(4747, 1.1021238565444946)
(4748, 1.0998378992080688)
(4749, 1.0982588529586792)
(4750, 1.0926287174224854)
(4751, 1.0974875688552856)
(4752, 1.0954699516296387)
(4753, 1.1003152132034302)
(4754, 1.1012866497039795)
(4755, 1.0937741994857788)
(4756, 1.1022295951843262)
(4757, 1.0959759950637817)
(4758, 1.099711298942566)
(4759, 1.103072166442871)
(4760, 1.0989121198654175)
(4761, 1.095879077911377)
(4762, 1.1067087650299072)
(4763, 1.1003837585449219)
(4764, 1.0962586402893066)
(4765, 1.0982471704483032)
(4766, 1.096434235572815)
(4767, 1.0979183912277222)
(4768, 1.101335048675537)
(4769, 1.0987358093261719)
(4770, 1.1025334596633911)
(4771, 1.1018445491790771)
(4772, 1.1000157594680786)
(4773, 1.0936381816864014)
(4774, 1.0932393074035645)
(4775, 1.094251275062561)
(4776, 1.1017725467681885)
(4777, 1.1036237478256226)
(4778, 1.0997552871704102)
(4779, 1.0974323749542236)
(4780, 1.0968178510665894)
(4781, 1.0960733890533447)
(4782, 1.0981793403625488)
(4783, 1.1034616231918335)
(4784, 1.0979820489883423)
(4785, 1.099585771560669)
(4786, 1.0996674299240112)
(4787, 1.0996609926223755)
(4788, 1.1010925769805908)
(4789, 1.102163314819336)
(4790, 1.095107913017273)
(4791, 1.0946600437164307)
(4792, 1.1031285524368286)
(4793, 1.102125883102417)
(4794, 1.0953657627105713)
(4795, 1.0986733436584473)
(4796, 1.097403883934021)
(4797, 1.099603295326233)
(4798, 1.1041349172592163)
(4799, 1.097904086112976)
(4800, 1.0963821411132812)
Train Epoch: 0 [9600/549367 (56%)]	Loss: 1.096382
(4801, 1.100635290145874)
(4802, 1.0936177968978882)
(4803, 1.0989371538162231)
(4804, 1.1018825769424438)
(4805, 1.1070809364318848)
(4806, 1.0996601581573486)
(4807, 1.0984537601470947)
(4808, 1.0946471691131592)
(4809, 1.103398323059082)
(4810, 1.104593276977539)
(4811, 1.0969494581222534)
(4812, 1.1026030778884888)
(4813, 1.1009758710861206)
(4814, 1.1017056703567505)
(4815, 1.0961787700653076)
(4816, 1.0974739789962769)
(4817, 1.100530743598938)
(4818, 1.1024293899536133)
(4819, 1.1027145385742188)
(4820, 1.0958245992660522)
(4821, 1.097004771232605)
(4822, 1.09965181350708)
(4823, 1.0947054624557495)
(4824, 1.1018885374069214)
(4825, 1.0973663330078125)
(4826, 1.0960196256637573)
(4827, 1.0984374284744263)
(4828, 1.1001921892166138)
(4829, 1.1000045537948608)
(4830, 1.0977894067764282)
(4831, 1.0986342430114746)
(4832, 1.09888756275177)
(4833, 1.1009563207626343)
(4834, 1.0986461639404297)
(4835, 1.0965447425842285)
(4836, 1.099923014640808)
(4837, 1.0989025831222534)
(4838, 1.0948067903518677)
(4839, 1.0950416326522827)
(4840, 1.0993486642837524)
(4841, 1.0989446640014648)
(4842, 1.0951097011566162)
(4843, 1.0986504554748535)
(4844, 1.096019983291626)
(4845, 1.0941728353500366)
(4846, 1.0976653099060059)
(4847, 1.100855827331543)
(4848, 1.1001200675964355)
(4849, 1.0976173877716064)
(4850, 1.0994848012924194)
(4851, 1.0984396934509277)
(4852, 1.1013095378875732)
(4853, 1.1013102531433105)
(4854, 1.100042462348938)
(4855, 1.0959926843643188)
(4856, 1.0955810546875)
(4857, 1.0980197191238403)
(4858, 1.0981667041778564)
(4859, 1.099876046180725)
(4860, 1.0968464612960815)
(4861, 1.100780963897705)
(4862, 1.1031962633132935)
(4863, 1.0990281105041504)
(4864, 1.0986071825027466)
(4865, 1.0990939140319824)
(4866, 1.1017780303955078)
(4867, 1.106866717338562)
(4868, 1.0969172716140747)
(4869, 1.0984752178192139)
(4870, 1.0955169200897217)
(4871, 1.1036403179168701)
(4872, 1.1019169092178345)
(4873, 1.1013203859329224)
(4874, 1.1003172397613525)
(4875, 1.0982083082199097)
(4876, 1.095677137374878)
(4877, 1.0989097356796265)
(4878, 1.0978384017944336)
(4879, 1.0974116325378418)
(4880, 1.1046656370162964)
(4881, 1.0971430540084839)
(4882, 1.1044621467590332)
(4883, 1.098065972328186)
(4884, 1.099861741065979)
(4885, 1.0987423658370972)
(4886, 1.1020562648773193)
(4887, 1.1010470390319824)
(4888, 1.0965166091918945)
(4889, 1.098107933998108)
(4890, 1.1036715507507324)
(4891, 1.0967659950256348)
(4892, 1.0947295427322388)
(4893, 1.0957499742507935)
(4894, 1.1000211238861084)
(4895, 1.0964421033859253)
(4896, 1.0970021486282349)
(4897, 1.1000674962997437)
(4898, 1.0978184938430786)
(4899, 1.100754976272583)
(4900, 1.0981508493423462)
Train Epoch: 0 [9800/549367 (57%)]	Loss: 1.098151
(4901, 1.0975147485733032)
(4902, 1.099579930305481)
(4903, 1.0974798202514648)
(4904, 1.0990689992904663)
(4905, 1.1003546714782715)
(4906, 1.1021174192428589)
(4907, 1.1009818315505981)
(4908, 1.0976502895355225)
(4909, 1.0984735488891602)
(4910, 1.0969066619873047)
(4911, 1.0992224216461182)
(4912, 1.09538996219635)
(4913, 1.0964362621307373)
(4914, 1.100091814994812)
(4915, 1.098037600517273)
(4916, 1.104361891746521)
(4917, 1.095998764038086)
(4918, 1.1009944677352905)
(4919, 1.1023789644241333)
(4920, 1.0980827808380127)
(4921, 1.0961558818817139)
(4922, 1.0991579294204712)
(4923, 1.097503900527954)
(4924, 1.0940102338790894)
(4925, 1.1016219854354858)
(4926, 1.0970003604888916)
(4927, 1.1012372970581055)
(4928, 1.0969318151474)
(4929, 1.0964164733886719)
(4930, 1.099238395690918)
(4931, 1.102489948272705)
(4932, 1.099625587463379)
(4933, 1.098046898841858)
(4934, 1.1005263328552246)
(4935, 1.0993245840072632)
(4936, 1.0984723567962646)
(4937, 1.1028008460998535)
(4938, 1.0967893600463867)
(4939, 1.0965101718902588)
(4940, 1.1034144163131714)
(4941, 1.0963021516799927)
(4942, 1.0985993146896362)
(4943, 1.0972974300384521)
(4944, 1.0985556840896606)
(4945, 1.095650315284729)
(4946, 1.0983858108520508)
(4947, 1.097870945930481)
(4948, 1.1017731428146362)
(4949, 1.0987235307693481)
(4950, 1.1001784801483154)
(4951, 1.0908693075180054)
(4952, 1.0965981483459473)
(4953, 1.1005388498306274)
(4954, 1.1001633405685425)
(4955, 1.0949733257293701)
(4956, 1.096269965171814)
(4957, 1.0970721244812012)
(4958, 1.0988199710845947)
(4959, 1.0969135761260986)
(4960, 1.1020700931549072)
(4961, 1.0960330963134766)
(4962, 1.1029433012008667)
(4963, 1.0979375839233398)
(4964, 1.0989437103271484)
(4965, 1.1008338928222656)
(4966, 1.1018303632736206)
(4967, 1.1006853580474854)
(4968, 1.0994778871536255)
(4969, 1.0975635051727295)
(4970, 1.1075725555419922)
(4971, 1.102270245552063)
(4972, 1.0968531370162964)
(4973, 1.0978038311004639)
(4974, 1.0947518348693848)
(4975, 1.0978584289550781)
(4976, 1.1024295091629028)
(4977, 1.1056418418884277)
(4978, 1.100319504737854)
(4979, 1.102531909942627)
(4980, 1.1116946935653687)
(4981, 1.0959755182266235)
(4982, 1.0962505340576172)
(4983, 1.0975297689437866)
(4984, 1.0966167449951172)
(4985, 1.1021835803985596)
(4986, 1.1019601821899414)
(4987, 1.0977603197097778)
(4988, 1.0956909656524658)
(4989, 1.0997861623764038)
(4990, 1.1121041774749756)
(4991, 1.1021616458892822)
(4992, 1.1013233661651611)
(4993, 1.0981605052947998)
(4994, 1.0968412160873413)
(4995, 1.0928575992584229)
(4996, 1.1000491380691528)
(4997, 1.103676199913025)
(4998, 1.0921214818954468)
(4999, 1.1009482145309448)
(5000, 1.0932462215423584)
Train Epoch: 0 [10000/549367 (58%)]	Loss: 1.093246
(5001, 1.0977706909179688)
(5002, 1.1035596132278442)
(5003, 1.0972760915756226)
(5004, 1.1001676321029663)
(5005, 1.1008915901184082)
(5006, 1.1031476259231567)
(5007, 1.0972312688827515)
(5008, 1.1085320711135864)
(5009, 1.105908751487732)
(5010, 1.1054694652557373)
(5011, 1.0921005010604858)
(5012, 1.0973351001739502)
(5013, 1.099156379699707)
(5014, 1.1009008884429932)
(5015, 1.100797414779663)
(5016, 1.100804090499878)
(5017, 1.0942473411560059)
(5018, 1.098816990852356)
(5019, 1.0997695922851562)
(5020, 1.1000430583953857)
(5021, 1.100697636604309)
(5022, 1.0991754531860352)
(5023, 1.0990780591964722)
(5024, 1.0990349054336548)
(5025, 1.10137140750885)
(5026, 1.0951662063598633)
(5027, 1.0996757745742798)
(5028, 1.099532961845398)
(5029, 1.1000186204910278)
(5030, 1.1012178659439087)
(5031, 1.0962262153625488)
(5032, 1.0959550142288208)
(5033, 1.1012451648712158)
(5034, 1.102117896080017)
(5035, 1.0967093706130981)
(5036, 1.0942718982696533)
(5037, 1.1000256538391113)
(5038, 1.100767731666565)
(5039, 1.102182388305664)
(5040, 1.0981078147888184)
(5041, 1.1008541584014893)
(5042, 1.0989575386047363)
(5043, 1.101786732673645)
(5044, 1.101458191871643)
(5045, 1.1001373529434204)
(5046, 1.0944358110427856)
(5047, 1.09810209274292)
(5048, 1.0951679944992065)
(5049, 1.104119896888733)
(5050, 1.0964168310165405)
(5051, 1.0983613729476929)
(5052, 1.1010363101959229)
(5053, 1.0995371341705322)
(5054, 1.1001858711242676)
(5055, 1.0999438762664795)
(5056, 1.0967540740966797)
(5057, 1.0995219945907593)
(5058, 1.0991922616958618)
(5059, 1.0987813472747803)
(5060, 1.100804090499878)
(5061, 1.0994757413864136)
(5062, 1.1008892059326172)
(5063, 1.0969202518463135)
(5064, 1.1014328002929688)
(5065, 1.0998053550720215)
(5066, 1.1036006212234497)
(5067, 1.0992454290390015)
(5068, 1.1063308715820312)
(5069, 1.1039643287658691)
(5070, 1.0969315767288208)
(5071, 1.0968445539474487)
(5072, 1.0988222360610962)
(5073, 1.095060110092163)
(5074, 1.0974657535552979)
(5075, 1.0963832139968872)
(5076, 1.1012439727783203)
(5077, 1.1003836393356323)
(5078, 1.0974963903427124)
(5079, 1.09922456741333)
(5080, 1.0987508296966553)
(5081, 1.1001763343811035)
(5082, 1.101449966430664)
(5083, 1.0982552766799927)
(5084, 1.1019004583358765)
(5085, 1.1010785102844238)
(5086, 1.1003435850143433)
(5087, 1.100740671157837)
(5088, 1.0988277196884155)
(5089, 1.109231948852539)
(5090, 1.0990818738937378)
(5091, 1.097747564315796)
(5092, 1.0976111888885498)
(5093, 1.1029075384140015)
(5094, 1.1003714799880981)
(5095, 1.1002718210220337)
(5096, 1.0976117849349976)
(5097, 1.096166729927063)
(5098, 1.101351261138916)
(5099, 1.099976897239685)
(5100, 1.1014912128448486)
Train Epoch: 0 [10200/549367 (59%)]	Loss: 1.101491
(5101, 1.0973628759384155)
(5102, 1.096698522567749)
(5103, 1.1047791242599487)
(5104, 1.0944910049438477)
(5105, 1.1011959314346313)
(5106, 1.0989433526992798)
(5107, 1.0989665985107422)
(5108, 1.0955654382705688)
(5109, 1.0985493659973145)
(5110, 1.0976063013076782)
(5111, 1.1023812294006348)
(5112, 1.1008621454238892)
(5113, 1.1015880107879639)
(5114, 1.1009660959243774)
(5115, 1.0971794128417969)
(5116, 1.0955578088760376)
(5117, 1.0970598459243774)
(5118, 1.1001757383346558)
(5119, 1.0999572277069092)
(5120, 1.101243495941162)
(5121, 1.1004860401153564)
(5122, 1.0994129180908203)
(5123, 1.0999784469604492)
(5124, 1.1025300025939941)
(5125, 1.1041488647460938)
(5126, 1.0971812009811401)
(5127, 1.1002939939498901)
(5128, 1.0973176956176758)
(5129, 1.094147801399231)
(5130, 1.104265570640564)
(5131, 1.1046628952026367)
(5132, 1.097035527229309)
(5133, 1.1014405488967896)
(5134, 1.0947085618972778)
(5135, 1.097669005393982)
(5136, 1.0975980758666992)
(5137, 1.0966026782989502)
(5138, 1.0972533226013184)
(5139, 1.0989938974380493)
(5140, 1.1026619672775269)
(5141, 1.0966984033584595)
(5142, 1.0984938144683838)
(5143, 1.0961464643478394)
(5144, 1.1006200313568115)
(5145, 1.0971347093582153)
(5146, 1.101728916168213)
(5147, 1.0987282991409302)
(5148, 1.106006383895874)
(5149, 1.1014095544815063)
(5150, 1.0978991985321045)
(5151, 1.0999492406845093)
(5152, 1.0985286235809326)
(5153, 1.0942902565002441)
(5154, 1.0941160917282104)
(5155, 1.1004451513290405)
(5156, 1.096585988998413)
(5157, 1.1041063070297241)
(5158, 1.0982834100723267)
(5159, 1.1003133058547974)
(5160, 1.1016433238983154)
(5161, 1.0995635986328125)
(5162, 1.098911166191101)
(5163, 1.1003416776657104)
(5164, 1.0929286479949951)
(5165, 1.091849684715271)
(5166, 1.1047033071517944)
(5167, 1.096874475479126)
(5168, 1.0989760160446167)
(5169, 1.0976351499557495)
(5170, 1.09996497631073)
(5171, 1.0985287427902222)
(5172, 1.1039927005767822)
(5173, 1.0993107557296753)
(5174, 1.1024651527404785)
(5175, 1.1016275882720947)
(5176, 1.1008141040802002)
(5177, 1.0991793870925903)
(5178, 1.0997376441955566)
(5179, 1.10228431224823)
(5180, 1.0929231643676758)
(5181, 1.0969569683074951)
(5182, 1.1001074314117432)
(5183, 1.0972498655319214)
(5184, 1.100459098815918)
(5185, 1.0968058109283447)
(5186, 1.1021963357925415)
(5187, 1.099377989768982)
(5188, 1.0968736410140991)
(5189, 1.1033042669296265)
(5190, 1.0967745780944824)
(5191, 1.0960623025894165)
(5192, 1.102277159690857)
(5193, 1.0978691577911377)
(5194, 1.1028673648834229)
(5195, 1.0967333316802979)
(5196, 1.0991369485855103)
(5197, 1.101479172706604)
(5198, 1.0983210802078247)
(5199, 1.0937625169754028)
(5200, 1.0964665412902832)
Train Epoch: 0 [10400/549367 (61%)]	Loss: 1.096467
(5201, 1.098565697669983)
(5202, 1.0999503135681152)
(5203, 1.1008942127227783)
(5204, 1.0944510698318481)
(5205, 1.0966445207595825)
(5206, 1.0993643999099731)
(5207, 1.1012098789215088)
(5208, 1.0948004722595215)
(5209, 1.0969197750091553)
(5210, 1.0963621139526367)
(5211, 1.1004571914672852)
(5212, 1.0993750095367432)
(5213, 1.0975241661071777)
(5214, 1.0970220565795898)
(5215, 1.0971959829330444)
(5216, 1.100387692451477)
(5217, 1.0990486145019531)
(5218, 1.0974736213684082)
(5219, 1.0976067781448364)
(5220, 1.1002103090286255)
(5221, 1.0984625816345215)
(5222, 1.102582573890686)
(5223, 1.0966293811798096)
(5224, 1.0964609384536743)
(5225, 1.0993472337722778)
(5226, 1.0955103635787964)
(5227, 1.1003942489624023)
(5228, 1.0969810485839844)
(5229, 1.0987883806228638)
(5230, 1.097751259803772)
(5231, 1.09834623336792)
(5232, 1.095422387123108)
(5233, 1.1002334356307983)
(5234, 1.10451078414917)
(5235, 1.0967803001403809)
(5236, 1.0987962484359741)
(5237, 1.1006712913513184)
(5238, 1.0992172956466675)
(5239, 1.0983161926269531)
(5240, 1.0988221168518066)
(5241, 1.0992487668991089)
(5242, 1.102779507637024)
(5243, 1.0898268222808838)
(5244, 1.0963943004608154)
(5245, 1.1067242622375488)
(5246, 1.0954021215438843)
(5247, 1.099485993385315)
(5248, 1.0996061563491821)
(5249, 1.0999709367752075)
(5250, 1.0998421907424927)
(5251, 1.1016297340393066)
(5252, 1.0945448875427246)
(5253, 1.0994696617126465)
(5254, 1.094541072845459)
(5255, 1.0977352857589722)
(5256, 1.1001518964767456)
(5257, 1.0987600088119507)
(5258, 1.0960395336151123)
(5259, 1.0965279340744019)
(5260, 1.0990498065948486)
(5261, 1.0989512205123901)
(5262, 1.099843978881836)
(5263, 1.095934510231018)
(5264, 1.1015135049819946)
(5265, 1.1038768291473389)
(5266, 1.0973098278045654)
(5267, 1.0993385314941406)
(5268, 1.1031882762908936)
(5269, 1.0981428623199463)
(5270, 1.095646619796753)
(5271, 1.1002081632614136)
(5272, 1.1017639636993408)
(5273, 1.0984413623809814)
(5274, 1.0939089059829712)
(5275, 1.0992871522903442)
(5276, 1.1014442443847656)
(5277, 1.0991040468215942)
(5278, 1.095603346824646)
(5279, 1.0993022918701172)
(5280, 1.0969362258911133)
(5281, 1.0989185571670532)
(5282, 1.095890760421753)
(5283, 1.100307583808899)
(5284, 1.0975241661071777)
(5285, 1.1024425029754639)
(5286, 1.0989371538162231)
(5287, 1.103359341621399)
(5288, 1.0943191051483154)
(5289, 1.097299337387085)
(5290, 1.0985485315322876)
(5291, 1.1040072441101074)
(5292, 1.098305344581604)
(5293, 1.1043386459350586)
(5294, 1.1029421091079712)
(5295, 1.0951265096664429)
(5296, 1.1016151905059814)
(5297, 1.1030203104019165)
(5298, 1.0997341871261597)
(5299, 1.09201979637146)
(5300, 1.1030404567718506)
Train Epoch: 0 [10600/549367 (62%)]	Loss: 1.103040
(5301, 1.0974444150924683)
(5302, 1.0968536138534546)
(5303, 1.095695972442627)
(5304, 1.0939409732818604)
(5305, 1.0975964069366455)
(5306, 1.1018359661102295)
(5307, 1.0986396074295044)
(5308, 1.0982978343963623)
(5309, 1.1090139150619507)
(5310, 1.0963120460510254)
(5311, 1.103218913078308)
(5312, 1.103265643119812)
(5313, 1.0933653116226196)
(5314, 1.094448208808899)
(5315, 1.098181128501892)
(5316, 1.0968449115753174)
(5317, 1.0959200859069824)
(5318, 1.0985172986984253)
(5319, 1.0922635793685913)
(5320, 1.097626805305481)
(5321, 1.0953903198242188)
(5322, 1.1026369333267212)
(5323, 1.0946937799453735)
(5324, 1.1042429208755493)
(5325, 1.09970223903656)
(5326, 1.100000262260437)
(5327, 1.101393699645996)
(5328, 1.0943435430526733)
(5329, 1.096983551979065)
(5330, 1.096488356590271)
(5331, 1.0982186794281006)
(5332, 1.0983175039291382)
(5333, 1.1036109924316406)
(5334, 1.0966930389404297)
(5335, 1.0990104675292969)
(5336, 1.1018438339233398)
(5337, 1.0984489917755127)
(5338, 1.0994999408721924)
(5339, 1.0954406261444092)
(5340, 1.097743034362793)
(5341, 1.1006395816802979)
(5342, 1.1007428169250488)
(5343, 1.0983333587646484)
(5344, 1.0964547395706177)
(5345, 1.100420355796814)
(5346, 1.0988507270812988)
(5347, 1.0997531414031982)
(5348, 1.0948954820632935)
(5349, 1.1032323837280273)
(5350, 1.1003040075302124)
(5351, 1.1004226207733154)
(5352, 1.0976645946502686)
(5353, 1.1006773710250854)
(5354, 1.099310040473938)
(5355, 1.0907039642333984)
(5356, 1.0994585752487183)
(5357, 1.098388910293579)
(5358, 1.0989683866500854)
(5359, 1.0990612506866455)
(5360, 1.1003869771957397)
(5361, 1.0972234010696411)
(5362, 1.1027647256851196)
(5363, 1.102553367614746)
(5364, 1.091631293296814)
(5365, 1.0962086915969849)
(5366, 1.0926079750061035)
(5367, 1.094604253768921)
(5368, 1.0963375568389893)
(5369, 1.0954641103744507)
(5370, 1.1051380634307861)
(5371, 1.097265362739563)
(5372, 1.0999091863632202)
(5373, 1.0971235036849976)
(5374, 1.0975197553634644)
(5375, 1.0941542387008667)
(5376, 1.1009633541107178)
(5377, 1.1010938882827759)
(5378, 1.0996589660644531)
(5379, 1.1055481433868408)
(5380, 1.0957928895950317)
(5381, 1.1065374612808228)
(5382, 1.095495343208313)
(5383, 1.0951865911483765)
(5384, 1.0995550155639648)
(5385, 1.094671368598938)
(5386, 1.1031544208526611)
(5387, 1.1022388935089111)
(5388, 1.0965665578842163)
(5389, 1.1017612218856812)
(5390, 1.0971375703811646)
(5391, 1.0999289751052856)
(5392, 1.0998579263687134)
(5393, 1.104341983795166)
(5394, 1.0924415588378906)
(5395, 1.099177360534668)
(5396, 1.1012152433395386)
(5397, 1.0999202728271484)
(5398, 1.097017765045166)
(5399, 1.097833275794983)
(5400, 1.0974737405776978)
Train Epoch: 0 [10800/549367 (63%)]	Loss: 1.097474
(5401, 1.0951058864593506)
(5402, 1.0921485424041748)
(5403, 1.1056392192840576)
(5404, 1.0999122858047485)
(5405, 1.0930564403533936)
(5406, 1.1003979444503784)
(5407, 1.1010239124298096)
(5408, 1.09320068359375)
(5409, 1.1055827140808105)
(5410, 1.0995558500289917)
(5411, 1.1006197929382324)
(5412, 1.091443419456482)
(5413, 1.0969964265823364)
(5414, 1.10370671749115)
(5415, 1.10403311252594)
(5416, 1.098931908607483)
(5417, 1.1001760959625244)
(5418, 1.0989445447921753)
(5419, 1.1006897687911987)
(5420, 1.098159670829773)
(5421, 1.097033977508545)
(5422, 1.097610592842102)
(5423, 1.1096476316452026)
(5424, 1.1024399995803833)
(5425, 1.1049011945724487)
(5426, 1.1027112007141113)
(5427, 1.0941036939620972)
(5428, 1.0927799940109253)
(5429, 1.1046258211135864)
(5430, 1.1036165952682495)
(5431, 1.101649522781372)
(5432, 1.0956928730010986)
(5433, 1.0968866348266602)
(5434, 1.0924828052520752)
(5435, 1.1042332649230957)
(5436, 1.0994189977645874)
(5437, 1.1013658046722412)
(5438, 1.0951303243637085)
(5439, 1.1045969724655151)
(5440, 1.0992281436920166)
(5441, 1.0981999635696411)
(5442, 1.1009000539779663)
(5443, 1.093613862991333)
(5444, 1.0976061820983887)
(5445, 1.094051480293274)
(5446, 1.0916922092437744)
(5447, 1.0960584878921509)
(5448, 1.0968936681747437)
(5449, 1.1032825708389282)
(5450, 1.1020541191101074)
(5451, 1.0926355123519897)
(5452, 1.1001546382904053)
(5453, 1.1023286581039429)
(5454, 1.0977998971939087)
(5455, 1.1011463403701782)
(5456, 1.0997397899627686)
(5457, 1.099879264831543)
(5458, 1.1086688041687012)
(5459, 1.0911442041397095)
(5460, 1.1029525995254517)
(5461, 1.0939762592315674)
(5462, 1.0932199954986572)
(5463, 1.088113784790039)
(5464, 1.1053684949874878)
(5465, 1.1008179187774658)
(5466, 1.1047228574752808)
(5467, 1.1021937131881714)
(5468, 1.0997090339660645)
(5469, 1.0976405143737793)
(5470, 1.0974631309509277)
(5471, 1.1050928831100464)
(5472, 1.104532241821289)
(5473, 1.106020450592041)
(5474, 1.0969725847244263)
(5475, 1.0925511121749878)
(5476, 1.0998334884643555)
(5477, 1.0928877592086792)
(5478, 1.1056277751922607)
(5479, 1.098186731338501)
(5480, 1.0930424928665161)
(5481, 1.100403904914856)
(5482, 1.1069008111953735)
(5483, 1.0996017456054688)
(5484, 1.0996912717819214)
(5485, 1.0970802307128906)
(5486, 1.1033879518508911)
(5487, 1.0959620475769043)
(5488, 1.100890874862671)
(5489, 1.0974396467208862)
(5490, 1.092329740524292)
(5491, 1.0970786809921265)
(5492, 1.0972143411636353)
(5493, 1.102475643157959)
(5494, 1.0994871854782104)
(5495, 1.1024348735809326)
(5496, 1.107879400253296)
(5497, 1.094343662261963)
(5498, 1.09348464012146)
(5499, 1.1047050952911377)
(5500, 1.0965417623519897)
Train Epoch: 0 [11000/549367 (64%)]	Loss: 1.096542
(5501, 1.1069939136505127)
(5502, 1.0947600603103638)
(5503, 1.103981375694275)
(5504, 1.10077702999115)
(5505, 1.0975373983383179)
(5506, 1.1082180738449097)
(5507, 1.0954229831695557)
(5508, 1.1051437854766846)
(5509, 1.0980340242385864)
(5510, 1.0979022979736328)
(5511, 1.1035054922103882)
(5512, 1.0973018407821655)
(5513, 1.0950305461883545)
(5514, 1.1028681993484497)
(5515, 1.103050708770752)
(5516, 1.0938142538070679)
(5517, 1.0968315601348877)
(5518, 1.0974739789962769)
(5519, 1.1053744554519653)
(5520, 1.099317193031311)
(5521, 1.0975303649902344)
(5522, 1.100117564201355)
(5523, 1.1020859479904175)
(5524, 1.0961499214172363)
(5525, 1.105025053024292)
(5526, 1.1012941598892212)
(5527, 1.0974189043045044)
(5528, 1.1067471504211426)
(5529, 1.1031807661056519)
(5530, 1.0945501327514648)
(5531, 1.1029506921768188)
(5532, 1.1030923128128052)
(5533, 1.097701072692871)
(5534, 1.1080914735794067)
(5535, 1.0969916582107544)
(5536, 1.0987025499343872)
(5537, 1.0965235233306885)
(5538, 1.094039797782898)
(5539, 1.1002728939056396)
(5540, 1.0993115901947021)
(5541, 1.0978798866271973)
(5542, 1.0981022119522095)
(5543, 1.0970996618270874)
(5544, 1.1004701852798462)
(5545, 1.096593976020813)
(5546, 1.0958489179611206)
(5547, 1.10079824924469)
(5548, 1.0987826585769653)
(5549, 1.0999621152877808)
(5550, 1.0941581726074219)
(5551, 1.1020570993423462)
(5552, 1.0987317562103271)
(5553, 1.0970385074615479)
(5554, 1.096883773803711)
(5555, 1.0982844829559326)
(5556, 1.098168134689331)
(5557, 1.1043050289154053)
(5558, 1.098111629486084)
(5559, 1.099265694618225)
(5560, 1.100886344909668)
(5561, 1.0950435400009155)
(5562, 1.0985071659088135)
(5563, 1.0962523221969604)
(5564, 1.0981992483139038)
(5565, 1.0982969999313354)
(5566, 1.0964668989181519)
(5567, 1.0988128185272217)
(5568, 1.0982983112335205)
(5569, 1.0993051528930664)
(5570, 1.0949538946151733)
(5571, 1.105385422706604)
(5572, 1.099222183227539)
(5573, 1.1021206378936768)
(5574, 1.1003187894821167)
(5575, 1.0995028018951416)
(5576, 1.0935250520706177)
(5577, 1.1024729013442993)
(5578, 1.0987035036087036)
(5579, 1.1025737524032593)
(5580, 1.0964735746383667)
(5581, 1.0977839231491089)
(5582, 1.0996555089950562)
(5583, 1.1036585569381714)
(5584, 1.0965001583099365)
(5585, 1.098982572555542)
(5586, 1.1007001399993896)
(5587, 1.1008259057998657)
(5588, 1.105805516242981)
(5589, 1.0960769653320312)
(5590, 1.0968382358551025)
(5591, 1.1012067794799805)
(5592, 1.0925267934799194)
(5593, 1.102900505065918)
(5594, 1.0994707345962524)
(5595, 1.0994160175323486)
(5596, 1.1008952856063843)
(5597, 1.1016215085983276)
(5598, 1.0948678255081177)
(5599, 1.0948309898376465)
(5600, 1.0962846279144287)
Train Epoch: 0 [11200/549367 (65%)]	Loss: 1.096285
(5601, 1.1017400026321411)
(5602, 1.1001956462860107)
(5603, 1.0983712673187256)
(5604, 1.1019985675811768)
(5605, 1.0978517532348633)
(5606, 1.0996055603027344)
(5607, 1.0965014696121216)
(5608, 1.099523901939392)
(5609, 1.0962698459625244)
(5610, 1.0988988876342773)
(5611, 1.096911907196045)
(5612, 1.0980976819992065)
(5613, 1.1021555662155151)
(5614, 1.1048482656478882)
(5615, 1.1004513502120972)
(5616, 1.0972111225128174)
(5617, 1.101705551147461)
(5618, 1.097863793373108)
(5619, 1.104404330253601)
(5620, 1.1029062271118164)
(5621, 1.105006217956543)
(5622, 1.1046473979949951)
(5623, 1.0985839366912842)
(5624, 1.0941753387451172)
(5625, 1.0962803363800049)
(5626, 1.0966745615005493)
(5627, 1.094484567642212)
(5628, 1.0995923280715942)
(5629, 1.1030510663986206)
(5630, 1.1004390716552734)
(5631, 1.099914789199829)
(5632, 1.1039061546325684)
(5633, 1.099218726158142)
(5634, 1.1012548208236694)
(5635, 1.0988167524337769)
(5636, 1.1022984981536865)
(5637, 1.1035597324371338)
(5638, 1.0993276834487915)
(5639, 1.0955419540405273)
(5640, 1.0994386672973633)
(5641, 1.0946378707885742)
(5642, 1.0949558019638062)
(5643, 1.1001529693603516)
(5644, 1.1034578084945679)
(5645, 1.0981254577636719)
(5646, 1.0971287488937378)
(5647, 1.0955321788787842)
(5648, 1.1002607345581055)
(5649, 1.101338505744934)
(5650, 1.096414566040039)
(5651, 1.1017158031463623)
(5652, 1.094901442527771)
(5653, 1.1014660596847534)
(5654, 1.1012272834777832)
(5655, 1.0976186990737915)
(5656, 1.0966784954071045)
(5657, 1.0993595123291016)
(5658, 1.0952786207199097)
(5659, 1.095943570137024)
(5660, 1.095346450805664)
(5661, 1.0995121002197266)
(5662, 1.098940372467041)
(5663, 1.0937999486923218)
(5664, 1.0980430841445923)
(5665, 1.0989290475845337)
(5666, 1.0970885753631592)
(5667, 1.0995979309082031)
(5668, 1.0959786176681519)
(5669, 1.0982680320739746)
(5670, 1.0991780757904053)
(5671, 1.0976572036743164)
(5672, 1.1004236936569214)
(5673, 1.0936553478240967)
(5674, 1.0985357761383057)
(5675, 1.0991828441619873)
(5676, 1.0981974601745605)
(5677, 1.1046086549758911)
(5678, 1.0987565517425537)
(5679, 1.1004449129104614)
(5680, 1.099579930305481)
(5681, 1.0998778343200684)
(5682, 1.0976157188415527)
(5683, 1.101373553276062)
(5684, 1.100329041481018)
(5685, 1.0931453704833984)
(5686, 1.0992510318756104)
(5687, 1.099915862083435)
(5688, 1.1007189750671387)
(5689, 1.1027005910873413)
(5690, 1.0988872051239014)
(5691, 1.0991098880767822)
(5692, 1.0981740951538086)
(5693, 1.098915457725525)
(5694, 1.0969263315200806)
(5695, 1.105141043663025)
(5696, 1.100995659828186)
(5697, 1.1008775234222412)
(5698, 1.1017029285430908)
(5699, 1.1087939739227295)
(5700, 1.095197081565857)
Train Epoch: 0 [11400/549367 (66%)]	Loss: 1.095197
(5701, 1.099064826965332)
(5702, 1.097671389579773)
(5703, 1.098022222518921)
(5704, 1.107645034790039)
(5705, 1.0915977954864502)
(5706, 1.0984095335006714)
(5707, 1.0954127311706543)
(5708, 1.103760004043579)
(5709, 1.1005699634552002)
(5710, 1.0992138385772705)
(5711, 1.100005865097046)
(5712, 1.1112205982208252)
(5713, 1.1008236408233643)
(5714, 1.0981512069702148)
(5715, 1.0981507301330566)
(5716, 1.0996861457824707)
(5717, 1.101133942604065)
(5718, 1.0999833345413208)
(5719, 1.1018006801605225)
(5720, 1.095340371131897)
(5721, 1.0999205112457275)
(5722, 1.0972741842269897)
(5723, 1.0947492122650146)
(5724, 1.0972574949264526)
(5725, 1.093225359916687)
(5726, 1.1014595031738281)
(5727, 1.0994930267333984)
(5728, 1.1090973615646362)
(5729, 1.102552890777588)
(5730, 1.1009517908096313)
(5731, 1.0984556674957275)
(5732, 1.1047972440719604)
(5733, 1.0984735488891602)
(5734, 1.0995842218399048)
(5735, 1.0966874361038208)
(5736, 1.0966989994049072)
(5737, 1.098595142364502)
(5738, 1.1050726175308228)
(5739, 1.0985277891159058)
(5740, 1.0995932817459106)
(5741, 1.0992387533187866)
(5742, 1.1012314558029175)
(5743, 1.105995535850525)
(5744, 1.1023221015930176)
(5745, 1.0987091064453125)
(5746, 1.1030946969985962)
(5747, 1.1035382747650146)
(5748, 1.0987229347229004)
(5749, 1.0948354005813599)
(5750, 1.1022417545318604)
(5751, 1.0960814952850342)
(5752, 1.099214792251587)
(5753, 1.0983842611312866)
(5754, 1.0967140197753906)
(5755, 1.0934034585952759)
(5756, 1.1008915901184082)
(5757, 1.0944461822509766)
(5758, 1.1017394065856934)
(5759, 1.1072204113006592)
(5760, 1.0937390327453613)
(5761, 1.1011953353881836)
(5762, 1.0983856916427612)
(5763, 1.0987902879714966)
(5764, 1.0954163074493408)
(5765, 1.0983816385269165)
(5766, 1.0940206050872803)
(5767, 1.0991392135620117)
(5768, 1.1020416021347046)
(5769, 1.0957835912704468)
(5770, 1.0966373682022095)
(5771, 1.1007062196731567)
(5772, 1.1030141115188599)
(5773, 1.1034772396087646)
(5774, 1.0910696983337402)
(5775, 1.0957720279693604)
(5776, 1.0983377695083618)
(5777, 1.1020663976669312)
(5778, 1.1001193523406982)
(5779, 1.096224308013916)
(5780, 1.0966442823410034)
(5781, 1.0976661443710327)
(5782, 1.0980801582336426)
(5783, 1.0967615842819214)
(5784, 1.096920132637024)
(5785, 1.1033095121383667)
(5786, 1.0968488454818726)
(5787, 1.097219705581665)
(5788, 1.0974043607711792)
(5789, 1.103495478630066)
(5790, 1.0986098051071167)
(5791, 1.0953264236450195)
(5792, 1.1067209243774414)
(5793, 1.0989243984222412)
(5794, 1.0908522605895996)
(5795, 1.1002585887908936)
(5796, 1.090651512145996)
(5797, 1.0997852087020874)
(5798, 1.0934603214263916)
(5799, 1.0965520143508911)
(5800, 1.1020410060882568)
Train Epoch: 0 [11600/549367 (68%)]	Loss: 1.102041
(5801, 1.1005126237869263)
(5802, 1.0998713970184326)
(5803, 1.1050705909729004)
(5804, 1.0900821685791016)
(5805, 1.105085849761963)
(5806, 1.1020631790161133)
(5807, 1.0996873378753662)
(5808, 1.097479224205017)
(5809, 1.1017199754714966)
(5810, 1.1024922132492065)
(5811, 1.0979722738265991)
(5812, 1.0994561910629272)
(5813, 1.098168969154358)
(5814, 1.0984137058258057)
(5815, 1.0954053401947021)
(5816, 1.0966792106628418)
(5817, 1.0980854034423828)
(5818, 1.0974111557006836)
(5819, 1.0970205068588257)
(5820, 1.0954813957214355)
(5821, 1.099766492843628)
(5822, 1.0880868434906006)
(5823, 1.092100739479065)
(5824, 1.0971300601959229)
(5825, 1.1041648387908936)
(5826, 1.0958360433578491)
(5827, 1.102279782295227)
(5828, 1.1041964292526245)
(5829, 1.1044844388961792)
(5830, 1.0963314771652222)
(5831, 1.1011873483657837)
(5832, 1.098961591720581)
(5833, 1.0965495109558105)
(5834, 1.1024084091186523)
(5835, 1.098272442817688)
(5836, 1.0961426496505737)
(5837, 1.1020406484603882)
(5838, 1.1012893915176392)
(5839, 1.0992680788040161)
(5840, 1.0948446989059448)
(5841, 1.1027534008026123)
(5842, 1.1071641445159912)
(5843, 1.0981789827346802)
(5844, 1.1017968654632568)
(5845, 1.09663724899292)
(5846, 1.095314621925354)
(5847, 1.0979740619659424)
(5848, 1.1008789539337158)
(5849, 1.1058419942855835)
(5850, 1.1020243167877197)
(5851, 1.0988625288009644)
(5852, 1.096094012260437)
(5853, 1.0951263904571533)
(5854, 1.0992883443832397)
(5855, 1.0958136320114136)
(5856, 1.1029847860336304)
(5857, 1.0996994972229004)
(5858, 1.0956214666366577)
(5859, 1.0998250246047974)
(5860, 1.0964266061782837)
(5861, 1.1045565605163574)
(5862, 1.0972334146499634)
(5863, 1.095033049583435)
(5864, 1.0988414287567139)
(5865, 1.1004252433776855)
(5866, 1.1012245416641235)
(5867, 1.0971617698669434)
(5868, 1.0944269895553589)
(5869, 1.099244236946106)
(5870, 1.1002084016799927)
(5871, 1.1080188751220703)
(5872, 1.0955772399902344)
(5873, 1.0965105295181274)
(5874, 1.0925896167755127)
(5875, 1.1001667976379395)
(5876, 1.097402572631836)
(5877, 1.0987764596939087)
(5878, 1.1016050577163696)
(5879, 1.1024640798568726)
(5880, 1.0986757278442383)
(5881, 1.1047067642211914)
(5882, 1.0973557233810425)
(5883, 1.0994162559509277)
(5884, 1.1019606590270996)
(5885, 1.0947203636169434)
(5886, 1.0992295742034912)
(5887, 1.0973327159881592)
(5888, 1.1041408777236938)
(5889, 1.0997226238250732)
(5890, 1.1042860746383667)
(5891, 1.0992060899734497)
(5892, 1.100743293762207)
(5893, 1.1000657081604004)
(5894, 1.0990111827850342)
(5895, 1.0947139263153076)
(5896, 1.1103723049163818)
(5897, 1.0955764055252075)
(5898, 1.0975496768951416)
(5899, 1.099638819694519)
(5900, 1.094194769859314)
Train Epoch: 0 [11800/549367 (69%)]	Loss: 1.094195
(5901, 1.0992039442062378)
(5902, 1.0963634252548218)
(5903, 1.1001343727111816)
(5904, 1.0975521802902222)
(5905, 1.0980381965637207)
(5906, 1.0934169292449951)
(5907, 1.0954376459121704)
(5908, 1.0970849990844727)
(5909, 1.0985980033874512)
(5910, 1.0986305475234985)
(5911, 1.0962402820587158)
(5912, 1.0983386039733887)
(5913, 1.100043773651123)
(5914, 1.0991220474243164)
(5915, 1.101768970489502)
(5916, 1.09376859664917)
(5917, 1.098594069480896)
(5918, 1.0942083597183228)
(5919, 1.0943725109100342)
(5920, 1.0979164838790894)
(5921, 1.0998220443725586)
(5922, 1.0962893962860107)
(5923, 1.1018821001052856)
(5924, 1.100830078125)
(5925, 1.0939271450042725)
(5926, 1.1020100116729736)
(5927, 1.096864938735962)
(5928, 1.096590518951416)
(5929, 1.0921149253845215)
(5930, 1.097456455230713)
(5931, 1.0957937240600586)
(5932, 1.103785514831543)
(5933, 1.1070431470870972)
(5934, 1.1006982326507568)
(5935, 1.1074531078338623)
(5936, 1.0999882221221924)
(5937, 1.1000053882598877)
(5938, 1.0981576442718506)
(5939, 1.0951783657073975)
(5940, 1.0959217548370361)
(5941, 1.0932363271713257)
(5942, 1.0993309020996094)
(5943, 1.1016665697097778)
(5944, 1.0967274904251099)
(5945, 1.107096552848816)
(5946, 1.10355544090271)
(5947, 1.1042876243591309)
(5948, 1.1038055419921875)
(5949, 1.0975112915039062)
(5950, 1.1055302619934082)
(5951, 1.103882074356079)
(5952, 1.0983366966247559)
(5953, 1.0950801372528076)
(5954, 1.1030421257019043)
(5955, 1.0956312417984009)
(5956, 1.094762921333313)
(5957, 1.0946567058563232)
(5958, 1.104628562927246)
(5959, 1.09978187084198)
(5960, 1.1052643060684204)
(5961, 1.1015411615371704)
(5962, 1.1013023853302002)
(5963, 1.0991475582122803)
(5964, 1.1001633405685425)
(5965, 1.096631407737732)
(5966, 1.1040492057800293)
(5967, 1.1002910137176514)
(5968, 1.0961734056472778)
(5969, 1.1007682085037231)
(5970, 1.0965142250061035)
(5971, 1.0949318408966064)
(5972, 1.1023280620574951)
(5973, 1.0996220111846924)
(5974, 1.102813720703125)
(5975, 1.0994383096694946)
(5976, 1.1013680696487427)
(5977, 1.0978071689605713)
(5978, 1.1012767553329468)
(5979, 1.0985125303268433)
(5980, 1.1013753414154053)
(5981, 1.0986621379852295)
(5982, 1.1019028425216675)
(5983, 1.094347596168518)
(5984, 1.0987279415130615)
(5985, 1.0974187850952148)
(5986, 1.09921395778656)
(5987, 1.097659945487976)
(5988, 1.1004210710525513)
(5989, 1.0989166498184204)
(5990, 1.100600004196167)
(5991, 1.096988320350647)
(5992, 1.1026936769485474)
(5993, 1.1020640134811401)
(5994, 1.0966546535491943)
(5995, 1.101051688194275)
(5996, 1.1004877090454102)
(5997, 1.1022902727127075)
(5998, 1.0975286960601807)
(5999, 1.099480152130127)
(6000, 1.0959513187408447)
Train Epoch: 0 [12000/549367 (70%)]	Loss: 1.095951
(6001, 1.0991322994232178)
(6002, 1.0959033966064453)
(6003, 1.102460503578186)
(6004, 1.102823257446289)
(6005, 1.0988093614578247)
(6006, 1.1025131940841675)
(6007, 1.0969483852386475)
(6008, 1.097649335861206)
(6009, 1.1058677434921265)
(6010, 1.0993331670761108)
(6011, 1.1025310754776)
(6012, 1.0980125665664673)
(6013, 1.1020255088806152)
(6014, 1.0996325016021729)
(6015, 1.0969938039779663)
(6016, 1.0930840969085693)
(6017, 1.09824800491333)
(6018, 1.1006149053573608)
(6019, 1.0980721712112427)
(6020, 1.0995714664459229)
(6021, 1.10089910030365)
(6022, 1.1035853624343872)
(6023, 1.0986902713775635)
(6024, 1.0993950366973877)
(6025, 1.0988821983337402)
(6026, 1.099695086479187)
(6027, 1.0950180292129517)
(6028, 1.0989744663238525)
(6029, 1.1023038625717163)
(6030, 1.0980585813522339)
(6031, 1.0998799800872803)
(6032, 1.1010380983352661)
(6033, 1.101584553718567)
(6034, 1.1015450954437256)
(6035, 1.0981746912002563)
(6036, 1.096950888633728)
(6037, 1.098623514175415)
(6038, 1.1005669832229614)
(6039, 1.0977104902267456)
(6040, 1.0934919118881226)
(6041, 1.0996490716934204)
(6042, 1.099328637123108)
(6043, 1.1047508716583252)
(6044, 1.1002246141433716)
(6045, 1.098357081413269)
(6046, 1.0963698625564575)
(6047, 1.0975050926208496)
(6048, 1.0974366664886475)
(6049, 1.1004600524902344)
(6050, 1.1011420488357544)
(6051, 1.1013212203979492)
(6052, 1.0965877771377563)
(6053, 1.0990928411483765)
(6054, 1.0996285676956177)
(6055, 1.0950902700424194)
(6056, 1.0995938777923584)
(6057, 1.0972965955734253)
(6058, 1.1027436256408691)
(6059, 1.093211054801941)
(6060, 1.0986642837524414)
(6061, 1.1006746292114258)
(6062, 1.097888708114624)
(6063, 1.0951861143112183)
(6064, 1.1010771989822388)
(6065, 1.0974470376968384)
(6066, 1.0982574224472046)
(6067, 1.101128101348877)
(6068, 1.1025218963623047)
(6069, 1.0970114469528198)
(6070, 1.0977004766464233)
(6071, 1.0989874601364136)
(6072, 1.1023075580596924)
(6073, 1.0974732637405396)
(6074, 1.0949643850326538)
(6075, 1.0983271598815918)
(6076, 1.0954972505569458)
(6077, 1.0987067222595215)
(6078, 1.101578950881958)
(6079, 1.0939292907714844)
(6080, 1.1049121618270874)
(6081, 1.096860647201538)
(6082, 1.0966066122055054)
(6083, 1.0982661247253418)
(6084, 1.1020798683166504)
(6085, 1.1013786792755127)
(6086, 1.0997394323349)
(6087, 1.100569486618042)
(6088, 1.0990009307861328)
(6089, 1.1020677089691162)
(6090, 1.1040406227111816)
(6091, 1.0983176231384277)
(6092, 1.1031622886657715)
(6093, 1.102159023284912)
(6094, 1.0982016324996948)
(6095, 1.1008124351501465)
(6096, 1.1002590656280518)
(6097, 1.100502848625183)
(6098, 1.0982860326766968)
(6099, 1.1013826131820679)
(6100, 1.096238136291504)
Train Epoch: 0 [12200/549367 (71%)]	Loss: 1.096238
(6101, 1.0985777378082275)
(6102, 1.1008775234222412)
(6103, 1.0968934297561646)
(6104, 1.0990972518920898)
(6105, 1.0981152057647705)
(6106, 1.1038649082183838)
(6107, 1.0962098836898804)
(6108, 1.1015883684158325)
(6109, 1.0988119840621948)
(6110, 1.1022075414657593)
(6111, 1.0992164611816406)
(6112, 1.0980982780456543)
(6113, 1.0994629859924316)
(6114, 1.0994261503219604)
(6115, 1.0993629693984985)
(6116, 1.0981345176696777)
(6117, 1.1013126373291016)
(6118, 1.1015034914016724)
(6119, 1.0992413759231567)
(6120, 1.1003514528274536)
(6121, 1.0949844121932983)
(6122, 1.1016184091567993)
(6123, 1.0970027446746826)
(6124, 1.0941165685653687)
(6125, 1.100644826889038)
(6126, 1.0946247577667236)
(6127, 1.1008353233337402)
(6128, 1.0972298383712769)
(6129, 1.0995292663574219)
(6130, 1.1045128107070923)
(6131, 1.0970779657363892)
(6132, 1.0958282947540283)
(6133, 1.0949736833572388)
(6134, 1.1007155179977417)
(6135, 1.096323013305664)
(6136, 1.1013400554656982)
(6137, 1.0981788635253906)
(6138, 1.1059880256652832)
(6139, 1.1025950908660889)
(6140, 1.0971928834915161)
(6141, 1.0940266847610474)
(6142, 1.098044514656067)
(6143, 1.09632408618927)
(6144, 1.0922240018844604)
(6145, 1.0981236696243286)
(6146, 1.0956494808197021)
(6147, 1.093930721282959)
(6148, 1.1025792360305786)
(6149, 1.1003036499023438)
(6150, 1.0971866846084595)
(6151, 1.0980112552642822)
(6152, 1.107033371925354)
(6153, 1.0993611812591553)
(6154, 1.1018742322921753)
(6155, 1.0980191230773926)
(6156, 1.1011488437652588)
(6157, 1.092288851737976)
(6158, 1.094538688659668)
(6159, 1.0949500799179077)
(6160, 1.0989608764648438)
(6161, 1.089640498161316)
(6162, 1.0924513339996338)
(6163, 1.1022984981536865)
(6164, 1.1001530885696411)
(6165, 1.0958939790725708)
(6166, 1.091909408569336)
(6167, 1.0962642431259155)
(6168, 1.0933332443237305)
(6169, 1.1006604433059692)
(6170, 1.0998014211654663)
(6171, 1.0953727960586548)
(6172, 1.1016926765441895)
(6173, 1.0999715328216553)
(6174, 1.1036503314971924)
(6175, 1.1050922870635986)
(6176, 1.1004903316497803)
(6177, 1.1010202169418335)
(6178, 1.099466323852539)
(6179, 1.097787857055664)
(6180, 1.1008405685424805)
(6181, 1.0992614030838013)
(6182, 1.0949487686157227)
(6183, 1.1001113653182983)
(6184, 1.1013168096542358)
(6185, 1.1035279035568237)
(6186, 1.0994157791137695)
(6187, 1.1027979850769043)
(6188, 1.1006449460983276)
(6189, 1.0979852676391602)
(6190, 1.0917437076568604)
(6191, 1.106858730316162)
(6192, 1.0980100631713867)
(6193, 1.0969643592834473)
(6194, 1.1025912761688232)
(6195, 1.0991636514663696)
(6196, 1.1017299890518188)
(6197, 1.0996479988098145)
(6198, 1.097116470336914)
(6199, 1.0969921350479126)
(6200, 1.1012822389602661)
Train Epoch: 0 [12400/549367 (72%)]	Loss: 1.101282
(6201, 1.0966484546661377)
(6202, 1.1019901037216187)
(6203, 1.1015781164169312)
(6204, 1.098595142364502)
(6205, 1.1001771688461304)
(6206, 1.1023911237716675)
(6207, 1.0945913791656494)
(6208, 1.0994930267333984)
(6209, 1.099971055984497)
(6210, 1.0996423959732056)
(6211, 1.0978221893310547)
(6212, 1.0987647771835327)
(6213, 1.096395492553711)
(6214, 1.0963730812072754)
(6215, 1.0874106884002686)
(6216, 1.1037631034851074)
(6217, 1.0961697101593018)
(6218, 1.096495509147644)
(6219, 1.0964933633804321)
(6220, 1.1021162271499634)
(6221, 1.0987943410873413)
(6222, 1.0986006259918213)
(6223, 1.0986710786819458)
(6224, 1.1017844676971436)
(6225, 1.1006437540054321)
(6226, 1.100066065788269)
(6227, 1.0958832502365112)
(6228, 1.0987844467163086)
(6229, 1.0979061126708984)
(6230, 1.0996872186660767)
(6231, 1.0959200859069824)
(6232, 1.10413658618927)
(6233, 1.0982376337051392)
(6234, 1.0980336666107178)
(6235, 1.1034700870513916)
(6236, 1.1010428667068481)
(6237, 1.095041036605835)
(6238, 1.0981849431991577)
(6239, 1.0981333255767822)
(6240, 1.1043243408203125)
(6241, 1.1046122312545776)
(6242, 1.102558970451355)
(6243, 1.100024700164795)
(6244, 1.1027650833129883)
(6245, 1.099992275238037)
(6246, 1.0990045070648193)
(6247, 1.1007405519485474)
(6248, 1.0995471477508545)
(6249, 1.0987374782562256)
(6250, 1.094912052154541)
(6251, 1.0987110137939453)
(6252, 1.1021746397018433)
(6253, 1.0986205339431763)
(6254, 1.0953905582427979)
(6255, 1.0984864234924316)
(6256, 1.0980902910232544)
(6257, 1.096590280532837)
(6258, 1.10161292552948)
(6259, 1.1009591817855835)
(6260, 1.094560980796814)
(6261, 1.0963701009750366)
(6262, 1.103168249130249)
(6263, 1.0986984968185425)
(6264, 1.0989623069763184)
(6265, 1.10195791721344)
(6266, 1.099076747894287)
(6267, 1.098710536956787)
(6268, 1.1056787967681885)
(6269, 1.0942243337631226)
(6270, 1.102508544921875)
(6271, 1.0983259677886963)
(6272, 1.0995910167694092)
(6273, 1.0935916900634766)
(6274, 1.099003791809082)
(6275, 1.1002535820007324)
(6276, 1.1011483669281006)
(6277, 1.096638798713684)
(6278, 1.098628282546997)
(6279, 1.1040387153625488)
(6280, 1.0973564386367798)
(6281, 1.0986465215682983)
(6282, 1.1029942035675049)
(6283, 1.0981794595718384)
(6284, 1.092941403388977)
(6285, 1.0979841947555542)
(6286, 1.0999516248703003)
(6287, 1.1022627353668213)
(6288, 1.103588581085205)
(6289, 1.1003695726394653)
(6290, 1.0950086116790771)
(6291, 1.0957093238830566)
(6292, 1.1016682386398315)
(6293, 1.0972565412521362)
(6294, 1.1001853942871094)
(6295, 1.100695013999939)
(6296, 1.0978550910949707)
(6297, 1.0930485725402832)
(6298, 1.1006814241409302)
(6299, 1.106316089630127)
(6300, 1.0998421907424927)
Train Epoch: 0 [12600/549367 (73%)]	Loss: 1.099842
(6301, 1.0942410230636597)
(6302, 1.0994142293930054)
(6303, 1.0965930223464966)
(6304, 1.1010587215423584)
(6305, 1.1007194519042969)
(6306, 1.0992742776870728)
(6307, 1.1004072427749634)
(6308, 1.0941818952560425)
(6309, 1.0974820852279663)
(6310, 1.0924389362335205)
(6311, 1.1014621257781982)
(6312, 1.101660966873169)
(6313, 1.0977697372436523)
(6314, 1.0957030057907104)
(6315, 1.1018455028533936)
(6316, 1.1023081541061401)
(6317, 1.0964269638061523)
(6318, 1.0989598035812378)
(6319, 1.1016513109207153)
(6320, 1.0997480154037476)
(6321, 1.1028156280517578)
(6322, 1.108272910118103)
(6323, 1.1077570915222168)
(6324, 1.0989620685577393)
(6325, 1.095877766609192)
(6326, 1.1009901762008667)
(6327, 1.093340516090393)
(6328, 1.1044738292694092)
(6329, 1.1023857593536377)
(6330, 1.095019817352295)
(6331, 1.0990928411483765)
(6332, 1.0981236696243286)
(6333, 1.0966298580169678)
(6334, 1.1040856838226318)
(6335, 1.0960723161697388)
(6336, 1.1048943996429443)
(6337, 1.0964192152023315)
(6338, 1.1043307781219482)
(6339, 1.1019244194030762)
(6340, 1.093139886856079)
(6341, 1.1030890941619873)
(6342, 1.0948140621185303)
(6343, 1.095697045326233)
(6344, 1.0963636636734009)
(6345, 1.096683144569397)
(6346, 1.0870438814163208)
(6347, 1.099112868309021)
(6348, 1.10776948928833)
(6349, 1.1077486276626587)
(6350, 1.0908104181289673)
(6351, 1.1012519598007202)
(6352, 1.1007676124572754)
(6353, 1.0977404117584229)
(6354, 1.1006587743759155)
(6355, 1.101424217224121)
(6356, 1.0982083082199097)
(6357, 1.0962709188461304)
(6358, 1.1015292406082153)
(6359, 1.0872266292572021)
(6360, 1.1007689237594604)
(6361, 1.0964679718017578)
(6362, 1.0953136682510376)
(6363, 1.094099521636963)
(6364, 1.1000632047653198)
(6365, 1.0966520309448242)
(6366, 1.0974884033203125)
(6367, 1.1037570238113403)
(6368, 1.097329020500183)
(6369, 1.0990936756134033)
(6370, 1.0860071182250977)
(6371, 1.0976160764694214)
(6372, 1.1080858707427979)
(6373, 1.1003385782241821)
(6374, 1.0977050065994263)
(6375, 1.09748113155365)
(6376, 1.1051534414291382)
(6377, 1.1049301624298096)
(6378, 1.1033869981765747)
(6379, 1.1068882942199707)
(6380, 1.1034278869628906)
(6381, 1.0977569818496704)
(6382, 1.0981186628341675)
(6383, 1.110385537147522)
(6384, 1.1043436527252197)
(6385, 1.102508544921875)
(6386, 1.1023699045181274)
(6387, 1.0964568853378296)
(6388, 1.100713849067688)
(6389, 1.094827651977539)
(6390, 1.1021206378936768)
(6391, 1.1055731773376465)
(6392, 1.1014608144760132)
(6393, 1.099231243133545)
(6394, 1.0938252210617065)
(6395, 1.0988346338272095)
(6396, 1.0920307636260986)
(6397, 1.106265902519226)
(6398, 1.0978094339370728)
(6399, 1.1016299724578857)
(6400, 1.0905508995056152)
Train Epoch: 0 [12800/549367 (75%)]	Loss: 1.090551
(6401, 1.1044963598251343)
(6402, 1.0977462530136108)
(6403, 1.0945724248886108)
(6404, 1.0995421409606934)
(6405, 1.0966755151748657)
(6406, 1.0993633270263672)
(6407, 1.0942567586898804)
(6408, 1.1043567657470703)
(6409, 1.101923942565918)
(6410, 1.1070243120193481)
(6411, 1.1011385917663574)
(6412, 1.0979315042495728)
(6413, 1.0992604494094849)
(6414, 1.0984530448913574)
(6415, 1.1023015975952148)
(6416, 1.1005123853683472)
(6417, 1.0990246534347534)
(6418, 1.0936310291290283)
(6419, 1.1017181873321533)
(6420, 1.0939362049102783)
(6421, 1.1008540391921997)
(6422, 1.1024194955825806)
(6423, 1.1010205745697021)
(6424, 1.099182367324829)
(6425, 1.099242925643921)
(6426, 1.0928897857666016)
(6427, 1.0956554412841797)
(6428, 1.100164532661438)
(6429, 1.1022142171859741)
(6430, 1.0997376441955566)
(6431, 1.0956391096115112)
(6432, 1.0990116596221924)
(6433, 1.095484733581543)
(6434, 1.100657343864441)
(6435, 1.1047065258026123)
(6436, 1.09165620803833)
(6437, 1.0940600633621216)
(6438, 1.0951621532440186)
(6439, 1.0930256843566895)
(6440, 1.0999789237976074)
(6441, 1.0959802865982056)
(6442, 1.099570393562317)
(6443, 1.097656011581421)
(6444, 1.1015968322753906)
(6445, 1.0981967449188232)
(6446, 1.0999653339385986)
(6447, 1.0914981365203857)
(6448, 1.1033027172088623)
(6449, 1.1025581359863281)
(6450, 1.1015424728393555)
(6451, 1.101122498512268)
(6452, 1.0972058773040771)
(6453, 1.106449007987976)
(6454, 1.099361777305603)
(6455, 1.1041747331619263)
(6456, 1.0932412147521973)
(6457, 1.095609426498413)
(6458, 1.0989840030670166)
(6459, 1.0888855457305908)
(6460, 1.0987893342971802)
(6461, 1.0990898609161377)
(6462, 1.097771406173706)
(6463, 1.1001830101013184)
(6464, 1.097368597984314)
(6465, 1.0992776155471802)
(6466, 1.0984594821929932)
(6467, 1.092444658279419)
(6468, 1.0987802743911743)
(6469, 1.0984783172607422)
(6470, 1.100386619567871)
(6471, 1.0940662622451782)
(6472, 1.0993402004241943)
(6473, 1.1012810468673706)
(6474, 1.0985897779464722)
(6475, 1.093235731124878)
(6476, 1.0994559526443481)
(6477, 1.108726143836975)
(6478, 1.1015502214431763)
(6479, 1.0943559408187866)
(6480, 1.0988872051239014)
(6481, 1.105096459388733)
(6482, 1.099137544631958)
(6483, 1.1022663116455078)
(6484, 1.0999786853790283)
(6485, 1.10000479221344)
(6486, 1.1042221784591675)
(6487, 1.1015499830245972)
(6488, 1.0945472717285156)
(6489, 1.0922317504882812)
(6490, 1.0968459844589233)
(6491, 1.0981078147888184)
(6492, 1.094417691230774)
(6493, 1.102054476737976)
(6494, 1.0903230905532837)
(6495, 1.0994093418121338)
(6496, 1.1002963781356812)
(6497, 1.0998685359954834)
(6498, 1.0986560583114624)
(6499, 1.1045689582824707)
(6500, 1.0941340923309326)
Train Epoch: 0 [13000/549367 (76%)]	Loss: 1.094134
(6501, 1.102342128753662)
(6502, 1.1006118059158325)
(6503, 1.0947418212890625)
(6504, 1.1031262874603271)
(6505, 1.100785255432129)
(6506, 1.1009498834609985)
(6507, 1.0981240272521973)
(6508, 1.0966784954071045)
(6509, 1.096562385559082)
(6510, 1.0968267917633057)
(6511, 1.094979166984558)
(6512, 1.0965958833694458)
(6513, 1.1073753833770752)
(6514, 1.1004451513290405)
(6515, 1.0968774557113647)
(6516, 1.1040486097335815)
(6517, 1.1008238792419434)
(6518, 1.099026083946228)
(6519, 1.099503517150879)
(6520, 1.098919153213501)
(6521, 1.0995759963989258)
(6522, 1.100940465927124)
(6523, 1.1021735668182373)
(6524, 1.0987422466278076)
(6525, 1.0906178951263428)
(6526, 1.0959559679031372)
(6527, 1.091062068939209)
(6528, 1.0985809564590454)
(6529, 1.0915356874465942)
(6530, 1.1033920049667358)
(6531, 1.0959398746490479)
(6532, 1.092729091644287)
(6533, 1.0984410047531128)
(6534, 1.1040971279144287)
(6535, 1.102465271949768)
(6536, 1.097896933555603)
(6537, 1.0997661352157593)
(6538, 1.0939757823944092)
(6539, 1.0945755243301392)
(6540, 1.0958528518676758)
(6541, 1.0990303754806519)
(6542, 1.0982849597930908)
(6543, 1.102827787399292)
(6544, 1.1018650531768799)
(6545, 1.1016554832458496)
(6546, 1.0956987142562866)
(6547, 1.100736141204834)
(6548, 1.098911166191101)
(6549, 1.1017752885818481)
(6550, 1.0924088954925537)
(6551, 1.1033475399017334)
(6552, 1.100472092628479)
(6553, 1.1010457277297974)
(6554, 1.1012022495269775)
(6555, 1.093319058418274)
(6556, 1.1054991483688354)
(6557, 1.098814606666565)
(6558, 1.107519507408142)
(6559, 1.0939133167266846)
(6560, 1.0956754684448242)
(6561, 1.1039491891860962)
(6562, 1.0911062955856323)
(6563, 1.1000601053237915)
(6564, 1.107759714126587)
(6565, 1.09829580783844)
(6566, 1.0951906442642212)
(6567, 1.0933408737182617)
(6568, 1.0969988107681274)
(6569, 1.0971242189407349)
(6570, 1.1024446487426758)
(6571, 1.0958501100540161)
(6572, 1.0947626829147339)
(6573, 1.0931782722473145)
(6574, 1.0993272066116333)
(6575, 1.09843909740448)
(6576, 1.1018474102020264)
(6577, 1.0998952388763428)
(6578, 1.0979372262954712)
(6579, 1.097422480583191)
(6580, 1.1047452688217163)
(6581, 1.0962613821029663)
(6582, 1.0910604000091553)
(6583, 1.095854640007019)
(6584, 1.0979968309402466)
(6585, 1.0910446643829346)
(6586, 1.0980967283248901)
(6587, 1.092751145362854)
(6588, 1.0953415632247925)
(6589, 1.093735933303833)
(6590, 1.102168321609497)
(6591, 1.1011693477630615)
(6592, 1.097219467163086)
(6593, 1.1084792613983154)
(6594, 1.0891331434249878)
(6595, 1.1043752431869507)
(6596, 1.114587664604187)
(6597, 1.1017444133758545)
(6598, 1.09801185131073)
(6599, 1.0995550155639648)
(6600, 1.0943623781204224)
Train Epoch: 0 [13200/549367 (77%)]	Loss: 1.094362
(6601, 1.099401831626892)
(6602, 1.101898193359375)
(6603, 1.09818696975708)
(6604, 1.1090691089630127)
(6605, 1.10653817653656)
(6606, 1.0948256254196167)
(6607, 1.1121056079864502)
(6608, 1.1049062013626099)
(6609, 1.0983941555023193)
(6610, 1.0963479280471802)
(6611, 1.0995057821273804)
(6612, 1.1006133556365967)
(6613, 1.1081565618515015)
(6614, 1.1042662858963013)
(6615, 1.0948001146316528)
(6616, 1.1003092527389526)
(6617, 1.1002719402313232)
(6618, 1.100291132926941)
(6619, 1.101588249206543)
(6620, 1.1024842262268066)
(6621, 1.1017377376556396)
(6622, 1.092063069343567)
(6623, 1.0922266244888306)
(6624, 1.1019816398620605)
(6625, 1.0974434614181519)
(6626, 1.0986887216567993)
(6627, 1.1039983034133911)
(6628, 1.0939704179763794)
(6629, 1.1046295166015625)
(6630, 1.1011930704116821)
(6631, 1.0992717742919922)
(6632, 1.1091489791870117)
(6633, 1.0950708389282227)
(6634, 1.1050333976745605)
(6635, 1.1063077449798584)
(6636, 1.1025199890136719)
(6637, 1.0997828245162964)
(6638, 1.0995651483535767)
(6639, 1.0943125486373901)
(6640, 1.103856086730957)
(6641, 1.0936464071273804)
(6642, 1.0980026721954346)
(6643, 1.10096275806427)
(6644, 1.1043509244918823)
(6645, 1.0919348001480103)
(6646, 1.0959595441818237)
(6647, 1.0997487306594849)
(6648, 1.1031492948532104)
(6649, 1.0978057384490967)
(6650, 1.1003679037094116)
(6651, 1.100777268409729)
(6652, 1.097265601158142)
(6653, 1.1025258302688599)
(6654, 1.1013646125793457)
(6655, 1.0979489088058472)
(6656, 1.0945425033569336)
(6657, 1.1016831398010254)
(6658, 1.0962339639663696)
(6659, 1.0968941450119019)
(6660, 1.0959137678146362)
(6661, 1.0958257913589478)
(6662, 1.099044919013977)
(6663, 1.097632646560669)
(6664, 1.1015241146087646)
(6665, 1.0981378555297852)
(6666, 1.1007518768310547)
(6667, 1.1028227806091309)
(6668, 1.1049391031265259)
(6669, 1.0906914472579956)
(6670, 1.1000750064849854)
(6671, 1.1002585887908936)
(6672, 1.0956575870513916)
(6673, 1.1017794609069824)
(6674, 1.101537823677063)
(6675, 1.0996919870376587)
(6676, 1.1073834896087646)
(6677, 1.098846673965454)
(6678, 1.1036211252212524)
(6679, 1.0987955331802368)
(6680, 1.0999540090560913)
(6681, 1.0975291728973389)
(6682, 1.1002233028411865)
(6683, 1.1019119024276733)
(6684, 1.0993057489395142)
(6685, 1.1021621227264404)
(6686, 1.1021009683609009)
(6687, 1.0946619510650635)
(6688, 1.0978829860687256)
(6689, 1.0993094444274902)
(6690, 1.0982877016067505)
(6691, 1.098987102508545)
(6692, 1.1002042293548584)
(6693, 1.096942663192749)
(6694, 1.0966211557388306)
(6695, 1.1022449731826782)
(6696, 1.1000761985778809)
(6697, 1.0996391773223877)
(6698, 1.0960744619369507)
(6699, 1.0982823371887207)
(6700, 1.0991393327713013)
Train Epoch: 0 [13400/549367 (78%)]	Loss: 1.099139
(6701, 1.094882845878601)
(6702, 1.0987528562545776)
(6703, 1.094476580619812)
(6704, 1.0959278345108032)
(6705, 1.0985597372055054)
(6706, 1.1021870374679565)
(6707, 1.1021841764450073)
(6708, 1.0987443923950195)
(6709, 1.1011641025543213)
(6710, 1.1009184122085571)
(6711, 1.1041123867034912)
(6712, 1.0980216264724731)
(6713, 1.099096417427063)
(6714, 1.102785587310791)
(6715, 1.1009870767593384)
(6716, 1.0957963466644287)
(6717, 1.1033952236175537)
(6718, 1.097024917602539)
(6719, 1.0994441509246826)
(6720, 1.1019939184188843)
(6721, 1.0983011722564697)
(6722, 1.0980651378631592)
(6723, 1.0990372896194458)
(6724, 1.099414348602295)
(6725, 1.1033052206039429)
(6726, 1.1008381843566895)
(6727, 1.1032103300094604)
(6728, 1.0997874736785889)
(6729, 1.0985300540924072)
(6730, 1.0986809730529785)
(6731, 1.1005626916885376)
(6732, 1.0945433378219604)
(6733, 1.0978143215179443)
(6734, 1.0997422933578491)
(6735, 1.0961393117904663)
(6736, 1.0986782312393188)
(6737, 1.0991933345794678)
(6738, 1.099402904510498)
(6739, 1.1013896465301514)
(6740, 1.0979344844818115)
(6741, 1.097213864326477)
(6742, 1.0959140062332153)
(6743, 1.0981956720352173)
(6744, 1.0986385345458984)
(6745, 1.1008998155593872)
(6746, 1.0998916625976562)
(6747, 1.1003056764602661)
(6748, 1.1003201007843018)
(6749, 1.0993523597717285)
(6750, 1.0932503938674927)
(6751, 1.0983997583389282)
(6752, 1.099876880645752)
(6753, 1.0946770906448364)
(6754, 1.099209189414978)
(6755, 1.0958853960037231)
(6756, 1.096314549446106)
(6757, 1.0996036529541016)
(6758, 1.094035029411316)
(6759, 1.0960263013839722)
(6760, 1.0997461080551147)
(6761, 1.0960280895233154)
(6762, 1.0993784666061401)
(6763, 1.0949833393096924)
(6764, 1.0947442054748535)
(6765, 1.0998958349227905)
(6766, 1.0940204858779907)
(6767, 1.101011872291565)
(6768, 1.101405382156372)
(6769, 1.0977195501327515)
(6770, 1.1015082597732544)
(6771, 1.0996018648147583)
(6772, 1.094162940979004)
(6773, 1.0995465517044067)
(6774, 1.0968271493911743)
(6775, 1.1002357006072998)
(6776, 1.098251223564148)
(6777, 1.100643277168274)
(6778, 1.103458285331726)
(6779, 1.1009072065353394)
(6780, 1.1023471355438232)
(6781, 1.1011360883712769)
(6782, 1.095029354095459)
(6783, 1.0989878177642822)
(6784, 1.0987064838409424)
(6785, 1.0991315841674805)
(6786, 1.0967695713043213)
(6787, 1.0995326042175293)
(6788, 1.0987133979797363)
(6789, 1.1023902893066406)
(6790, 1.0917868614196777)
(6791, 1.0961720943450928)
(6792, 1.0980191230773926)
(6793, 1.1019874811172485)
(6794, 1.1017194986343384)
(6795, 1.0958137512207031)
(6796, 1.1024571657180786)
(6797, 1.0988085269927979)
(6798, 1.1020795106887817)
(6799, 1.1010842323303223)
(6800, 1.100234866142273)
Train Epoch: 0 [13600/549367 (79%)]	Loss: 1.100235
(6801, 1.1016689538955688)
(6802, 1.0906747579574585)
(6803, 1.1009293794631958)
(6804, 1.0971676111221313)
(6805, 1.0989151000976562)
(6806, 1.0938118696212769)
(6807, 1.1033798456192017)
(6808, 1.0996719598770142)
(6809, 1.1010870933532715)
(6810, 1.0983437299728394)
(6811, 1.1023422479629517)
(6812, 1.1005196571350098)
(6813, 1.097510814666748)
(6814, 1.0930960178375244)
(6815, 1.097998023033142)
(6816, 1.0995782613754272)
(6817, 1.0980604887008667)
(6818, 1.101458191871643)
(6819, 1.1015390157699585)
(6820, 1.0965505838394165)
(6821, 1.094647765159607)
(6822, 1.0965092182159424)
(6823, 1.0931252241134644)
(6824, 1.1029655933380127)
(6825, 1.0973020792007446)
(6826, 1.1002696752548218)
(6827, 1.0978739261627197)
(6828, 1.1015524864196777)
(6829, 1.10245943069458)
(6830, 1.1027843952178955)
(6831, 1.0982099771499634)
(6832, 1.1037299633026123)
(6833, 1.094980001449585)
(6834, 1.0955663919448853)
(6835, 1.0967812538146973)
(6836, 1.094271183013916)
(6837, 1.0976310968399048)
(6838, 1.1009886264801025)
(6839, 1.0952425003051758)
(6840, 1.099996566772461)
(6841, 1.09757399559021)
(6842, 1.097606897354126)
(6843, 1.0964266061782837)
(6844, 1.0979408025741577)
(6845, 1.0976041555404663)
(6846, 1.1008915901184082)
(6847, 1.0916178226470947)
(6848, 1.0981343984603882)
(6849, 1.1013957262039185)
(6850, 1.103015422821045)
(6851, 1.1022932529449463)
(6852, 1.0965391397476196)
(6853, 1.0968483686447144)
(6854, 1.0991356372833252)
(6855, 1.100710391998291)
(6856, 1.0957111120224)
(6857, 1.1015819311141968)
(6858, 1.1008620262145996)
(6859, 1.0928099155426025)
(6860, 1.1008968353271484)
(6861, 1.0948030948638916)
(6862, 1.0982218980789185)
(6863, 1.0966320037841797)
(6864, 1.1008269786834717)
(6865, 1.1002986431121826)
(6866, 1.0990275144577026)
(6867, 1.0966862440109253)
(6868, 1.098755955696106)
(6869, 1.098759651184082)
(6870, 1.097700834274292)
(6871, 1.0938801765441895)
(6872, 1.100328803062439)
(6873, 1.1010159254074097)
(6874, 1.0962681770324707)
(6875, 1.0988352298736572)
(6876, 1.0968821048736572)
(6877, 1.102673888206482)
(6878, 1.0968220233917236)
(6879, 1.1001518964767456)
(6880, 1.1015987396240234)
(6881, 1.0991156101226807)
(6882, 1.0946515798568726)
(6883, 1.0893112421035767)
(6884, 1.103962779045105)
(6885, 1.097971796989441)
(6886, 1.0977643728256226)
(6887, 1.1030584573745728)
(6888, 1.0992156267166138)
(6889, 1.095570683479309)
(6890, 1.0940098762512207)
(6891, 1.1001499891281128)
(6892, 1.099311113357544)
(6893, 1.1017396450042725)
(6894, 1.1033602952957153)
(6895, 1.1065493822097778)
(6896, 1.1014617681503296)
(6897, 1.1013821363449097)
(6898, 1.0998661518096924)
(6899, 1.095228672027588)
(6900, 1.1019668579101562)
Train Epoch: 0 [13800/549367 (80%)]	Loss: 1.101967
(6901, 1.0949021577835083)
(6902, 1.094848871231079)
(6903, 1.0999705791473389)
(6904, 1.1013946533203125)
(6905, 1.1046040058135986)
(6906, 1.0956555604934692)
(6907, 1.093790888786316)
(6908, 1.101633071899414)
(6909, 1.101550817489624)
(6910, 1.1004928350448608)
(6911, 1.0951783657073975)
(6912, 1.10029137134552)
(6913, 1.1017268896102905)
(6914, 1.0993801355361938)
(6915, 1.0993949174880981)
(6916, 1.0981202125549316)
(6917, 1.1002471446990967)
(6918, 1.0978517532348633)
(6919, 1.1027534008026123)
(6920, 1.099756121635437)
(6921, 1.096845030784607)
(6922, 1.0975278615951538)
(6923, 1.0995419025421143)
(6924, 1.0967472791671753)
(6925, 1.1021534204483032)
(6926, 1.1013245582580566)
(6927, 1.0977624654769897)
(6928, 1.099672555923462)
(6929, 1.097578763961792)
(6930, 1.0992645025253296)
(6931, 1.1013867855072021)
(6932, 1.09848153591156)
(6933, 1.09516441822052)
(6934, 1.0988764762878418)
(6935, 1.095530390739441)
(6936, 1.095192790031433)
(6937, 1.0997498035430908)
(6938, 1.0975167751312256)
(6939, 1.1039533615112305)
(6940, 1.0943148136138916)
(6941, 1.0960451364517212)
(6942, 1.0993603467941284)
(6943, 1.0957823991775513)
(6944, 1.0998945236206055)
(6945, 1.0966633558273315)
(6946, 1.101485013961792)
(6947, 1.1093887090682983)
(6948, 1.102833867073059)
(6949, 1.09954833984375)
(6950, 1.0983209609985352)
(6951, 1.0960248708724976)
(6952, 1.1028612852096558)
(6953, 1.0985699892044067)
(6954, 1.0955164432525635)
(6955, 1.0968974828720093)
(6956, 1.099453091621399)
(6957, 1.1088535785675049)
(6958, 1.0994353294372559)
(6959, 1.0998777151107788)
(6960, 1.0992032289505005)
(6961, 1.1037923097610474)
(6962, 1.100709319114685)
(6963, 1.098296880722046)
(6964, 1.0950393676757812)
(6965, 1.092585802078247)
(6966, 1.1037462949752808)
(6967, 1.0962510108947754)
(6968, 1.0980855226516724)
(6969, 1.101264238357544)
(6970, 1.0960631370544434)
(6971, 1.100921869277954)
(6972, 1.1032588481903076)
(6973, 1.0984890460968018)
(6974, 1.0956467390060425)
(6975, 1.1024202108383179)
(6976, 1.1021226644515991)
(6977, 1.0985037088394165)
(6978, 1.0995084047317505)
(6979, 1.0998376607894897)
(6980, 1.1025558710098267)
(6981, 1.0960441827774048)
(6982, 1.0963094234466553)
(6983, 1.1028025150299072)
(6984, 1.0967457294464111)
(6985, 1.1030242443084717)
(6986, 1.1013239622116089)
(6987, 1.1012929677963257)
(6988, 1.0943740606307983)
(6989, 1.0938615798950195)
(6990, 1.0997499227523804)
(6991, 1.0973925590515137)
(6992, 1.0955514907836914)
(6993, 1.0983264446258545)
(6994, 1.0992164611816406)
(6995, 1.1048222780227661)
(6996, 1.1033880710601807)
(6997, 1.0978038311004639)
(6998, 1.0993844270706177)
(6999, 1.0998258590698242)
(7000, 1.094597339630127)
Train Epoch: 0 [14000/549367 (82%)]	Loss: 1.094597
(7001, 1.0959125757217407)
(7002, 1.099933385848999)
(7003, 1.0993837118148804)
(7004, 1.0926172733306885)
(7005, 1.0949629545211792)
(7006, 1.0953736305236816)
(7007, 1.0994762182235718)
(7008, 1.103347659111023)
(7009, 1.0980697870254517)
(7010, 1.095076560974121)
(7011, 1.1023998260498047)
(7012, 1.095517635345459)
(7013, 1.0993765592575073)
(7014, 1.0984206199645996)
(7015, 1.0984910726547241)
(7016, 1.101427674293518)
(7017, 1.0988714694976807)
(7018, 1.096534252166748)
(7019, 1.099338412284851)
(7020, 1.1008306741714478)
(7021, 1.097330927848816)
(7022, 1.099255084991455)
(7023, 1.0985668897628784)
(7024, 1.097671389579773)
(7025, 1.0937162637710571)
(7026, 1.09774649143219)
(7027, 1.103640079498291)
(7028, 1.0956777334213257)
(7029, 1.0999376773834229)
(7030, 1.1001774072647095)
(7031, 1.0946894884109497)
(7032, 1.100433111190796)
(7033, 1.0963590145111084)
(7034, 1.100089192390442)
(7035, 1.1005287170410156)
(7036, 1.0991051197052002)
(7037, 1.0956660509109497)
(7038, 1.0983833074569702)
(7039, 1.1025986671447754)
(7040, 1.101383090019226)
(7041, 1.0993603467941284)
(7042, 1.100157618522644)
(7043, 1.102432370185852)
(7044, 1.098001480102539)
(7045, 1.1003398895263672)
(7046, 1.1055258512496948)
(7047, 1.1079423427581787)
(7048, 1.0971065759658813)
(7049, 1.0987917184829712)
(7050, 1.0989267826080322)
(7051, 1.102158546447754)
(7052, 1.1014879941940308)
(7053, 1.0960465669631958)
(7054, 1.1045125722885132)
(7055, 1.1032118797302246)
(7056, 1.0958993434906006)
(7057, 1.0959244966506958)
(7058, 1.1016685962677002)
(7059, 1.102833867073059)
(7060, 1.0986696481704712)
(7061, 1.0966144800186157)
(7062, 1.0958032608032227)
(7063, 1.0953305959701538)
(7064, 1.0975044965744019)
(7065, 1.1001816987991333)
(7066, 1.0980664491653442)
(7067, 1.0981141328811646)
(7068, 1.0965386629104614)
(7069, 1.1029189825057983)
(7070, 1.0972110033035278)
(7071, 1.0995092391967773)
(7072, 1.0978952646255493)
(7073, 1.1018617153167725)
(7074, 1.099883794784546)
(7075, 1.0998576879501343)
(7076, 1.0943361520767212)
(7077, 1.0953686237335205)
(7078, 1.096740484237671)
(7079, 1.0991337299346924)
(7080, 1.1013175249099731)
(7081, 1.1009811162948608)
(7082, 1.101602554321289)
(7083, 1.0961909294128418)
(7084, 1.1010388135910034)
(7085, 1.0958086252212524)
(7086, 1.0977133512496948)
(7087, 1.0992175340652466)
(7088, 1.1016008853912354)
(7089, 1.101778507232666)
(7090, 1.0993682146072388)
(7091, 1.0971722602844238)
(7092, 1.097477674484253)
(7093, 1.0957366228103638)
(7094, 1.0962313413619995)
(7095, 1.102246642112732)
(7096, 1.0982602834701538)
(7097, 1.1004869937896729)
(7098, 1.098152756690979)
(7099, 1.1010791063308716)
(7100, 1.0980905294418335)
Train Epoch: 0 [14200/549367 (83%)]	Loss: 1.098091
(7101, 1.0966264009475708)
(7102, 1.0996171236038208)
(7103, 1.09535813331604)
(7104, 1.1003479957580566)
(7105, 1.0989744663238525)
(7106, 1.10173499584198)
(7107, 1.100111722946167)
(7108, 1.1008503437042236)
(7109, 1.1003555059432983)
(7110, 1.096732497215271)
(7111, 1.0980420112609863)
(7112, 1.0975341796875)
(7113, 1.1013691425323486)
(7114, 1.1014835834503174)
(7115, 1.0996251106262207)
(7116, 1.0997076034545898)
(7117, 1.101851224899292)
(7118, 1.0989724397659302)
(7119, 1.1015712022781372)
(7120, 1.0979368686676025)
(7121, 1.099852204322815)
(7122, 1.097286343574524)
(7123, 1.0983552932739258)
(7124, 1.0966522693634033)
(7125, 1.1036640405654907)
(7126, 1.0974030494689941)
(7127, 1.097361445426941)
(7128, 1.099218726158142)
(7129, 1.0984609127044678)
(7130, 1.097878336906433)
(7131, 1.0964722633361816)
(7132, 1.0979877710342407)
(7133, 1.0998921394348145)
(7134, 1.0987926721572876)
(7135, 1.0992413759231567)
(7136, 1.0961233377456665)
(7137, 1.1005992889404297)
(7138, 1.0995569229125977)
(7139, 1.1019312143325806)
(7140, 1.100701093673706)
(7141, 1.095468521118164)
(7142, 1.0972387790679932)
(7143, 1.100475788116455)
(7144, 1.0989750623703003)
(7145, 1.1006721258163452)
(7146, 1.0985480546951294)
(7147, 1.1011310815811157)
(7148, 1.0925040245056152)
(7149, 1.0989062786102295)
(7150, 1.0959523916244507)
(7151, 1.1022875308990479)
(7152, 1.0990759134292603)
(7153, 1.1006914377212524)
(7154, 1.103807806968689)
(7155, 1.0954383611679077)
(7156, 1.101846694946289)
(7157, 1.0946905612945557)
(7158, 1.0994590520858765)
(7159, 1.1020452976226807)
(7160, 1.1016860008239746)
(7161, 1.0991886854171753)
(7162, 1.0984896421432495)
(7163, 1.1024783849716187)
(7164, 1.0937010049819946)
(7165, 1.09804368019104)
(7166, 1.098070740699768)
(7167, 1.098084568977356)
(7168, 1.0996253490447998)
(7169, 1.1018410921096802)
(7170, 1.0978399515151978)
(7171, 1.0990264415740967)
(7172, 1.1024450063705444)
(7173, 1.1003422737121582)
(7174, 1.1014561653137207)
(7175, 1.103747010231018)
(7176, 1.0997843742370605)
(7177, 1.1004819869995117)
(7178, 1.1024823188781738)
(7179, 1.0987814664840698)
(7180, 1.1012444496154785)
(7181, 1.0974578857421875)
(7182, 1.1011853218078613)
(7183, 1.0982248783111572)
(7184, 1.0977741479873657)
(7185, 1.097196102142334)
(7186, 1.0978363752365112)
(7187, 1.101177453994751)
(7188, 1.0984723567962646)
(7189, 1.099487543106079)
(7190, 1.099116563796997)
(7191, 1.1011852025985718)
(7192, 1.10064697265625)
(7193, 1.1009790897369385)
(7194, 1.0961391925811768)
(7195, 1.0992146730422974)
(7196, 1.0998506546020508)
(7197, 1.0991045236587524)
(7198, 1.1001979112625122)
(7199, 1.1000685691833496)
(7200, 1.095976710319519)
Train Epoch: 0 [14400/549367 (84%)]	Loss: 1.095977
(7201, 1.1018261909484863)
(7202, 1.0935978889465332)
(7203, 1.098175287246704)
(7204, 1.0972304344177246)
(7205, 1.1021981239318848)
(7206, 1.0970432758331299)
(7207, 1.1002862453460693)
(7208, 1.0983527898788452)
(7209, 1.0973888635635376)
(7210, 1.1012072563171387)
(7211, 1.0990232229232788)
(7212, 1.1001431941986084)
(7213, 1.0991743803024292)
(7214, 1.1022437810897827)
(7215, 1.1005761623382568)
(7216, 1.0989806652069092)
(7217, 1.0979609489440918)
(7218, 1.0991284847259521)
(7219, 1.099410891532898)
(7220, 1.0985467433929443)
(7221, 1.1037797927856445)
(7222, 1.0984822511672974)
(7223, 1.098767638206482)
(7224, 1.0996836423873901)
(7225, 1.1006171703338623)
(7226, 1.0956767797470093)
(7227, 1.0999661684036255)
(7228, 1.0981855392456055)
(7229, 1.0954729318618774)
(7230, 1.1030045747756958)
(7231, 1.095810055732727)
(7232, 1.0976251363754272)
(7233, 1.100655436515808)
(7234, 1.1017298698425293)
(7235, 1.095603585243225)
(7236, 1.1004642248153687)
(7237, 1.0985922813415527)
(7238, 1.0992571115493774)
(7239, 1.0984981060028076)
(7240, 1.0961828231811523)
(7241, 1.0961741209030151)
(7242, 1.095708966255188)
(7243, 1.1013771295547485)
(7244, 1.0965808629989624)
(7245, 1.0976942777633667)
(7246, 1.1019771099090576)
(7247, 1.101088047027588)
(7248, 1.0998852252960205)
(7249, 1.0996365547180176)
(7250, 1.100152611732483)
(7251, 1.101332187652588)
(7252, 1.0995583534240723)
(7253, 1.0940556526184082)
(7254, 1.097643494606018)
(7255, 1.1020686626434326)
(7256, 1.0979058742523193)
(7257, 1.0967782735824585)
(7258, 1.0989365577697754)
(7259, 1.0959501266479492)
(7260, 1.0972038507461548)
(7261, 1.099452018737793)
(7262, 1.0948411226272583)
(7263, 1.100193738937378)
(7264, 1.098393201828003)
(7265, 1.0993562936782837)
(7266, 1.0959725379943848)
(7267, 1.1012710332870483)
(7268, 1.1002755165100098)
(7269, 1.0995571613311768)
(7270, 1.0944924354553223)
(7271, 1.100701928138733)
(7272, 1.0979628562927246)
(7273, 1.099815845489502)
(7274, 1.1024188995361328)
(7275, 1.0972013473510742)
(7276, 1.0973753929138184)
(7277, 1.098509669303894)
(7278, 1.0961024761199951)
(7279, 1.1004246473312378)
(7280, 1.0989774465560913)
(7281, 1.1032174825668335)
(7282, 1.0998990535736084)
(7283, 1.0988916158676147)
(7284, 1.099766492843628)
(7285, 1.0972449779510498)
(7286, 1.0960578918457031)
(7287, 1.1003754138946533)
(7288, 1.1038966178894043)
(7289, 1.0966167449951172)
(7290, 1.0973727703094482)
(7291, 1.1002602577209473)
(7292, 1.101693034172058)
(7293, 1.095606803894043)
(7294, 1.095504641532898)
(7295, 1.1017547845840454)
(7296, 1.0956263542175293)
(7297, 1.1014482975006104)
(7298, 1.097975730895996)
(7299, 1.0958532094955444)
(7300, 1.0952668190002441)
Train Epoch: 0 [14600/549367 (85%)]	Loss: 1.095267
(7301, 1.1011627912521362)
(7302, 1.097115397453308)
(7303, 1.0974141359329224)
(7304, 1.1003658771514893)
(7305, 1.096596121788025)
(7306, 1.1003224849700928)
(7307, 1.098240852355957)
(7308, 1.0977678298950195)
(7309, 1.0981801748275757)
(7310, 1.1002990007400513)
(7311, 1.1025476455688477)
(7312, 1.101044774055481)
(7313, 1.0970854759216309)
(7314, 1.0991342067718506)
(7315, 1.099545955657959)
(7316, 1.0956722497940063)
(7317, 1.1005361080169678)
(7318, 1.1001265048980713)
(7319, 1.0964616537094116)
(7320, 1.0970429182052612)
(7321, 1.1008142232894897)
(7322, 1.0961873531341553)
(7323, 1.0978314876556396)
(7324, 1.0976240634918213)
(7325, 1.102980136871338)
(7326, 1.0955075025558472)
(7327, 1.0963423252105713)
(7328, 1.0964899063110352)
(7329, 1.102843165397644)
(7330, 1.1012611389160156)
(7331, 1.0978509187698364)
(7332, 1.101125955581665)
(7333, 1.0985078811645508)
(7334, 1.0982633829116821)
(7335, 1.1015419960021973)
(7336, 1.0969778299331665)
(7337, 1.097839593887329)
(7338, 1.0994945764541626)
(7339, 1.097507119178772)
(7340, 1.1001839637756348)
(7341, 1.097643494606018)
(7342, 1.0985260009765625)
(7343, 1.0926927328109741)
(7344, 1.102542757987976)
(7345, 1.0987838506698608)
(7346, 1.098120927810669)
(7347, 1.09884774684906)
(7348, 1.0968451499938965)
(7349, 1.1045653820037842)
(7350, 1.1031765937805176)
(7351, 1.0974875688552856)
(7352, 1.095548152923584)
(7353, 1.1011208295822144)
(7354, 1.099409580230713)
(7355, 1.1005370616912842)
(7356, 1.095479965209961)
(7357, 1.0984867811203003)
(7358, 1.097269892692566)
(7359, 1.0939033031463623)
(7360, 1.0978000164031982)
(7361, 1.0998520851135254)
(7362, 1.1012310981750488)
(7363, 1.0951638221740723)
(7364, 1.0967849493026733)
(7365, 1.0935251712799072)
(7366, 1.097058653831482)
(7367, 1.098921537399292)
(7368, 1.1008065938949585)
(7369, 1.095869541168213)
(7370, 1.0937035083770752)
(7371, 1.100037932395935)
(7372, 1.1042841672897339)
(7373, 1.0971263647079468)
(7374, 1.0996568202972412)
(7375, 1.1025617122650146)
(7376, 1.0958911180496216)
(7377, 1.1007198095321655)
(7378, 1.0995742082595825)
(7379, 1.098122477531433)
(7380, 1.0953805446624756)
(7381, 1.0936110019683838)
(7382, 1.0985488891601562)
(7383, 1.0991084575653076)
(7384, 1.0975382328033447)
(7385, 1.0996259450912476)
(7386, 1.099442958831787)
(7387, 1.0998252630233765)
(7388, 1.0984594821929932)
(7389, 1.0996555089950562)
(7390, 1.1042145490646362)
(7391, 1.0995210409164429)
(7392, 1.0976881980895996)
(7393, 1.095496654510498)
(7394, 1.0971348285675049)
(7395, 1.0961198806762695)
(7396, 1.0940617322921753)
(7397, 1.1003178358078003)
(7398, 1.1016855239868164)
(7399, 1.0984104871749878)
(7400, 1.100115418434143)
Train Epoch: 0 [14800/549367 (86%)]	Loss: 1.100115
(7401, 1.101080298423767)
(7402, 1.0945223569869995)
(7403, 1.0947816371917725)
(7404, 1.0989857912063599)
(7405, 1.1004135608673096)
(7406, 1.0964946746826172)
(7407, 1.0937248468399048)
(7408, 1.0961976051330566)
(7409, 1.0999528169631958)
(7410, 1.0975236892700195)
(7411, 1.1007620096206665)
(7412, 1.1027752161026)
(7413, 1.1005396842956543)
(7414, 1.0981756448745728)
(7415, 1.0972665548324585)
(7416, 1.1001214981079102)
(7417, 1.0956356525421143)
(7418, 1.0926225185394287)
(7419, 1.0968174934387207)
(7420, 1.1001029014587402)
(7421, 1.097105860710144)
(7422, 1.105474829673767)
(7423, 1.096727967262268)
(7424, 1.0976389646530151)
(7425, 1.0981210470199585)
(7426, 1.1045055389404297)
(7427, 1.0984361171722412)
(7428, 1.0982856750488281)
(7429, 1.1019262075424194)
(7430, 1.101360559463501)
(7431, 1.1019095182418823)
(7432, 1.1031163930892944)
(7433, 1.1031705141067505)
(7434, 1.1025400161743164)
(7435, 1.1033016443252563)
(7436, 1.1008423566818237)
(7437, 1.096183180809021)
(7438, 1.0988155603408813)
(7439, 1.1034272909164429)
(7440, 1.1016178131103516)
(7441, 1.1004892587661743)
(7442, 1.098764181137085)
(7443, 1.095432996749878)
(7444, 1.0993754863739014)
(7445, 1.0998988151550293)
(7446, 1.0979512929916382)
(7447, 1.1001255512237549)
(7448, 1.0961461067199707)
(7449, 1.0987122058868408)
(7450, 1.0976884365081787)
(7451, 1.098888874053955)
(7452, 1.1000710725784302)
(7453, 1.09437894821167)
(7454, 1.0987505912780762)
(7455, 1.0966941118240356)
(7456, 1.094881534576416)
(7457, 1.0944210290908813)
(7458, 1.09687340259552)
(7459, 1.0995267629623413)
(7460, 1.1004507541656494)
(7461, 1.097898006439209)
(7462, 1.0999177694320679)
(7463, 1.0946762561798096)
(7464, 1.0993058681488037)
(7465, 1.0954232215881348)
(7466, 1.1023564338684082)
(7467, 1.09553062915802)
(7468, 1.1048614978790283)
(7469, 1.096114993095398)
(7470, 1.1006799936294556)
(7471, 1.0986347198486328)
(7472, 1.094081997871399)
(7473, 1.1031142473220825)
(7474, 1.100969672203064)
(7475, 1.0960776805877686)
(7476, 1.1047894954681396)
(7477, 1.1024370193481445)
(7478, 1.0984418392181396)
(7479, 1.0988861322402954)
(7480, 1.1015527248382568)
(7481, 1.1016651391983032)
(7482, 1.0988422632217407)
(7483, 1.0969719886779785)
(7484, 1.099995493888855)
(7485, 1.098452091217041)
(7486, 1.0951745510101318)
(7487, 1.09748375415802)
(7488, 1.103658676147461)
(7489, 1.0958625078201294)
(7490, 1.0975440740585327)
(7491, 1.0983684062957764)
(7492, 1.1032594442367554)
(7493, 1.1046783924102783)
(7494, 1.0947308540344238)
(7495, 1.1035178899765015)
(7496, 1.1024491786956787)
(7497, 1.0948107242584229)
(7498, 1.097621202468872)
(7499, 1.1009228229522705)
(7500, 1.0983967781066895)
Train Epoch: 0 [15000/549367 (87%)]	Loss: 1.098397
(7501, 1.100300669670105)
(7502, 1.0935360193252563)
(7503, 1.1005125045776367)
(7504, 1.1026809215545654)
(7505, 1.10178804397583)
(7506, 1.0989551544189453)
(7507, 1.092702031135559)
(7508, 1.1034077405929565)
(7509, 1.0912342071533203)
(7510, 1.0965237617492676)
(7511, 1.1029798984527588)
(7512, 1.095727801322937)
(7513, 1.0968235731124878)
(7514, 1.0996849536895752)
(7515, 1.0971176624298096)
(7516, 1.1005175113677979)
(7517, 1.1028505563735962)
(7518, 1.0987950563430786)
(7519, 1.0964728593826294)
(7520, 1.0992358922958374)
(7521, 1.1001362800598145)
(7522, 1.1016203165054321)
(7523, 1.09850013256073)
(7524, 1.0973939895629883)
(7525, 1.102171540260315)
(7526, 1.0950171947479248)
(7527, 1.0985952615737915)
(7528, 1.099033236503601)
(7529, 1.099104404449463)
(7530, 1.102255940437317)
(7531, 1.1028876304626465)
(7532, 1.0989915132522583)
(7533, 1.10193932056427)
(7534, 1.0992262363433838)
(7535, 1.0972468852996826)
(7536, 1.1028480529785156)
(7537, 1.0986803770065308)
(7538, 1.0948508977890015)
(7539, 1.1008127927780151)
(7540, 1.0878281593322754)
(7541, 1.1017199754714966)
(7542, 1.1045204401016235)
(7543, 1.0991871356964111)
(7544, 1.1038237810134888)
(7545, 1.1004133224487305)
(7546, 1.099959135055542)
(7547, 1.09952974319458)
(7548, 1.0971719026565552)
(7549, 1.1043912172317505)
(7550, 1.1037843227386475)
(7551, 1.0994725227355957)
(7552, 1.099516749382019)
(7553, 1.0992172956466675)
(7554, 1.0918840169906616)
(7555, 1.0973711013793945)
(7556, 1.1013795137405396)
(7557, 1.1011936664581299)
(7558, 1.0991582870483398)
(7559, 1.0951446294784546)
(7560, 1.0983672142028809)
(7561, 1.0970336198806763)
(7562, 1.1039447784423828)
(7563, 1.097045660018921)
(7564, 1.1007165908813477)
(7565, 1.0974090099334717)
(7566, 1.1040103435516357)
(7567, 1.098877191543579)
(7568, 1.0972975492477417)
(7569, 1.0992968082427979)
(7570, 1.099053144454956)
(7571, 1.0996780395507812)
(7572, 1.098712682723999)
(7573, 1.0959302186965942)
(7574, 1.102578043937683)
(7575, 1.0998291969299316)
(7576, 1.101539134979248)
(7577, 1.092529296875)
(7578, 1.1051849126815796)
(7579, 1.103661060333252)
(7580, 1.1022859811782837)
(7581, 1.0965615510940552)
(7582, 1.0982996225357056)
(7583, 1.096853256225586)
(7584, 1.0990369319915771)
(7585, 1.0999056100845337)
(7586, 1.0995368957519531)
(7587, 1.1008063554763794)
(7588, 1.0973671674728394)
(7589, 1.1017707586288452)
(7590, 1.1010602712631226)
(7591, 1.0980926752090454)
(7592, 1.0979688167572021)
(7593, 1.0911524295806885)
(7594, 1.100982904434204)
(7595, 1.0984327793121338)
(7596, 1.098013997077942)
(7597, 1.0983954668045044)
(7598, 1.1002479791641235)
(7599, 1.101078987121582)
(7600, 1.0958068370819092)
Train Epoch: 0 [15200/549367 (89%)]	Loss: 1.095807
(7601, 1.09786057472229)
(7602, 1.0982248783111572)
(7603, 1.1005499362945557)
(7604, 1.0988253355026245)
(7605, 1.0931199789047241)
(7606, 1.099530816078186)
(7607, 1.1008127927780151)
(7608, 1.0990606546401978)
(7609, 1.1024971008300781)
(7610, 1.0957765579223633)
(7611, 1.1022638082504272)
(7612, 1.0976303815841675)
(7613, 1.0952337980270386)
(7614, 1.0986173152923584)
(7615, 1.0994912385940552)
(7616, 1.1005680561065674)
(7617, 1.0987533330917358)
(7618, 1.0970643758773804)
(7619, 1.1008044481277466)
(7620, 1.097609519958496)
(7621, 1.1037585735321045)
(7622, 1.0999774932861328)
(7623, 1.096043348312378)
(7624, 1.100538969039917)
(7625, 1.0936256647109985)
(7626, 1.0967191457748413)
(7627, 1.103438377380371)
(7628, 1.0982413291931152)
(7629, 1.097766399383545)
(7630, 1.0974451303482056)
(7631, 1.1035020351409912)
(7632, 1.0972040891647339)
(7633, 1.103114128112793)
(7634, 1.0967377424240112)
(7635, 1.098367691040039)
(7636, 1.0973118543624878)
(7637, 1.1003825664520264)
(7638, 1.0991504192352295)
(7639, 1.098736047744751)
(7640, 1.1015020608901978)
(7641, 1.0998014211654663)
(7642, 1.0984569787979126)
(7643, 1.099597692489624)
(7644, 1.1010242700576782)
(7645, 1.1009538173675537)
(7646, 1.0975269079208374)
(7647, 1.0957804918289185)
(7648, 1.1006183624267578)
(7649, 1.1005147695541382)
(7650, 1.1017519235610962)
(7651, 1.0992320775985718)
(7652, 1.098199486732483)
(7653, 1.099879264831543)
(7654, 1.098248839378357)
(7655, 1.1000747680664062)
(7656, 1.09907865524292)
(7657, 1.1013262271881104)
(7658, 1.0990840196609497)
(7659, 1.098360300064087)
(7660, 1.098131775856018)
(7661, 1.0987098217010498)
(7662, 1.0952140092849731)
(7663, 1.104441523551941)
(7664, 1.1005595922470093)
(7665, 1.0981194972991943)
(7666, 1.097885251045227)
(7667, 1.0955430269241333)
(7668, 1.0937440395355225)
(7669, 1.0998739004135132)
(7670, 1.0976505279541016)
(7671, 1.0969643592834473)
(7672, 1.0999025106430054)
(7673, 1.0988996028900146)
(7674, 1.1015901565551758)
(7675, 1.1042057275772095)
(7676, 1.097118854522705)
(7677, 1.1026381254196167)
(7678, 1.0995218753814697)
(7679, 1.0969854593276978)
(7680, 1.0947190523147583)
(7681, 1.1008535623550415)
(7682, 1.0982680320739746)
(7683, 1.0979514122009277)
(7684, 1.0994641780853271)
(7685, 1.0973377227783203)
(7686, 1.099170446395874)
(7687, 1.0965533256530762)
(7688, 1.104394555091858)
(7689, 1.1022926568984985)
(7690, 1.0996109247207642)
(7691, 1.097291350364685)
(7692, 1.0976545810699463)
(7693, 1.0972285270690918)
(7694, 1.0993642807006836)
(7695, 1.101067304611206)
(7696, 1.0978219509124756)
(7697, 1.0973066091537476)
(7698, 1.0986428260803223)
(7699, 1.0953497886657715)
(7700, 1.1002365350723267)
Train Epoch: 0 [15400/549367 (90%)]	Loss: 1.100237
(7701, 1.0980912446975708)
(7702, 1.0957791805267334)
(7703, 1.0970863103866577)
(7704, 1.0987703800201416)
(7705, 1.1031756401062012)
(7706, 1.09590482711792)
(7707, 1.0988895893096924)
(7708, 1.100785255432129)
(7709, 1.101083755493164)
(7710, 1.098565697669983)
(7711, 1.0998146533966064)
(7712, 1.1006814241409302)
(7713, 1.096864938735962)
(7714, 1.1034882068634033)
(7715, 1.1024867296218872)
(7716, 1.1012197732925415)
(7717, 1.0912091732025146)
(7718, 1.0961562395095825)
(7719, 1.0983275175094604)
(7720, 1.1046417951583862)
(7721, 1.0972594022750854)
(7722, 1.0986052751541138)
(7723, 1.1005319356918335)
(7724, 1.0989757776260376)
(7725, 1.1009938716888428)
(7726, 1.1010313034057617)
(7727, 1.0990869998931885)
(7728, 1.0996980667114258)
(7729, 1.0982259511947632)
(7730, 1.1040929555892944)
(7731, 1.0972602367401123)
(7732, 1.0950868129730225)
(7733, 1.1022186279296875)
(7734, 1.1010607481002808)
(7735, 1.098615050315857)
(7736, 1.099250078201294)
(7737, 1.0999889373779297)
(7738, 1.0998722314834595)
(7739, 1.0963269472122192)
(7740, 1.1012495756149292)
(7741, 1.097284197807312)
(7742, 1.097078800201416)
(7743, 1.0992885828018188)
(7744, 1.101462483406067)
(7745, 1.0972214937210083)
(7746, 1.0964778661727905)
(7747, 1.0991849899291992)
(7748, 1.105058193206787)
(7749, 1.1010091304779053)
(7750, 1.09754478931427)
(7751, 1.1010594367980957)
(7752, 1.096521258354187)
(7753, 1.0987299680709839)
(7754, 1.1014469861984253)
(7755, 1.100022792816162)
(7756, 1.0981744527816772)
(7757, 1.0989097356796265)
(7758, 1.1004105806350708)
(7759, 1.1009496450424194)
(7760, 1.0995391607284546)
(7761, 1.0997014045715332)
(7762, 1.101234793663025)
(7763, 1.0974451303482056)
(7764, 1.0975810289382935)
(7765, 1.1023255586624146)
(7766, 1.0976685285568237)
(7767, 1.0997843742370605)
(7768, 1.0988447666168213)
(7769, 1.0981591939926147)
(7770, 1.1000937223434448)
(7771, 1.0978389978408813)
(7772, 1.0983105897903442)
(7773, 1.0977236032485962)
(7774, 1.1002764701843262)
(7775, 1.1005390882492065)
(7776, 1.104631781578064)
(7777, 1.0965054035186768)
(7778, 1.0983294248580933)
(7779, 1.0954623222351074)
(7780, 1.1007051467895508)
(7781, 1.1001183986663818)
(7782, 1.0973172187805176)
(7783, 1.096488118171692)
(7784, 1.097251296043396)
(7785, 1.101647973060608)
(7786, 1.0998520851135254)
(7787, 1.0977574586868286)
(7788, 1.0977089405059814)
(7789, 1.0999350547790527)
(7790, 1.0994676351547241)
(7791, 1.102264165878296)
(7792, 1.1005220413208008)
(7793, 1.0994799137115479)
(7794, 1.0983014106750488)
(7795, 1.1009043455123901)
(7796, 1.0974748134613037)
(7797, 1.0970524549484253)
(7798, 1.095444917678833)
(7799, 1.100618600845337)
(7800, 1.0975861549377441)
Train Epoch: 0 [15600/549367 (91%)]	Loss: 1.097586
(7801, 1.0998672246932983)
(7802, 1.1004769802093506)
(7803, 1.1014550924301147)
(7804, 1.0994116067886353)
(7805, 1.101026177406311)
(7806, 1.1026992797851562)
(7807, 1.0976924896240234)
(7808, 1.102055311203003)
(7809, 1.1004279851913452)
(7810, 1.0974751710891724)
(7811, 1.0992716550827026)
(7812, 1.096510648727417)
(7813, 1.095848798751831)
(7814, 1.1024731397628784)
(7815, 1.0991286039352417)
(7816, 1.0989536046981812)
(7817, 1.0972825288772583)
(7818, 1.098514437675476)
(7819, 1.0976252555847168)
(7820, 1.0989071130752563)
(7821, 1.0960090160369873)
(7822, 1.0996583700180054)
(7823, 1.099297285079956)
(7824, 1.0959124565124512)
(7825, 1.0994913578033447)
(7826, 1.102523922920227)
(7827, 1.0968748331069946)
(7828, 1.0974141359329224)
(7829, 1.1032006740570068)
(7830, 1.0982047319412231)
(7831, 1.098039150238037)
(7832, 1.1011091470718384)
(7833, 1.1003854274749756)
(7834, 1.098667860031128)
(7835, 1.097186803817749)
(7836, 1.095188856124878)
(7837, 1.0951844453811646)
(7838, 1.1064670085906982)
(7839, 1.0958971977233887)
(7840, 1.0996237993240356)
(7841, 1.0991395711898804)
(7842, 1.0985461473464966)
(7843, 1.0953257083892822)
(7844, 1.0990701913833618)
(7845, 1.1002706289291382)
(7846, 1.1003044843673706)
(7847, 1.0957140922546387)
(7848, 1.0972758531570435)
(7849, 1.094969630241394)
(7850, 1.1006101369857788)
(7851, 1.0981396436691284)
(7852, 1.1008167266845703)
(7853, 1.1031882762908936)
(7854, 1.1004775762557983)
(7855, 1.0997594594955444)
(7856, 1.0931074619293213)
(7857, 1.0970070362091064)
(7858, 1.094875693321228)
(7859, 1.0983476638793945)
(7860, 1.0998481512069702)
(7861, 1.1007553339004517)
(7862, 1.1006532907485962)
(7863, 1.0968972444534302)
(7864, 1.099870204925537)
(7865, 1.100978970527649)
(7866, 1.0976626873016357)
(7867, 1.102674126625061)
(7868, 1.0926333665847778)
(7869, 1.0991742610931396)
(7870, 1.0932754278182983)
(7871, 1.1015220880508423)
(7872, 1.099663257598877)
(7873, 1.1010550260543823)
(7874, 1.0986285209655762)
(7875, 1.097700834274292)
(7876, 1.102595329284668)
(7877, 1.098832368850708)
(7878, 1.101263165473938)
(7879, 1.0937389135360718)
(7880, 1.1071149110794067)
(7881, 1.099587082862854)
(7882, 1.0959495306015015)
(7883, 1.0966699123382568)
(7884, 1.0996695756912231)
(7885, 1.10013747215271)
(7886, 1.0998321771621704)
(7887, 1.097998023033142)
(7888, 1.0976983308792114)
(7889, 1.0999358892440796)
(7890, 1.0991437435150146)
(7891, 1.10402512550354)
(7892, 1.0980724096298218)
(7893, 1.095934510231018)
(7894, 1.0984468460083008)
(7895, 1.0955138206481934)
(7896, 1.0971453189849854)
(7897, 1.0996311902999878)
(7898, 1.0954890251159668)
(7899, 1.095518946647644)
(7900, 1.0980048179626465)
Train Epoch: 0 [15800/549367 (92%)]	Loss: 1.098005
(7901, 1.0984983444213867)
(7902, 1.099752426147461)
(7903, 1.098718523979187)
(7904, 1.0987415313720703)
(7905, 1.0985521078109741)
(7906, 1.097172498703003)
(7907, 1.0978810787200928)
(7908, 1.096514344215393)
(7909, 1.102332353591919)
(7910, 1.1024396419525146)
(7911, 1.101042628288269)
(7912, 1.0989662408828735)
(7913, 1.0963877439498901)
(7914, 1.1015281677246094)
(7915, 1.0974810123443604)
(7916, 1.102728247642517)
(7917, 1.0997627973556519)
(7918, 1.1044362783432007)
(7919, 1.1019421815872192)
(7920, 1.1030685901641846)
(7921, 1.1014673709869385)
(7922, 1.1008998155593872)
(7923, 1.0993605852127075)
(7924, 1.1010220050811768)
(7925, 1.1031415462493896)
(7926, 1.1020394563674927)
(7927, 1.0973849296569824)
(7928, 1.0967719554901123)
(7929, 1.0970866680145264)
(7930, 1.1011401414871216)
(7931, 1.0956701040267944)
(7932, 1.0991101264953613)
(7933, 1.0966944694519043)
(7934, 1.0988621711730957)
(7935, 1.0990145206451416)
(7936, 1.0983301401138306)
(7937, 1.0967669486999512)
(7938, 1.097154140472412)
(7939, 1.1024360656738281)
(7940, 1.1002073287963867)
(7941, 1.0984482765197754)
(7942, 1.1001161336898804)
(7943, 1.0999106168746948)
(7944, 1.1008275747299194)
(7945, 1.098193645477295)
(7946, 1.0981093645095825)
(7947, 1.0952732563018799)
(7948, 1.1008052825927734)
(7949, 1.101226806640625)
(7950, 1.0966742038726807)
(7951, 1.1003949642181396)
(7952, 1.098281979560852)
(7953, 1.0977344512939453)
(7954, 1.0988658666610718)
(7955, 1.1012556552886963)
(7956, 1.0962884426116943)
(7957, 1.0996092557907104)
(7958, 1.096629023551941)
(7959, 1.1008310317993164)
(7960, 1.0979931354522705)
(7961, 1.095798134803772)
(7962, 1.0992765426635742)
(7963, 1.0981847047805786)
(7964, 1.1006039381027222)
(7965, 1.0997778177261353)
(7966, 1.101129412651062)
(7967, 1.0989311933517456)
(7968, 1.0990873575210571)
(7969, 1.0976784229278564)
(7970, 1.0966308116912842)
(7971, 1.0993393659591675)
(7972, 1.1020705699920654)
(7973, 1.0989378690719604)
(7974, 1.1017104387283325)
(7975, 1.09900963306427)
(7976, 1.1005043983459473)
(7977, 1.1005873680114746)
(7978, 1.0992166996002197)
(7979, 1.0973799228668213)
(7980, 1.100696325302124)
(7981, 1.0976932048797607)
(7982, 1.0966405868530273)
(7983, 1.1002272367477417)
(7984, 1.0985100269317627)
(7985, 1.0959264039993286)
(7986, 1.0994527339935303)
(7987, 1.1013606786727905)
(7988, 1.0961850881576538)
(7989, 1.0994360446929932)
(7990, 1.1011812686920166)
(7991, 1.0991709232330322)
(7992, 1.0961410999298096)
(7993, 1.0994840860366821)
(7994, 1.096567153930664)
(7995, 1.09791100025177)
(7996, 1.0980594158172607)
(7997, 1.0977803468704224)
(7998, 1.0995641946792603)
(7999, 1.0977205038070679)
(8000, 1.0988389253616333)
Train Epoch: 0 [16000/549367 (93%)]	Loss: 1.098839
(8001, 1.0981841087341309)
(8002, 1.102433204650879)
(8003, 1.0991055965423584)
(8004, 1.0993248224258423)
(8005, 1.1000899076461792)
(8006, 1.0985431671142578)
(8007, 1.0964815616607666)
(8008, 1.0970615148544312)
(8009, 1.1011850833892822)
(8010, 1.0973498821258545)
(8011, 1.0989474058151245)
(8012, 1.0966408252716064)
(8013, 1.1000728607177734)
(8014, 1.1027694940567017)
(8015, 1.0949525833129883)
(8016, 1.098602533340454)
(8017, 1.0990192890167236)
(8018, 1.0993163585662842)
(8019, 1.1022858619689941)
(8020, 1.0944987535476685)
(8021, 1.0986311435699463)
(8022, 1.0933136940002441)
(8023, 1.098648190498352)
(8024, 1.0971856117248535)
(8025, 1.0959609746932983)
(8026, 1.1016509532928467)
(8027, 1.0989880561828613)
(8028, 1.0992279052734375)
(8029, 1.0988447666168213)
(8030, 1.101883053779602)
(8031, 1.0973138809204102)
(8032, 1.1021056175231934)
(8033, 1.0987303256988525)
(8034, 1.1039443016052246)
(8035, 1.1006832122802734)
(8036, 1.0961147546768188)
(8037, 1.0965344905853271)
(8038, 1.1001778841018677)
(8039, 1.101874828338623)
(8040, 1.0953633785247803)
(8041, 1.0970158576965332)
(8042, 1.1026360988616943)
(8043, 1.100740671157837)
(8044, 1.0996891260147095)
(8045, 1.101819396018982)
(8046, 1.0959714651107788)
(8047, 1.0984632968902588)
(8048, 1.1020642518997192)
(8049, 1.0960862636566162)
(8050, 1.0984715223312378)
(8051, 1.097833275794983)
(8052, 1.101122260093689)
(8053, 1.0966904163360596)
(8054, 1.0978543758392334)
(8055, 1.0970431566238403)
(8056, 1.0988192558288574)
(8057, 1.1007053852081299)
(8058, 1.0988364219665527)
(8059, 1.1026332378387451)
(8060, 1.0998647212982178)
(8061, 1.0964893102645874)
(8062, 1.0978864431381226)
(8063, 1.0998189449310303)
(8064, 1.099458932876587)
(8065, 1.1026430130004883)
(8066, 1.0978093147277832)
(8067, 1.0976078510284424)
(8068, 1.0986675024032593)
(8069, 1.0990954637527466)
(8070, 1.0970731973648071)
(8071, 1.0992439985275269)
(8072, 1.0986063480377197)
(8073, 1.0996887683868408)
(8074, 1.096358060836792)
(8075, 1.0997953414916992)
(8076, 1.098708152770996)
(8077, 1.0998952388763428)
(8078, 1.0997239351272583)
(8079, 1.0972983837127686)
(8080, 1.1035887002944946)
(8081, 1.1003079414367676)
(8082, 1.0963337421417236)
(8083, 1.0973258018493652)
(8084, 1.1038435697555542)
(8085, 1.1013352870941162)
(8086, 1.1035335063934326)
(8087, 1.0999698638916016)
(8088, 1.0946669578552246)
(8089, 1.0966792106628418)
(8090, 1.0988764762878418)
(8091, 1.0968345403671265)
(8092, 1.0974164009094238)
(8093, 1.0983185768127441)
(8094, 1.1047534942626953)
(8095, 1.1009479761123657)
(8096, 1.1006006002426147)
(8097, 1.0968060493469238)
(8098, 1.0974335670471191)
(8099, 1.0969243049621582)
(8100, 1.099037528038025)
Train Epoch: 0 [16200/549367 (94%)]	Loss: 1.099038
(8101, 1.0983259677886963)
(8102, 1.1026113033294678)
(8103, 1.0965981483459473)
(8104, 1.096808671951294)
(8105, 1.0978155136108398)
(8106, 1.1003520488739014)
(8107, 1.0974785089492798)
(8108, 1.100748062133789)
(8109, 1.0983495712280273)
(8110, 1.0926090478897095)
(8111, 1.099894642829895)
(8112, 1.098460078239441)
(8113, 1.098355770111084)
(8114, 1.0954738855361938)
(8115, 1.103712558746338)
(8116, 1.103266716003418)
(8117, 1.0974631309509277)
(8118, 1.0987523794174194)
(8119, 1.1017682552337646)
(8120, 1.098153829574585)
(8121, 1.0986136198043823)
(8122, 1.1010664701461792)
(8123, 1.0974080562591553)
(8124, 1.099664330482483)
(8125, 1.1002576351165771)
(8126, 1.1011478900909424)
(8127, 1.0993632078170776)
(8128, 1.100584864616394)
(8129, 1.097786545753479)
(8130, 1.0976985692977905)
(8131, 1.0954781770706177)
(8132, 1.0984625816345215)
(8133, 1.1034612655639648)
(8134, 1.0954720973968506)
(8135, 1.1016154289245605)
(8136, 1.1020010709762573)
(8137, 1.097277283668518)
(8138, 1.1022889614105225)
(8139, 1.1007115840911865)
(8140, 1.0936415195465088)
(8141, 1.0975701808929443)
(8142, 1.099600076675415)
(8143, 1.1000593900680542)
(8144, 1.1019501686096191)
(8145, 1.0992494821548462)
(8146, 1.0986086130142212)
(8147, 1.0926878452301025)
(8148, 1.0953954458236694)
(8149, 1.0992814302444458)
(8150, 1.1008400917053223)
(8151, 1.10344398021698)
(8152, 1.0981436967849731)
(8153, 1.098740816116333)
(8154, 1.1016476154327393)
(8155, 1.099764108657837)
(8156, 1.0957882404327393)
(8157, 1.0981550216674805)
(8158, 1.1012382507324219)
(8159, 1.0963051319122314)
(8160, 1.1049681901931763)
(8161, 1.0948786735534668)
(8162, 1.094612956047058)
(8163, 1.1004421710968018)
(8164, 1.0957505702972412)
(8165, 1.0989545583724976)
(8166, 1.0983854532241821)
(8167, 1.1072087287902832)
(8168, 1.0968304872512817)
(8169, 1.100991129875183)
(8170, 1.1010483503341675)
(8171, 1.1053482294082642)
(8172, 1.0951787233352661)
(8173, 1.0971078872680664)
(8174, 1.100803256034851)
(8175, 1.095098853111267)
(8176, 1.098294734954834)
(8177, 1.0982297658920288)
(8178, 1.1000757217407227)
(8179, 1.0973916053771973)
(8180, 1.0930336713790894)
(8181, 1.1000150442123413)
(8182, 1.0981488227844238)
(8183, 1.100942850112915)
(8184, 1.1017212867736816)
(8185, 1.0953575372695923)
(8186, 1.1076488494873047)
(8187, 1.0992083549499512)
(8188, 1.1016756296157837)
(8189, 1.0992381572723389)
(8190, 1.1045222282409668)
(8191, 1.1003037691116333)
(8192, 1.1022571325302124)
(8193, 1.0998133420944214)
(8194, 1.1006674766540527)
(8195, 1.0996735095977783)
(8196, 1.0990933179855347)
(8197, 1.0968486070632935)
(8198, 1.0991231203079224)
(8199, 1.1001712083816528)
(8200, 1.0984017848968506)
Train Epoch: 0 [16400/549367 (96%)]	Loss: 1.098402
(8201, 1.1000548601150513)
(8202, 1.0993181467056274)
(8203, 1.098036289215088)
(8204, 1.0984957218170166)
(8205, 1.1000487804412842)
(8206, 1.0996636152267456)
(8207, 1.0977451801300049)
(8208, 1.0963331460952759)
(8209, 1.099685788154602)
(8210, 1.1017874479293823)
(8211, 1.097782015800476)
(8212, 1.0969359874725342)
(8213, 1.0986039638519287)
(8214, 1.099025845527649)
(8215, 1.0993438959121704)
(8216, 1.0981396436691284)
(8217, 1.0982036590576172)
(8218, 1.095073938369751)
(8219, 1.1008871793746948)
(8220, 1.100609302520752)
(8221, 1.100191354751587)
(8222, 1.0998286008834839)
(8223, 1.0962406396865845)
(8224, 1.1023375988006592)
(8225, 1.0956974029541016)
(8226, 1.1000821590423584)
(8227, 1.0985746383666992)
(8228, 1.099113941192627)
(8229, 1.1016587018966675)
(8230, 1.1040984392166138)
(8231, 1.1031821966171265)
(8232, 1.1001479625701904)
(8233, 1.0964463949203491)
(8234, 1.1014630794525146)
(8235, 1.0998951196670532)
(8236, 1.1002644300460815)
(8237, 1.0995572805404663)
(8238, 1.0990025997161865)
(8239, 1.1022015810012817)
(8240, 1.101510763168335)
(8241, 1.1022597551345825)
(8242, 1.0960811376571655)
(8243, 1.1015723943710327)
(8244, 1.097898006439209)
(8245, 1.095643401145935)
(8246, 1.1008857488632202)
(8247, 1.1026579141616821)
(8248, 1.0958446264266968)
(8249, 1.097615122795105)
(8250, 1.0994638204574585)
(8251, 1.0986607074737549)
(8252, 1.0960005521774292)
(8253, 1.0995265245437622)
(8254, 1.095422625541687)
(8255, 1.0998576879501343)
(8256, 1.1045526266098022)
(8257, 1.0974581241607666)
(8258, 1.097662091255188)
(8259, 1.1044799089431763)
(8260, 1.095427393913269)
(8261, 1.0970693826675415)
(8262, 1.0992380380630493)
(8263, 1.1025724411010742)
(8264, 1.1001368761062622)
(8265, 1.098915934562683)
(8266, 1.0973894596099854)
(8267, 1.099637746810913)
(8268, 1.1004804372787476)
(8269, 1.1037375926971436)
(8270, 1.0993901491165161)
(8271, 1.1006579399108887)
(8272, 1.1023715734481812)
(8273, 1.0974416732788086)
(8274, 1.1008249521255493)
(8275, 1.097469449043274)
(8276, 1.1005456447601318)
(8277, 1.0944608449935913)
(8278, 1.1022928953170776)
(8279, 1.0996215343475342)
(8280, 1.0955742597579956)
(8281, 1.1019468307495117)
(8282, 1.0986158847808838)
(8283, 1.1016407012939453)
(8284, 1.0964499711990356)
(8285, 1.0995897054672241)
(8286, 1.0979419946670532)
(8287, 1.0981556177139282)
(8288, 1.0976759195327759)
(8289, 1.0994038581848145)
(8290, 1.09369957447052)
(8291, 1.0961754322052002)
(8292, 1.0992405414581299)
(8293, 1.0975761413574219)
(8294, 1.0969417095184326)
(8295, 1.1010366678237915)
(8296, 1.104196310043335)
(8297, 1.097739577293396)
(8298, 1.1033955812454224)
(8299, 1.1026568412780762)
(8300, 1.1011027097702026)
Train Epoch: 0 [16600/549367 (97%)]	Loss: 1.101103
(8301, 1.0974370241165161)
(8302, 1.0962669849395752)
(8303, 1.0982692241668701)
(8304, 1.0965232849121094)
(8305, 1.0967880487442017)
(8306, 1.1039592027664185)
(8307, 1.0931453704833984)
(8308, 1.0947903394699097)
(8309, 1.1004383563995361)
(8310, 1.1044176816940308)
(8311, 1.0941994190216064)
(8312, 1.0967744588851929)
(8313, 1.0938979387283325)
(8314, 1.0977990627288818)
(8315, 1.0987366437911987)
(8316, 1.101119875907898)
(8317, 1.0946259498596191)
(8318, 1.0931599140167236)
(8319, 1.0997729301452637)
(8320, 1.0975782871246338)
(8321, 1.1009876728057861)
(8322, 1.0976128578186035)
(8323, 1.0970741510391235)
(8324, 1.0944359302520752)
(8325, 1.0983654260635376)
(8326, 1.0964187383651733)
(8327, 1.0980138778686523)
(8328, 1.0927842855453491)
(8329, 1.0963786840438843)
(8330, 1.0962790250778198)
(8331, 1.0940536260604858)
(8332, 1.1004024744033813)
(8333, 1.1000641584396362)
(8334, 1.0948514938354492)
(8335, 1.0882906913757324)
(8336, 1.0950103998184204)
(8337, 1.0985792875289917)
(8338, 1.1008484363555908)
(8339, 1.1008366346359253)
(8340, 1.1007074117660522)
(8341, 1.099576711654663)
(8342, 1.1006505489349365)
(8343, 1.0962964296340942)
(8344, 1.0959728956222534)
(8345, 1.1017882823944092)
(8346, 1.098322868347168)
(8347, 1.1028858423233032)
(8348, 1.0990033149719238)
(8349, 1.0989837646484375)
(8350, 1.0974760055541992)
(8351, 1.1024090051651)
(8352, 1.094334363937378)
(8353, 1.101185917854309)
(8354, 1.099242091178894)
(8355, 1.1033188104629517)
(8356, 1.0978683233261108)
(8357, 1.0974563360214233)
(8358, 1.090755581855774)
(8359, 1.0999807119369507)
(8360, 1.0949753522872925)
(8361, 1.0953882932662964)
(8362, 1.1053948402404785)
(8363, 1.102137565612793)
(8364, 1.0964328050613403)
(8365, 1.0966293811798096)
(8366, 1.099511981010437)
(8367, 1.0970377922058105)
(8368, 1.0950062274932861)
(8369, 1.1002678871154785)
(8370, 1.0985124111175537)
(8371, 1.0981955528259277)
(8372, 1.1041091680526733)
(8373, 1.1012850999832153)
(8374, 1.1038511991500854)
(8375, 1.0978357791900635)
(8376, 1.094434380531311)
(8377, 1.1007548570632935)
(8378, 1.1067975759506226)
(8379, 1.0971819162368774)
(8380, 1.1003721952438354)
(8381, 1.0989733934402466)
(8382, 1.101396083831787)
(8383, 1.099888801574707)
(8384, 1.1123906373977661)
(8385, 1.1028636693954468)
(8386, 1.098860263824463)
(8387, 1.1044321060180664)
(8388, 1.1052342653274536)
(8389, 1.0963636636734009)
(8390, 1.1052497625350952)
(8391, 1.1057604551315308)
(8392, 1.0996482372283936)
(8393, 1.097786545753479)
(8394, 1.0938860177993774)
(8395, 1.0956934690475464)
(8396, 1.100598692893982)
(8397, 1.1017526388168335)
(8398, 1.1006641387939453)
(8399, 1.0974366664886475)
(8400, 1.1023207902908325)
Train Epoch: 0 [16800/549367 (98%)]	Loss: 1.102321
(8401, 1.098744511604309)
(8402, 1.098557472229004)
(8403, 1.1022634506225586)
(8404, 1.0981305837631226)
(8405, 1.0988253355026245)
(8406, 1.098956823348999)
(8407, 1.101096749305725)
(8408, 1.098992943763733)
(8409, 1.101670742034912)
(8410, 1.0960330963134766)
(8411, 1.1024587154388428)
(8412, 1.098328948020935)
(8413, 1.0979909896850586)
(8414, 1.098678708076477)
(8415, 1.1031361818313599)
(8416, 1.0949962139129639)
(8417, 1.0974706411361694)
(8418, 1.0950877666473389)
(8419, 1.1006927490234375)
(8420, 1.0998247861862183)
(8421, 1.0980397462844849)
(8422, 1.0996218919754028)
(8423, 1.1041839122772217)
(8424, 1.097590446472168)
(8425, 1.1011399030685425)
(8426, 1.09421706199646)
(8427, 1.097137212753296)
(8428, 1.094696283340454)
(8429, 1.0968036651611328)
(8430, 1.0968037843704224)
(8431, 1.0991160869598389)
(8432, 1.0968270301818848)
(8433, 1.0981336832046509)
(8434, 1.1006035804748535)
(8435, 1.0968660116195679)
(8436, 1.0996290445327759)
(8437, 1.0988377332687378)
(8438, 1.0966086387634277)
(8439, 1.1010091304779053)
(8440, 1.0976402759552002)
(8441, 1.1014244556427002)
(8442, 1.0993815660476685)
(8443, 1.1023198366165161)
(8444, 1.0993367433547974)
(8445, 1.0998668670654297)
(8446, 1.0982211828231812)
(8447, 1.097267746925354)
(8448, 1.0981969833374023)
(8449, 1.1005895137786865)
(8450, 1.099922776222229)
(8451, 1.1024879217147827)
(8452, 1.0986707210540771)
(8453, 1.09953773021698)
(8454, 1.1038962602615356)
(8455, 1.0963813066482544)
(8456, 1.096845269203186)
(8457, 1.0992674827575684)
(8458, 1.1023688316345215)
(8459, 1.1036735773086548)
(8460, 1.092031478881836)
(8461, 1.0974411964416504)
(8462, 1.0953369140625)
(8463, 1.0999369621276855)
(8464, 1.0948915481567383)
(8465, 1.098807692527771)
(8466, 1.0988129377365112)
(8467, 1.0946546792984009)
(8468, 1.0981764793395996)
(8469, 1.0994148254394531)
(8470, 1.1005711555480957)
(8471, 1.0985817909240723)
(8472, 1.095740795135498)
(8473, 1.1014951467514038)
(8474, 1.0998164415359497)
(8475, 1.0950496196746826)
(8476, 1.0968246459960938)
(8477, 1.1052931547164917)
(8478, 1.0982797145843506)
(8479, 1.097141146659851)
(8480, 1.0962673425674438)
(8481, 1.0965217351913452)
(8482, 1.1027677059173584)
(8483, 1.097843050956726)
(8484, 1.1010799407958984)
(8485, 1.0983456373214722)
(8486, 1.0992921590805054)
(8487, 1.1045119762420654)
(8488, 1.0962233543395996)
(8489, 1.0990264415740967)
(8490, 1.0989930629730225)
(8491, 1.0998730659484863)
(8492, 1.0952773094177246)
(8493, 1.0998412370681763)
(8494, 1.0953319072723389)
(8495, 1.1035939455032349)
(8496, 1.1003303527832031)
(8497, 1.0986181497573853)
(8498, 1.1047571897506714)
(8499, 1.1001617908477783)
(8500, 1.1031296253204346)
Train Epoch: 0 [17000/549367 (99%)]	Loss: 1.103130
(8501, 1.1005090475082397)
(8502, 1.09832763671875)
(8503, 1.0999729633331299)
(8504, 1.098343849182129)
(8505, 1.0994513034820557)
(8506, 1.101745843887329)
(8507, 1.1030362844467163)
(8508, 1.0995941162109375)
(8509, 1.0979418754577637)
(8510, 1.0997415781021118)
(8511, 1.1008397340774536)
(8512, 1.09762704372406)
(8513, 1.099204659461975)
(8514, 1.0981593132019043)
(8515, 1.097226858139038)
(8516, 1.0999336242675781)
(8517, 1.10028076171875)
(8518, 1.0998636484146118)
(8519, 1.1017377376556396)
(8520, 1.098720669746399)
(8521, 1.0989940166473389)
(8522, 1.1009798049926758)
(8523, 1.0971564054489136)
(8524, 1.1033399105072021)
(8525, 1.0986528396606445)
(8526, 1.095309853553772)
(8527, 1.0995217561721802)
(8528, 1.1005209684371948)
(8529, 1.1021904945373535)
(8530, 1.0977061986923218)
(8531, 1.1003111600875854)
(8532, 1.102609634399414)
(8533, 1.0960681438446045)
(8534, 1.100495457649231)
(8535, 1.0974743366241455)
(8536, 1.0986249446868896)
(8537, 1.098954677581787)
(8538, 1.0954599380493164)
(8539, 1.0974119901657104)
(8540, 1.0939505100250244)
(8541, 1.1027452945709229)
(8542, 1.0994925498962402)
(8543, 1.0969939231872559)
(8544, 1.0957626104354858)
(8545, 1.0999205112457275)
(8546, 1.0958833694458008)
(8547, 1.0981184244155884)
(8548, 1.099901795387268)
(8549, 1.097025752067566)
(8550, 1.097548007965088)
(8551, 1.0982916355133057)
(8552, 1.0993634462356567)
(8553, 1.0954091548919678)
(8554, 1.0998274087905884)
(8555, 1.0997370481491089)
(8556, 1.0987341403961182)
(8557, 1.097448468208313)
(8558, 1.1000425815582275)
(8559, 1.1017378568649292)
(8560, 1.0951586961746216)
(8561, 1.09915292263031)
(8562, 1.0999975204467773)
(8563, 1.1005085706710815)
(8564, 1.0995994806289673)
(8565, 1.1015959978103638)
(8566, 1.1019748449325562)
(8567, 1.101965308189392)
(8568, 1.1024872064590454)
(8569, 1.0991290807724)
(8570, 1.0987497568130493)
(8571, 1.098692536354065)
(8572, 1.098533272743225)
(8573, 1.0969091653823853)
(8574, 1.1016138792037964)
(8575, 1.1013245582580566)
(8576, 1.0998246669769287)
(8577, 1.0954996347427368)
(8578, 1.0973683595657349)
(8579, 1.09695303440094)
(8580, 1.1030300855636597)
(8581, 1.0985488891601562)
(8582, 1.0988986492156982)
Traceback (most recent call last):
  File "./snliEncoder.py", line 210, in <module>
    main()
  File "./snliEncoder.py", line 205, in main
    train(numEpochs, trainLoader, model, optimizer, criterion, inp_dim, batchSize)
  File "./snliEncoder.py", line 145, in train
    trainEpoch(epoch,20000000,trainLoader,model,optimizer,criterion,inp_dim,batchSize)
  File "./snliEncoder.py", line 124, in trainEpoch
    s1 = s1.transpose(0,1).contiguous().view(-1,inp_dim,batchSize).transpose(1,2)
RuntimeError: invalid argument 2: size '[-1 x 300 x 64]' is invalid for input with 1287000 elements at /pytorch/torch/lib/TH/THStorage.c:37
